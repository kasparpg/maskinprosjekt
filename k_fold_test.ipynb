{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import warnings\n",
    "import os.path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from shapely import wkt\n",
    "from retail_revenue_xgb import generate_features, create_buffer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import squared_log, rmsle\n",
    "from xgboost import plot_importance, to_graphviz\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "age = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "income = pd.read_csv('data/grunnkrets_income_households.csv')\n",
    "households = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "plaace = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "\n",
    "\n",
    "def generate_features1(df: pd.DataFrame):\n",
    "    features = ['year', 'store_name', 'mall_name', 'chain_name', 'address', 'lat', 'lon',\n",
    "                'plaace_hierarchy_id', 'grunnkrets_id']\n",
    "    df = df[features]\n",
    "    df['store_name'] = df['store_name'].astype('category')\n",
    "    # df['store_id'] = df['store_id'].astype('category')\n",
    "    df['address'] = df['address'].astype('category')\n",
    "    df['chain_name+mall_name'] = (df['chain_name'] + df['mall_name']).astype('category')\n",
    "    df['mall_name'] = df['mall_name'].astype('category')\n",
    "    df['chain_name'] = df['chain_name'].astype('category')\n",
    "    df['plaace_hierarchy_id'] = df['plaace_hierarchy_id'].astype('category')\n",
    "\n",
    "    # attempt to difference the lat and lon values, as they seem to be somewhat trending negatively.\n",
    "    df['lon'] = df['lon'].diff()\n",
    "    df['lat'] = df['lat'].diff()\n",
    "\n",
    "    # remove duplicates and merge with the spatial data.\n",
    "    spatial.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    df = pd.merge(df, spatial.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "    df['grunnkrets_name'] = df['grunnkrets_name'].astype('category')\n",
    "    df['district_name'] = df['district_name'].astype('category')\n",
    "    df['municipality_name'] = df['municipality_name'].astype('category')\n",
    "    df['geometry'] = df['geometry'].astype('category')\n",
    "\n",
    "    # age.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    # df = pd.merge(df, age.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "\n",
    "    income.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    df = pd.merge(df, income.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "\n",
    "    households.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    df = pd.merge(df, households.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "\n",
    "    plaace.drop_duplicates(subset=['plaace_hierarchy_id'])\n",
    "    df = pd.merge(df, plaace.drop_duplicates(subset=['plaace_hierarchy_id']), how='left')\n",
    "    df['plaace_hierarchy_id'] = df['plaace_hierarchy_id'].astype('category')\n",
    "    df['sales_channel_name'] = df['sales_channel_name'].astype('category')\n",
    "    df['lv1_desc'] = df['lv1_desc'].astype('category')\n",
    "    df['lv2_desc'] = df['lv2_desc'].astype('category')\n",
    "    df['lv3'] = df['lv3'].astype('category')\n",
    "    df['lv3_desc'] = df['lv3_desc'].astype('category')\n",
    "    df['lv4'] = df['lv4'].astype('category')\n",
    "    df['lv4_desc'] = df['lv4_desc'].astype('category')\n",
    "\n",
    "    df = df.drop(columns=['grunnkrets_id', 'plaace_hierarchy_id'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_features(df: pd.DataFrame):\n",
    "    features = ['year', 'store_name', 'mall_name', 'chain_name', 'address', 'lat', 'lon',\n",
    "                'plaace_hierarchy_id', 'grunnkrets_id']\n",
    "    df = df[features]\n",
    "    df['store_name'] = df['store_name']\n",
    "    # df['store_id'] = df['store_id']\n",
    "    df['address'] = df['address']\n",
    "    df['chain_name+mall_name'] = (df['chain_name'] + df['mall_name'])\n",
    "    df['mall_name'] = df['mall_name']\n",
    "    df['chain_name'] = df['chain_name']\n",
    "    df['plaace_hierarchy_id'] = df['plaace_hierarchy_id']\n",
    "\n",
    "    # attempt to difference the lat and lon values, as they seem to be somewhat trending negatively.\n",
    "    df['lon'] = df['lon'].diff()\n",
    "    df['lat'] = df['lat'].diff()\n",
    "\n",
    "    # remove duplicates and merge with the spatial data.\n",
    "    spatial.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    df = pd.merge(df, spatial.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "    df['grunnkrets_name'] = df['grunnkrets_name']\n",
    "    df['district_name'] = df['district_name']\n",
    "    df['municipality_name'] = df['municipality_name']\n",
    "    df['geometry'] = df['geometry']\n",
    "\n",
    "    # age.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    # df = pd.merge(df, age.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "\n",
    "    income.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    df = pd.merge(df, income.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "\n",
    "    households.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    df = pd.merge(df, households.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "\n",
    "    plaace.drop_duplicates(subset=['plaace_hierarchy_id'])\n",
    "    df = pd.merge(df, plaace.drop_duplicates(subset=['plaace_hierarchy_id']), how='left')\n",
    "    df['plaace_hierarchy_id'] = df['plaace_hierarchy_id']\n",
    "    df['sales_channel_name'] = df['sales_channel_name']\n",
    "    df['lv1_desc'] = df['lv1_desc']\n",
    "    df['lv2_desc'] = df['lv2_desc']\n",
    "    df['lv3'] = df['lv3']\n",
    "    df['lv3_desc'] = df['lv3_desc']\n",
    "    df['lv4'] = df['lv4']\n",
    "    df['lv4_desc'] = df['lv4_desc']\n",
    "\n",
    "    df = df.drop(columns=['grunnkrets_id', 'plaace_hierarchy_id'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = pd.read_csv('data/stores_train.csv')\n",
    "test = pd.read_csv('data/stores_test.csv')\n",
    "\n",
    "label_name = 'revenue'\n",
    "X = train.drop(columns=[label_name])\n",
    "y = train[label_name]\n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "model_to_load = \"modeling/0002.model\"\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "\n",
    "X = generate_features(X)\n",
    "X_train, X_val = generate_features(X_train), generate_features(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clear buffers\n",
    "# folder = os.path.join(os.getcwd(), 'modeling')\n",
    "# for filename in os.listdir(folder):\n",
    "#     file_path = os.path.join(folder, filename)\n",
    "#     if os.path.isfile(file_path):\n",
    "#         os.unlink(file_path)\n",
    "#         print(f'Deleted file: {file_path}')\n",
    "\n",
    "# train_buffer_path = 'modeling/train.buffer'\n",
    "# test_buffer_path = 'modeling/test.buffer'\n",
    "\n",
    "# dtrain = xgb.DMatrix(data=X_train, label=y_train, enable_categorical=True)\n",
    "# dtrain.save_binary(train_buffer_path)\n",
    "# print(f'--> {train_buffer_path} created and saved.')\n",
    "\n",
    "# dvalid = xgb.DMatrix(data=X_val, label=y_val, enable_categorical=True)\n",
    "# dvalid.save_binary(test_buffer_path)\n",
    "# print(f'--> {test_buffer_path} created and saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[23:49:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "-0.7734579532975809\n",
      "{'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 500, 'nthread': 4, 'objective': 'reg:squaredlogerror', 'silent': 1, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl = LabelEncoder()\n",
    "\n",
    "# Parameter grid for XGBoost\n",
    "params = {\n",
    "    # 'min_child_weight': [1, 5, 10],\n",
    "    # 'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    # 'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [4, 7, 10]\n",
    "}\n",
    "folds = 5\n",
    "param_comb = 5\n",
    "\n",
    "# Convert columns that are not numeric to a numeric value\n",
    "for c in X_train.columns:\n",
    "    if X_train[c].dtype == 'object':\n",
    "        lbl.fit(list(X_train[c].values))\n",
    "        X_train[c] = lbl.transform(list(X_train[c].values))\n",
    "        # x_train_full.drop(c,axis=1,inplace=True)\n",
    "\n",
    "X_val = generate_features(test)\n",
    "\n",
    "for c in X_val.columns:\n",
    "    if X_val[c].dtype == 'object':\n",
    "        lbl.fit(list(X_val[c].values))\n",
    "        X_val[c] = lbl.transform(list(X_val[c].values))\n",
    "        # x_test.drop(c,axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# xgb_model = XGBRegressor()\n",
    "# xgb_clf = RandomizedSearchCV(xgb_model, param_distributions=params, n_iter=100, \n",
    "#                                 scoring=mean_squared_log_error, n_jobs=4, \n",
    "#                                 cv=kfold.split(X_train, y_train), verbose=3, \n",
    "#                                 random_state=420)\n",
    "\n",
    "# model = xgb_clf.fit(X_train, y_train)\n",
    "# print(model.best_estimator_)\n",
    "\n",
    "# Various hyper-parameters to tune\n",
    "kfold = KFold(n_splits=folds, shuffle=True, random_state=420)\n",
    "xgb1 = XGBRegressor(eval_metric=mean_squared_log_error)\n",
    "parameters = {'nthread': [4],  # when use hyperthread, xgboost may become slower\n",
    "              'objective': ['reg:squaredlogerror'],\n",
    "              'learning_rate': [.03, 0.05, .07],  # so called `eta` value\n",
    "              'max_depth': [5, 10, 15],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "def rmsle(X, y):\n",
    "    y[y < -1] = -1 + 1e-6\n",
    "    elements = np.power(np.log1p(y) - np.log1p(y), 2)\n",
    "    return 'RMSLE', float(np.sqrt(np.sum(elements) / len(y)))\n",
    "\n",
    "\n",
    "def rmsle_vanilla(y_pred, y_true):\n",
    "    elements = np.power(np.log1p(y_pred) - np.log1p(y_true), 2)\n",
    "    return float(np.sqrt(np.sum(elements) / len(y_true)))\n",
    "\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_vanilla, greater_is_better=False)\n",
    "\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv=kfold,\n",
    "                        n_jobs=-1,\n",
    "                        scoring=rmsle_scorer,\n",
    "                        verbose=3)\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)\n",
    "\n",
    "model = xgb_grid.best_estimator_\n",
    "# y_predict_train = xgb_grid.best_estimator_.predict(X_train)\n",
    "\n",
    "\n",
    "# y_predict_test = xgb_grid.best_estimator_.predict(X_test)\n",
    "\n",
    "# X_test = generate_features(test)\n",
    "# dtest = xgb.DMatrix(data=X_test, enable_categorical=True)\n",
    "\n",
    "# y_pred = model.predict_proba(X_test)\n",
    "# print(\"\\nAttempting to save prediction...\")\n",
    "# submission['predicted'] = np.array(y_pred)\n",
    "# submission.to_csv('submissions/submission.csv', index=False)\n",
    "# print(\"--> prediction saved with features as name in submission folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RMSLE', 0.16609332197106508)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def rmsle_vanilla(y_pred, y_true):\n",
    "    elements = np.power(np.log1p(y_pred) - np.log1p(y_true), 2)\n",
    "    return 'RMSLE', float(np.sqrt(np.sum(elements) / len(y_true)))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_vanilla, greater_is_better=False)\n",
    "\n",
    "rmsle(\n",
    "    np.array([1, 2, 3]),\n",
    "    np.array([1, 2, 2])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36004/975118123.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'object'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mlbl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlbl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# x_test.drop(c,axis=1,inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m     98\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_unique\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m     43\u001b[0m         )\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# numerical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     return _unique_np(\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_unique_np\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \"\"\"Helper function to find unique values for numpy arrays that correctly\n\u001b[0;32m     52\u001b[0m     accounts for nans. See `_unique` documentation for details.\"\"\"\n\u001b[1;32m---> 53\u001b[1;33m     uniques = np.unique(\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     )\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_test = generate_features(test)\n",
    "\n",
    "for c in X_test.columns:\n",
    "    if X_test[c].dtype == 'object':\n",
    "        lbl.fit(list(X_test[c].values))\n",
    "        X_test[c] = lbl.transform(list(X_test[c].values))\n",
    "        # x_test.drop(c,axis=1,inplace=True)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "# print(mean_squared_log_error(y_test, y_pred_test, squared=False))\n",
    "\n",
    "print(\"\\nAttempting to save prediction...\")\n",
    "submission['predicted'] = np.array(y_pred_test)\n",
    "submission.to_csv('submissions/submission.csv', index=False)\n",
    "print(\"--> prediction saved with features as name in submission folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572 2572 2572\n",
      "1.085321068283053\n"
     ]
    }
   ],
   "source": [
    "for c in X_val.columns:\n",
    "    if X_val[c].dtype == 'object':\n",
    "        lbl.fit(list(X_val[c].values))\n",
    "        X_val[c] = lbl.transform(list(X_val[c].values))\n",
    "        # x_test.drop(c,axis=1,inplace=True)\n",
    "\n",
    "\n",
    "y_pred_val = xgb_grid.best_estimator_.predict(X_val)\n",
    "print(len(y_val), len(y_pred_val), len(X_val))\n",
    "print(mean_squared_log_error(y_val, y_pred_val, squared=False))\n",
    "\n",
    "# y_pred_train = xgb_grid.best_estimator_.predict(X_train)\n",
    "# print(mean_squared_log_error(y_train, y_pred_train, squared=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to start prediction...\n",
      "--> Prediction finished.\n",
      "\n",
      "Attempting to save prediction...\n",
      "--> prediction saved with features as name in submission folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:91: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# X_test = generate_features(test)\n",
    "# dtest = xgb.DMatrix(data=X_test, enable_categorical=True)\n",
    "\n",
    "# print(\"\\nAttempting to start prediction...\")\n",
    "# y_pred = model.predict(dtest, ntree_limit=model.best_iteration)\n",
    "# print(\"--> Prediction finished.\")\n",
    "\n",
    "# print(\"\\nAttempting to save prediction...\")\n",
    "# submission['predicted'] = np.array(y_pred)\n",
    "# submission.to_csv('submissions/submission.csv', index=False)\n",
    "# print(\"--> prediction saved with features as name in submission folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[17:49:29] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\c_api\\c_api_utils.h:222: Check failed: feature_names.size() == n_features (34 vs. 36) : Incorrect number of feature names.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45032/3892230781.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_trees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# fig, ax = plt.subplots(figsize=(30, 30))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\plotting.py\u001b[0m in \u001b[0;36mplot_importance\u001b[1;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m             importance_type=importance_type, fmap=fmap)\n\u001b[0;32m     66\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mimportance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mimportance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mget_score\u001b[1;34m(self, fmap, importance_type)\u001b[0m\n\u001b[0;32m   2462\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2464\u001b[1;33m         _check_call(\n\u001b[0m\u001b[0;32m   2465\u001b[0m             _LIB.XGBoosterFeatureScore(\n\u001b[0;32m   2466\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \"\"\"\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [17:49:29] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\c_api\\c_api_utils.h:222: Check failed: feature_names.size() == n_features (34 vs. 36) : Incorrect number of feature names."
     ]
    }
   ],
   "source": [
    "from xgboost import plot_tree\n",
    "\n",
    "plot_importance(model)\n",
    "xgb.to_graphviz(model, num_trees=1)\n",
    "# fig, ax = plt.subplots(figsize=(30, 30))\n",
    "# xgb.plot_tree(bst, num_trees=1, ax=ax)\n",
    "# plt.savefig(\"temp.pdf\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "882a6b7fc3ca80e688227decd54209862062b8721a918d514e0ed60576137ba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
