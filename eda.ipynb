{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import warnings\n",
    "import os.path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from shapely import wkt\n",
    "from retail_revenue_xgb import generate_features, create_buffer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import squared_log, rmsle\n",
    "from xgboost import plot_importance, to_graphviz\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "age = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "income = pd.read_csv('data/grunnkrets_income_households.csv')\n",
    "households = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "plaace = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "\n",
    "\n",
    "def generate_features(df: pd.DataFrame):\n",
    "    features = ['year', 'store_name', 'mall_name', 'chain_name', 'address', 'lat', 'lon',\n",
    "                'plaace_hierarchy_id', 'grunnkrets_id']\n",
    "    df = df[features]\n",
    "    df['store_name'] = df['store_name'].astype('category')\n",
    "    # df['store_id'] = df['store_id'].astype('category')\n",
    "    df['address'] = df['address'].astype('category')\n",
    "    df['chain_name+mall_name'] = (df['chain_name'] + df['mall_name']).astype('category')\n",
    "    df['mall_name'] = df['mall_name'].astype('category')\n",
    "    df['chain_name'] = df['chain_name'].astype('category')\n",
    "    df['plaace_hierarchy_id'] = df['plaace_hierarchy_id'].astype('category')\n",
    "\n",
    "    # attempt to difference the lat and lon values, as they seem to be somewhat trending negatively.\n",
    "    df['lon'] = df['lon'].diff()\n",
    "    df['lat'] = df['lat'].diff()\n",
    "\n",
    "    # remove duplicates and merge with the spatial data.\n",
    "    spatial.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    df = pd.merge(df, spatial.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "    df['grunnkrets_name'] = df['grunnkrets_name'].astype('category')\n",
    "    df['district_name'] = df['district_name'].astype('category')\n",
    "    df['municipality_name'] = df['municipality_name'].astype('category')\n",
    "    df['geometry'] = df['geometry'].astype('category')\n",
    "\n",
    "    # age.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    # df = pd.merge(df, age.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "\n",
    "    income.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    df = pd.merge(df, income.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "\n",
    "    households.drop_duplicates(subset=['grunnkrets_id'])\n",
    "    df = pd.merge(df, households.drop_duplicates(subset=['grunnkrets_id']), how='left')\n",
    "\n",
    "    plaace.drop_duplicates(subset=['plaace_hierarchy_id'])\n",
    "    df = pd.merge(df, plaace.drop_duplicates(subset=['plaace_hierarchy_id']), how='left')\n",
    "    df['plaace_hierarchy_id'] = df['plaace_hierarchy_id'].astype('category')\n",
    "    df['sales_channel_name'] = df['sales_channel_name'].astype('category')\n",
    "    df['lv1_desc'] = df['lv1_desc'].astype('category')\n",
    "    df['lv2_desc'] = df['lv2_desc'].astype('category')\n",
    "    df['lv3'] = df['lv3'].astype('category')\n",
    "    df['lv3_desc'] = df['lv3_desc'].astype('category')\n",
    "    df['lv4'] = df['lv4'].astype('category')\n",
    "    df['lv4_desc'] = df['lv4_desc'].astype('category')\n",
    "\n",
    "    df = df.drop(columns=['grunnkrets_id', 'plaace_hierarchy_id'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = pd.read_csv('data/stores_train.csv')\n",
    "test = pd.read_csv('data/stores_test.csv')\n",
    "\n",
    "label_name = 'revenue'\n",
    "X = train.drop(columns=[label_name])\n",
    "y = train[label_name]\n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "model_to_load = \"modeling/0002.model\"\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "\n",
    "X_train, X_val = generate_features(X_train), generate_features(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> modeling/train.buffer created and saved.\n",
      "--> modeling/test.buffer created and saved.\n"
     ]
    }
   ],
   "source": [
    "# Clear buffers\n",
    "folder = os.path.join(os.getcwd(), 'modeling')\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.unlink(file_path)\n",
    "        print(f'Deleted file: {file_path}')\n",
    "\n",
    "train_buffer_path = 'modeling/train.buffer'\n",
    "test_buffer_path = 'modeling/test.buffer'\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train, enable_categorical=True)\n",
    "dtrain.save_binary(train_buffer_path)\n",
    "print(f'--> {train_buffer_path} created and saved.')\n",
    "\n",
    "dvalid = xgb.DMatrix(data=X_val, label=y_val, enable_categorical=True)\n",
    "dvalid.save_binary(test_buffer_path)\n",
    "print(f'--> {test_buffer_path} created and saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No model found. Attempt at creating a new one will now start:\n",
      "Attempting to initialize parameters for training...\n",
      "Starting k-fold cross validaition...\n",
      "[0]\ttrain-RMSLE:1.54266+0.00486\ttest-RMSLE:1.54265+0.04401\n",
      "[0]\ttrain-RMSLE:1.54266\ttest-RMSLE:1.54265\n",
      "[1]\ttrain-RMSLE:1.52145+0.00482\ttest-RMSLE:1.52207+0.04370\n",
      "[1]\ttrain-RMSLE:1.52145\ttest-RMSLE:1.52207\n",
      "[2]\ttrain-RMSLE:1.50054+0.00478\ttest-RMSLE:1.50181+0.04340\n",
      "[2]\ttrain-RMSLE:1.50054\ttest-RMSLE:1.50181\n",
      "[3]\ttrain-RMSLE:1.47994+0.00474\ttest-RMSLE:1.48189+0.04308\n",
      "[3]\ttrain-RMSLE:1.47994\ttest-RMSLE:1.48189\n",
      "[4]\ttrain-RMSLE:1.45964+0.00470\ttest-RMSLE:1.46228+0.04276\n",
      "[4]\ttrain-RMSLE:1.45964\ttest-RMSLE:1.46228\n",
      "[5]\ttrain-RMSLE:1.43965+0.00466\ttest-RMSLE:1.44298+0.04243\n",
      "[5]\ttrain-RMSLE:1.43965\ttest-RMSLE:1.44298\n",
      "[6]\ttrain-RMSLE:1.41996+0.00462\ttest-RMSLE:1.42397+0.04212\n",
      "[6]\ttrain-RMSLE:1.41996\ttest-RMSLE:1.42397\n",
      "[7]\ttrain-RMSLE:1.40057+0.00458\ttest-RMSLE:1.40529+0.04180\n",
      "[7]\ttrain-RMSLE:1.40057\ttest-RMSLE:1.40529\n",
      "[8]\ttrain-RMSLE:1.38149+0.00453\ttest-RMSLE:1.38692+0.04147\n",
      "[8]\ttrain-RMSLE:1.38149\ttest-RMSLE:1.38692\n",
      "[9]\ttrain-RMSLE:1.36273+0.00448\ttest-RMSLE:1.36890+0.04111\n",
      "[9]\ttrain-RMSLE:1.36273\ttest-RMSLE:1.36890\n",
      "[10]\ttrain-RMSLE:1.34428+0.00443\ttest-RMSLE:1.35118+0.04074\n",
      "[10]\ttrain-RMSLE:1.34428\ttest-RMSLE:1.35118\n",
      "[11]\ttrain-RMSLE:1.32616+0.00439\ttest-RMSLE:1.33375+0.04032\n",
      "[11]\ttrain-RMSLE:1.32616\ttest-RMSLE:1.33375\n",
      "[12]\ttrain-RMSLE:1.30834+0.00434\ttest-RMSLE:1.31666+0.03992\n",
      "[12]\ttrain-RMSLE:1.30834\ttest-RMSLE:1.31666\n",
      "[13]\ttrain-RMSLE:1.29085+0.00429\ttest-RMSLE:1.29989+0.03952\n",
      "[13]\ttrain-RMSLE:1.29085\ttest-RMSLE:1.29989\n",
      "[14]\ttrain-RMSLE:1.27367+0.00425\ttest-RMSLE:1.28343+0.03908\n",
      "[14]\ttrain-RMSLE:1.27367\ttest-RMSLE:1.28343\n",
      "[15]\ttrain-RMSLE:1.25680+0.00420\ttest-RMSLE:1.26728+0.03865\n",
      "[15]\ttrain-RMSLE:1.25680\ttest-RMSLE:1.26728\n",
      "[16]\ttrain-RMSLE:1.24025+0.00417\ttest-RMSLE:1.25147+0.03822\n",
      "[16]\ttrain-RMSLE:1.24025\ttest-RMSLE:1.25147\n",
      "[17]\ttrain-RMSLE:1.22401+0.00412\ttest-RMSLE:1.23602+0.03776\n",
      "[17]\ttrain-RMSLE:1.22401\ttest-RMSLE:1.23602\n",
      "[18]\ttrain-RMSLE:1.20806+0.00409\ttest-RMSLE:1.22084+0.03730\n",
      "[18]\ttrain-RMSLE:1.20806\ttest-RMSLE:1.22084\n",
      "[19]\ttrain-RMSLE:1.19242+0.00404\ttest-RMSLE:1.20602+0.03681\n",
      "[19]\ttrain-RMSLE:1.19242\ttest-RMSLE:1.20602\n",
      "[20]\ttrain-RMSLE:1.17709+0.00399\ttest-RMSLE:1.19148+0.03634\n",
      "[20]\ttrain-RMSLE:1.17709\ttest-RMSLE:1.19148\n",
      "[21]\ttrain-RMSLE:1.16207+0.00394\ttest-RMSLE:1.17725+0.03587\n",
      "[21]\ttrain-RMSLE:1.16207\ttest-RMSLE:1.17725\n",
      "[22]\ttrain-RMSLE:1.14736+0.00390\ttest-RMSLE:1.16333+0.03537\n",
      "[22]\ttrain-RMSLE:1.14736\ttest-RMSLE:1.16333\n",
      "[23]\ttrain-RMSLE:1.13295+0.00383\ttest-RMSLE:1.14965+0.03489\n",
      "[23]\ttrain-RMSLE:1.13295\ttest-RMSLE:1.14965\n",
      "[24]\ttrain-RMSLE:1.11883+0.00377\ttest-RMSLE:1.13628+0.03446\n",
      "[24]\ttrain-RMSLE:1.11883\ttest-RMSLE:1.13628\n",
      "[25]\ttrain-RMSLE:1.10502+0.00370\ttest-RMSLE:1.12325+0.03397\n",
      "[25]\ttrain-RMSLE:1.10502\ttest-RMSLE:1.12325\n",
      "[26]\ttrain-RMSLE:1.09148+0.00363\ttest-RMSLE:1.11058+0.03342\n",
      "[26]\ttrain-RMSLE:1.09148\ttest-RMSLE:1.11058\n",
      "[27]\ttrain-RMSLE:1.07825+0.00357\ttest-RMSLE:1.09818+0.03294\n",
      "[27]\ttrain-RMSLE:1.07825\ttest-RMSLE:1.09818\n",
      "[28]\ttrain-RMSLE:1.06531+0.00350\ttest-RMSLE:1.08607+0.03245\n",
      "[28]\ttrain-RMSLE:1.06531\ttest-RMSLE:1.08607\n",
      "[29]\ttrain-RMSLE:1.05268+0.00343\ttest-RMSLE:1.07426+0.03197\n",
      "[29]\ttrain-RMSLE:1.05268\ttest-RMSLE:1.07426\n",
      "[30]\ttrain-RMSLE:1.04033+0.00338\ttest-RMSLE:1.06276+0.03151\n",
      "[30]\ttrain-RMSLE:1.04033\ttest-RMSLE:1.06276\n",
      "[31]\ttrain-RMSLE:1.02829+0.00333\ttest-RMSLE:1.05157+0.03105\n",
      "[31]\ttrain-RMSLE:1.02829\ttest-RMSLE:1.05157\n",
      "[32]\ttrain-RMSLE:1.01656+0.00328\ttest-RMSLE:1.04067+0.03062\n",
      "[32]\ttrain-RMSLE:1.01656\ttest-RMSLE:1.04067\n",
      "[33]\ttrain-RMSLE:1.00511+0.00323\ttest-RMSLE:1.03008+0.03021\n",
      "[33]\ttrain-RMSLE:1.00511\ttest-RMSLE:1.03008\n",
      "[34]\ttrain-RMSLE:0.99397+0.00318\ttest-RMSLE:1.01976+0.02979\n",
      "[34]\ttrain-RMSLE:0.99397\ttest-RMSLE:1.01976\n",
      "[35]\ttrain-RMSLE:0.98312+0.00313\ttest-RMSLE:1.00974+0.02937\n",
      "[35]\ttrain-RMSLE:0.98312\ttest-RMSLE:1.00974\n",
      "[36]\ttrain-RMSLE:0.97257+0.00308\ttest-RMSLE:1.00006+0.02894\n",
      "[36]\ttrain-RMSLE:0.97257\ttest-RMSLE:1.00006\n",
      "[37]\ttrain-RMSLE:0.96230+0.00303\ttest-RMSLE:0.99063+0.02856\n",
      "[37]\ttrain-RMSLE:0.96230\ttest-RMSLE:0.99063\n",
      "[38]\ttrain-RMSLE:0.95231+0.00299\ttest-RMSLE:0.98149+0.02820\n",
      "[38]\ttrain-RMSLE:0.95231\ttest-RMSLE:0.98149\n",
      "[39]\ttrain-RMSLE:0.94261+0.00295\ttest-RMSLE:0.97261+0.02784\n",
      "[39]\ttrain-RMSLE:0.94261\ttest-RMSLE:0.97261\n",
      "[40]\ttrain-RMSLE:0.93321+0.00292\ttest-RMSLE:0.96402+0.02754\n",
      "[40]\ttrain-RMSLE:0.93321\ttest-RMSLE:0.96402\n",
      "[41]\ttrain-RMSLE:0.92407+0.00290\ttest-RMSLE:0.95577+0.02724\n",
      "[41]\ttrain-RMSLE:0.92407\ttest-RMSLE:0.95577\n",
      "[42]\ttrain-RMSLE:0.91524+0.00285\ttest-RMSLE:0.94776+0.02698\n",
      "[42]\ttrain-RMSLE:0.91524\ttest-RMSLE:0.94776\n",
      "[43]\ttrain-RMSLE:0.90669+0.00281\ttest-RMSLE:0.94002+0.02675\n",
      "[43]\ttrain-RMSLE:0.90669\ttest-RMSLE:0.94002\n",
      "[44]\ttrain-RMSLE:0.89845+0.00278\ttest-RMSLE:0.93264+0.02648\n",
      "[44]\ttrain-RMSLE:0.89845\ttest-RMSLE:0.93264\n",
      "[45]\ttrain-RMSLE:0.89047+0.00276\ttest-RMSLE:0.92549+0.02628\n",
      "[45]\ttrain-RMSLE:0.89047\ttest-RMSLE:0.92549\n",
      "[46]\ttrain-RMSLE:0.88274+0.00273\ttest-RMSLE:0.91861+0.02595\n",
      "[46]\ttrain-RMSLE:0.88274\ttest-RMSLE:0.91861\n",
      "[47]\ttrain-RMSLE:0.87526+0.00271\ttest-RMSLE:0.91193+0.02570\n",
      "[47]\ttrain-RMSLE:0.87526\ttest-RMSLE:0.91193\n",
      "[48]\ttrain-RMSLE:0.86802+0.00271\ttest-RMSLE:0.90543+0.02539\n",
      "[48]\ttrain-RMSLE:0.86802\ttest-RMSLE:0.90543\n",
      "[49]\ttrain-RMSLE:0.86100+0.00273\ttest-RMSLE:0.89918+0.02507\n",
      "[49]\ttrain-RMSLE:0.86100\ttest-RMSLE:0.89918\n",
      "[50]\ttrain-RMSLE:0.85424+0.00273\ttest-RMSLE:0.89315+0.02479\n",
      "[50]\ttrain-RMSLE:0.85424\ttest-RMSLE:0.89315\n",
      "[51]\ttrain-RMSLE:0.84773+0.00272\ttest-RMSLE:0.88734+0.02448\n",
      "[51]\ttrain-RMSLE:0.84773\ttest-RMSLE:0.88734\n",
      "[52]\ttrain-RMSLE:0.84147+0.00273\ttest-RMSLE:0.88181+0.02427\n",
      "[52]\ttrain-RMSLE:0.84147\ttest-RMSLE:0.88181\n",
      "[53]\ttrain-RMSLE:0.83545+0.00272\ttest-RMSLE:0.87648+0.02409\n",
      "[53]\ttrain-RMSLE:0.83545\ttest-RMSLE:0.87648\n",
      "[54]\ttrain-RMSLE:0.82967+0.00270\ttest-RMSLE:0.87139+0.02397\n",
      "[54]\ttrain-RMSLE:0.82967\ttest-RMSLE:0.87139\n",
      "[55]\ttrain-RMSLE:0.82410+0.00270\ttest-RMSLE:0.86649+0.02383\n",
      "[55]\ttrain-RMSLE:0.82410\ttest-RMSLE:0.86649\n",
      "[56]\ttrain-RMSLE:0.81871+0.00269\ttest-RMSLE:0.86179+0.02375\n",
      "[56]\ttrain-RMSLE:0.81871\ttest-RMSLE:0.86179\n",
      "[57]\ttrain-RMSLE:0.81360+0.00263\ttest-RMSLE:0.85730+0.02371\n",
      "[57]\ttrain-RMSLE:0.81360\ttest-RMSLE:0.85730\n",
      "[58]\ttrain-RMSLE:0.80862+0.00256\ttest-RMSLE:0.85296+0.02364\n",
      "[58]\ttrain-RMSLE:0.80862\ttest-RMSLE:0.85296\n",
      "[59]\ttrain-RMSLE:0.80383+0.00256\ttest-RMSLE:0.84880+0.02359\n",
      "[59]\ttrain-RMSLE:0.80383\ttest-RMSLE:0.84880\n",
      "[60]\ttrain-RMSLE:0.79923+0.00252\ttest-RMSLE:0.84481+0.02350\n",
      "[60]\ttrain-RMSLE:0.79923\ttest-RMSLE:0.84481\n",
      "[61]\ttrain-RMSLE:0.79486+0.00248\ttest-RMSLE:0.84099+0.02353\n",
      "[61]\ttrain-RMSLE:0.79486\ttest-RMSLE:0.84099\n",
      "[62]\ttrain-RMSLE:0.79070+0.00245\ttest-RMSLE:0.83739+0.02350\n",
      "[62]\ttrain-RMSLE:0.79070\ttest-RMSLE:0.83739\n",
      "[63]\ttrain-RMSLE:0.78673+0.00244\ttest-RMSLE:0.83394+0.02349\n",
      "[63]\ttrain-RMSLE:0.78673\ttest-RMSLE:0.83394\n",
      "[64]\ttrain-RMSLE:0.78290+0.00243\ttest-RMSLE:0.83064+0.02354\n",
      "[64]\ttrain-RMSLE:0.78290\ttest-RMSLE:0.83064\n",
      "[65]\ttrain-RMSLE:0.77927+0.00242\ttest-RMSLE:0.82755+0.02358\n",
      "[65]\ttrain-RMSLE:0.77927\ttest-RMSLE:0.82755\n",
      "[66]\ttrain-RMSLE:0.77578+0.00245\ttest-RMSLE:0.82454+0.02357\n",
      "[66]\ttrain-RMSLE:0.77578\ttest-RMSLE:0.82454\n",
      "[67]\ttrain-RMSLE:0.77248+0.00245\ttest-RMSLE:0.82173+0.02364\n",
      "[67]\ttrain-RMSLE:0.77248\ttest-RMSLE:0.82173\n",
      "[68]\ttrain-RMSLE:0.76932+0.00245\ttest-RMSLE:0.81910+0.02369\n",
      "[68]\ttrain-RMSLE:0.76932\ttest-RMSLE:0.81910\n",
      "[69]\ttrain-RMSLE:0.76633+0.00244\ttest-RMSLE:0.81657+0.02373\n",
      "[69]\ttrain-RMSLE:0.76633\ttest-RMSLE:0.81657\n",
      "[70]\ttrain-RMSLE:0.76347+0.00249\ttest-RMSLE:0.81423+0.02379\n",
      "[70]\ttrain-RMSLE:0.76347\ttest-RMSLE:0.81423\n",
      "[71]\ttrain-RMSLE:0.76078+0.00250\ttest-RMSLE:0.81197+0.02385\n",
      "[71]\ttrain-RMSLE:0.76078\ttest-RMSLE:0.81197\n",
      "[72]\ttrain-RMSLE:0.75823+0.00253\ttest-RMSLE:0.80986+0.02389\n",
      "[72]\ttrain-RMSLE:0.75823\ttest-RMSLE:0.80986\n",
      "[73]\ttrain-RMSLE:0.75571+0.00255\ttest-RMSLE:0.80783+0.02403\n",
      "[73]\ttrain-RMSLE:0.75571\ttest-RMSLE:0.80783\n",
      "[74]\ttrain-RMSLE:0.75340+0.00256\ttest-RMSLE:0.80601+0.02404\n",
      "[74]\ttrain-RMSLE:0.75340\ttest-RMSLE:0.80601\n",
      "[75]\ttrain-RMSLE:0.75120+0.00259\ttest-RMSLE:0.80426+0.02415\n",
      "[75]\ttrain-RMSLE:0.75120\ttest-RMSLE:0.80426\n",
      "[76]\ttrain-RMSLE:0.74918+0.00266\ttest-RMSLE:0.80270+0.02416\n",
      "[76]\ttrain-RMSLE:0.74918\ttest-RMSLE:0.80270\n",
      "[77]\ttrain-RMSLE:0.74718+0.00270\ttest-RMSLE:0.80121+0.02425\n",
      "[77]\ttrain-RMSLE:0.74718\ttest-RMSLE:0.80121\n",
      "[78]\ttrain-RMSLE:0.74532+0.00280\ttest-RMSLE:0.79983+0.02425\n",
      "[78]\ttrain-RMSLE:0.74532\ttest-RMSLE:0.79983\n",
      "[79]\ttrain-RMSLE:0.74362+0.00284\ttest-RMSLE:0.79861+0.02433\n",
      "[79]\ttrain-RMSLE:0.74362\ttest-RMSLE:0.79861\n",
      "[80]\ttrain-RMSLE:0.74203+0.00290\ttest-RMSLE:0.79744+0.02444\n",
      "[80]\ttrain-RMSLE:0.74203\ttest-RMSLE:0.79744\n",
      "[81]\ttrain-RMSLE:0.74052+0.00293\ttest-RMSLE:0.79633+0.02455\n",
      "[81]\ttrain-RMSLE:0.74052\ttest-RMSLE:0.79633\n",
      "[82]\ttrain-RMSLE:0.73906+0.00302\ttest-RMSLE:0.79529+0.02467\n",
      "[82]\ttrain-RMSLE:0.73906\ttest-RMSLE:0.79529\n",
      "[83]\ttrain-RMSLE:0.73768+0.00303\ttest-RMSLE:0.79423+0.02481\n",
      "[83]\ttrain-RMSLE:0.73768\ttest-RMSLE:0.79423\n",
      "[84]\ttrain-RMSLE:0.73635+0.00302\ttest-RMSLE:0.79325+0.02485\n",
      "[84]\ttrain-RMSLE:0.73635\ttest-RMSLE:0.79325\n",
      "[85]\ttrain-RMSLE:0.73501+0.00292\ttest-RMSLE:0.79231+0.02507\n",
      "[85]\ttrain-RMSLE:0.73501\ttest-RMSLE:0.79231\n",
      "[86]\ttrain-RMSLE:0.73383+0.00296\ttest-RMSLE:0.79146+0.02520\n",
      "[86]\ttrain-RMSLE:0.73383\ttest-RMSLE:0.79146\n",
      "[87]\ttrain-RMSLE:0.73273+0.00297\ttest-RMSLE:0.79066+0.02532\n",
      "[87]\ttrain-RMSLE:0.73273\ttest-RMSLE:0.79066\n",
      "[88]\ttrain-RMSLE:0.73169+0.00303\ttest-RMSLE:0.79000+0.02539\n",
      "[88]\ttrain-RMSLE:0.73169\ttest-RMSLE:0.79000\n",
      "[89]\ttrain-RMSLE:0.73075+0.00302\ttest-RMSLE:0.78941+0.02557\n",
      "[89]\ttrain-RMSLE:0.73075\ttest-RMSLE:0.78941\n",
      "[90]\ttrain-RMSLE:0.72985+0.00306\ttest-RMSLE:0.78895+0.02568\n",
      "[90]\ttrain-RMSLE:0.72985\ttest-RMSLE:0.78895\n",
      "[91]\ttrain-RMSLE:0.72896+0.00306\ttest-RMSLE:0.78842+0.02574\n",
      "[91]\ttrain-RMSLE:0.72896\ttest-RMSLE:0.78842\n",
      "[92]\ttrain-RMSLE:0.72816+0.00309\ttest-RMSLE:0.78798+0.02586\n",
      "[92]\ttrain-RMSLE:0.72816\ttest-RMSLE:0.78798\n",
      "[93]\ttrain-RMSLE:0.72742+0.00307\ttest-RMSLE:0.78766+0.02604\n",
      "[93]\ttrain-RMSLE:0.72742\ttest-RMSLE:0.78766\n",
      "[94]\ttrain-RMSLE:0.72670+0.00305\ttest-RMSLE:0.78731+0.02621\n",
      "[94]\ttrain-RMSLE:0.72670\ttest-RMSLE:0.78731\n",
      "[95]\ttrain-RMSLE:0.72603+0.00306\ttest-RMSLE:0.78701+0.02635\n",
      "[95]\ttrain-RMSLE:0.72603\ttest-RMSLE:0.78701\n",
      "[96]\ttrain-RMSLE:0.72539+0.00311\ttest-RMSLE:0.78680+0.02646\n",
      "[96]\ttrain-RMSLE:0.72539\ttest-RMSLE:0.78680\n",
      "[97]\ttrain-RMSLE:0.72481+0.00311\ttest-RMSLE:0.78671+0.02657\n",
      "[97]\ttrain-RMSLE:0.72481\ttest-RMSLE:0.78671\n",
      "[98]\ttrain-RMSLE:0.72429+0.00309\ttest-RMSLE:0.78649+0.02665\n",
      "[98]\ttrain-RMSLE:0.72429\ttest-RMSLE:0.78649\n",
      "[99]\ttrain-RMSLE:0.72378+0.00308\ttest-RMSLE:0.78635+0.02675\n",
      "[99]\ttrain-RMSLE:0.72378\ttest-RMSLE:0.78635\n",
      "[100]\ttrain-RMSLE:0.72330+0.00310\ttest-RMSLE:0.78620+0.02680\n",
      "[100]\ttrain-RMSLE:0.72330\ttest-RMSLE:0.78620\n",
      "[101]\ttrain-RMSLE:0.72287+0.00309\ttest-RMSLE:0.78619+0.02683\n",
      "[101]\ttrain-RMSLE:0.72287\ttest-RMSLE:0.78619\n",
      "[102]\ttrain-RMSLE:0.72248+0.00314\ttest-RMSLE:0.78621+0.02682\n",
      "[102]\ttrain-RMSLE:0.72248\ttest-RMSLE:0.78621\n",
      "[103]\ttrain-RMSLE:0.72211+0.00314\ttest-RMSLE:0.78617+0.02690\n",
      "[103]\ttrain-RMSLE:0.72211\ttest-RMSLE:0.78617\n",
      "[104]\ttrain-RMSLE:0.72182+0.00316\ttest-RMSLE:0.78615+0.02698\n",
      "[104]\ttrain-RMSLE:0.72182\ttest-RMSLE:0.78615\n",
      "[105]\ttrain-RMSLE:0.72148+0.00314\ttest-RMSLE:0.78611+0.02704\n",
      "[105]\ttrain-RMSLE:0.72148\ttest-RMSLE:0.78611\n",
      "[106]\ttrain-RMSLE:0.72120+0.00315\ttest-RMSLE:0.78615+0.02703\n",
      "[106]\ttrain-RMSLE:0.72120\ttest-RMSLE:0.78615\n",
      "[107]\ttrain-RMSLE:0.72086+0.00317\ttest-RMSLE:0.78611+0.02707\n",
      "[107]\ttrain-RMSLE:0.72086\ttest-RMSLE:0.78611\n",
      "[108]\ttrain-RMSLE:0.72054+0.00319\ttest-RMSLE:0.78608+0.02709\n",
      "[108]\ttrain-RMSLE:0.72054\ttest-RMSLE:0.78608\n",
      "[109]\ttrain-RMSLE:0.72024+0.00321\ttest-RMSLE:0.78610+0.02712\n",
      "[109]\ttrain-RMSLE:0.72024\ttest-RMSLE:0.78610\n",
      "[110]\ttrain-RMSLE:0.71998+0.00322\ttest-RMSLE:0.78611+0.02713\n",
      "[110]\ttrain-RMSLE:0.71998\ttest-RMSLE:0.78611\n",
      "[111]\ttrain-RMSLE:0.71973+0.00322\ttest-RMSLE:0.78615+0.02711\n",
      "[111]\ttrain-RMSLE:0.71973\ttest-RMSLE:0.78615\n",
      "[112]\ttrain-RMSLE:0.71950+0.00326\ttest-RMSLE:0.78615+0.02712\n",
      "[112]\ttrain-RMSLE:0.71950\ttest-RMSLE:0.78615\n",
      "[113]\ttrain-RMSLE:0.71929+0.00331\ttest-RMSLE:0.78620+0.02714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# # check if there already exists a model.\n",
    "# if os.path.exists(model_to_load):\n",
    "#     print(\"\\nModel found, attempting to load.\")\n",
    "#     model = xgb.Booster({'nthread': 4, 'disable_default_eval_metric': True})  # init model\n",
    "#     model.load_model(model_to_load)  # load data\n",
    "#     print(\"--> model successfully loaded.\")\n",
    "# else:\n",
    "print(\"\\nNo model found. Attempt at creating a new one will now start:\")\n",
    "print(\"Attempting to initialize parameters for training...\")\n",
    "params = {\n",
    "    'max_depth': 9, \n",
    "    'eta': 0.05, \n",
    "    'min_child_weight': 7,\n",
    "    'disable_default_eval_metric': True,\n",
    "}\n",
    "num_round = 999\n",
    "\n",
    "# xgbmodel = XGBClassifier()\n",
    "# kfold = KFold(n_splits=5,shuffle=True, random_state=420)\n",
    "# xgb_clf = RandomizedSearchCV(xgbmodel, param_distributions=param, n_iter=100, )\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "# print(\"--> parameters for training initialized.\")\n",
    "\n",
    "# print(\"Attempting to start training...\")\n",
    "# bst = xgb.train(\n",
    "#     params=params, \n",
    "#     dtrain=dtrain, \n",
    "#     num_boost_round=num_round, \n",
    "#     obj=squared_log,\n",
    "#     custom_metric=rmsle,\n",
    "#     evals=watchlist, \n",
    "#     early_stopping_rounds=10, \n",
    "#     verbose_eval=5)\n",
    "# print(\"--> model trained.\")\n",
    "\n",
    "# print(\"Attempting to save model...\")\n",
    "# bst.save_model(model_to_load)\n",
    "# print(\"--> model saved.\")\n",
    "\n",
    "print(\"Starting k-fold cross validaition...\")\n",
    "xgb_param = xgb.cv(params, dtrain, num_boost_round=200, nfold=10, seed=420, obj=squared_log, \n",
    "                custom_metric=rmsle, verbose_eval=True, \n",
    "                callbacks=[xgb.callback.EvaluationMonitor(show_stdv=False),\n",
    "                           xgb.callback.EarlyStopping(5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\\RMSLE 0.765178 for 21 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\\RMSLE 0.7640579999999999 for 22 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\\RMSLE 0.7630676000000001 for 22 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\\RMSLE 0.7687875999999999 for 21 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\\RMSLE 0.766042 for 21 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\\RMSLE 0.7636806 for 23 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\\RMSLE 0.7707318 for 22 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\\RMSLE 0.7708202 for 23 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\\RMSLE 0.7668524 for 22 rounds\n",
      "Best params: 9, 7, RMSLE: 0.7630676000000001\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9, 12)\n",
    "    for min_child_weight in range(5, 8)\n",
    "]\n",
    "\n",
    "min_rmsle = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "        max_depth,\n",
    "        min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=100,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        custom_metric=rmsle,\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_rmsle = cv_results['test-RMSLE-mean'].min()\n",
    "    boost_rounds = cv_results['test-RMSLE-mean'].argmin()\n",
    "    print(\"\\tRMSLE {} for {} rounds\".format(mean_rmsle, boost_rounds))\n",
    "    if mean_rmsle < min_rmsle:\n",
    "        min_rmsle = mean_rmsle\n",
    "        best_params = (max_depth, min_child_weight)\n",
    "print(\"Best params: {}, {}, RMSLE: {}\".format(best_params[0], best_params[1], min_rmsle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'eta': 0.05, 'min_child_weight': 5}\n",
      "\tRMSLE 0.765178 for 21 rounds \t(New best)\n",
      "{'max_depth': 9, 'eta': 0.05, 'min_child_weight': 6}\n",
      "\tRMSLE 0.7640579999999999 for 22 rounds \t(New best)\n",
      "{'max_depth': 9, 'eta': 0.05, 'min_child_weight': 7}\n",
      "\tRMSLE 0.7630676000000001 for 22 rounds \t(New best)\n",
      "{'max_depth': 9, 'eta': 0.1, 'min_child_weight': 5}\n",
      "\tRMSLE 0.7667822 for 10 rounds \t\n",
      "{'max_depth': 9, 'eta': 0.1, 'min_child_weight': 6}\n",
      "\tRMSLE 0.765438 for 10 rounds \t\n",
      "{'max_depth': 9, 'eta': 0.1, 'min_child_weight': 7}\n",
      "\tRMSLE 0.7644392 for 10 rounds \t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45032/1131912927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mxgb_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45032/1131912927.py\u001b[0m in \u001b[0;36mxgb_cross_validation\u001b[1;34m(param_lists, dtrain, num_boost_round, nfold, metric, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproduct_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam_lists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# Run CV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         cv_results = xgb.cv(\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle, custom_metric)\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[0mshould_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, obj)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;34m'''Iterate through folds for update'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1779\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import xgb_cross_validation\n",
    "\n",
    "params = {\n",
    "    'max_depth': range(9, 12),\n",
    "    'eta': [0.05, 0.1, 0.2, 0.3],\n",
    "    'min_child_weight': range(5, 8),\n",
    "    # 'disable_default_eval_metric': True,\n",
    "}\n",
    "\n",
    "xgb_cross_validation(params, dtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 9, 'eta': 0.05, 'min_child_weight': 7},\n",
       " {'max_depth': 9, 'eta': 0.05, 'min_child_weight': 11},\n",
       " {'max_depth': 9, 'eta': 0.05, 'min_child_weight': 33},\n",
       " {'max_depth': 10, 'eta': 0.05, 'min_child_weight': 7},\n",
       " {'max_depth': 10, 'eta': 0.05, 'min_child_weight': 11},\n",
       " {'max_depth': 10, 'eta': 0.05, 'min_child_weight': 33},\n",
       " {'max_depth': 11, 'eta': 0.05, 'min_child_weight': 7},\n",
       " {'max_depth': 11, 'eta': 0.05, 'min_child_weight': 11},\n",
       " {'max_depth': 11, 'eta': 0.05, 'min_child_weight': 33}]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "params = {\n",
    "    'max_depth': [9, 10, 11],\n",
    "    'eta': [0.05],\n",
    "    'min_child_weight': [7, 11, 33],\n",
    "    # 'disable_default_eval_metric': True,\n",
    "}\n",
    "\n",
    "def product_dict(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    vals = kwargs.values()\n",
    "    lst = []\n",
    "    for instance in itertools.product(*vals):\n",
    "        # yield dict(zip(keys, instance))\n",
    "        lst.append(dict(zip(keys, instance)))\n",
    "    return lst\n",
    "\n",
    "\n",
    "product_dict(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.3\n",
      "\tMAE 0.7847501999999998 for 2 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "\tMAE 0.7792326 for 4 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "\tMAE 0.7743976 for 11 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "\tMAE 0.7719683999999999 for 25 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "\tMAE 0.7767526 for 99 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "\tMAE 0.8555772000000001 for 99 rounds\n",
      "\n",
      "Best params: 0.05, RMSLE: 0.7719683999999999\n"
     ]
    }
   ],
   "source": [
    "# This can take some timeâ€¦\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=100,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        custom_metric=rmsle,\n",
    "        # verbose_eval=True,\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-RMSLE-mean'].min()\n",
    "    boost_rounds = cv_results['test-RMSLE-mean'].argmin()\n",
    "    print(\"\\tRMSLE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "\n",
    "print(\"Best params: {}, RMSLE: {}\".format(best_params, min_mae))\n",
    "\n",
    "\n",
    "# print(\"Starting k-fold cross validaition...\")\n",
    "# xgb_param = xgb.cv(params, dtrain, num_boost_round=100, nfold=10, seed=0, obj=squared_log,\n",
    "#                    custom_metric=rmsle, verbose_eval=True,\n",
    "#                    callbacks=[xgb.callback.EvaluationMonitor(show_stdv=False),\n",
    "#                               xgb.callback.EarlyStopping(3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to start prediction...\n",
      "--> Prediction finished.\n",
      "\n",
      "Attempting to save prediction...\n",
      "--> prediction saved with features as name in submission folder.\n"
     ]
    }
   ],
   "source": [
    "X_test = generate_features(test)\n",
    "dtest = xgb.DMatrix(data=X_test, enable_categorical=True)\n",
    "\n",
    "print(\"\\nAttempting to start prediction...\")\n",
    "y_pred = bst.predict(dtest, ntree_limit=bst.best_iteration)\n",
    "print(\"--> Prediction finished.\")\n",
    "\n",
    "print(\"\\nAttempting to save prediction...\")\n",
    "submission['predicted'] = np.array(y_pred)\n",
    "submission.to_csv('submissions/submission.csv', index=False)\n",
    "print(\"--> prediction saved with features as name in submission folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[17:49:29] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\c_api\\c_api_utils.h:222: Check failed: feature_names.size() == n_features (34 vs. 36) : Incorrect number of feature names.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45032/3892230781.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_trees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# fig, ax = plt.subplots(figsize=(30, 30))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\plotting.py\u001b[0m in \u001b[0;36mplot_importance\u001b[1;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m             importance_type=importance_type, fmap=fmap)\n\u001b[0;32m     66\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mimportance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mimportance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mget_score\u001b[1;34m(self, fmap, importance_type)\u001b[0m\n\u001b[0;32m   2462\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2464\u001b[1;33m         _check_call(\n\u001b[0m\u001b[0;32m   2465\u001b[0m             _LIB.XGBoosterFeatureScore(\n\u001b[0;32m   2466\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \"\"\"\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [17:49:29] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\c_api\\c_api_utils.h:222: Check failed: feature_names.size() == n_features (34 vs. 36) : Incorrect number of feature names."
     ]
    }
   ],
   "source": [
    "from xgboost import plot_tree\n",
    "\n",
    "plot_importance(model)\n",
    "xgb.to_graphviz(model, num_trees=1)\n",
    "# fig, ax = plt.subplots(figsize=(30, 30))\n",
    "# xgb.plot_tree(bst, num_trees=1, ax=ax)\n",
    "# plt.savefig(\"temp.pdf\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "882a6b7fc3ca80e688227decd54209862062b8721a918d514e0ed60576137ba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
