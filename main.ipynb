{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==2.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: attrs==22.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (22.1.0)\n",
      "Requirement already satisfied: autopep8==2.0.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: catboost==1.1.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: certifi==2022.9.24 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (2022.9.24)\n",
      "Requirement already satisfied: click==8.1.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: click-plugins==1.1.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: cligj==0.7.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: colorama==0.4.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: contourpy==1.0.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (1.0.6)\n",
      "Requirement already satisfied: cycler==0.11.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.11.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (0.29.28)\n",
      "Requirement already satisfied: debugpy==1.6.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (1.6.3)\n",
      "Requirement already satisfied: decorator==5.1.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (5.1.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: executing==1.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: Fiona==1.8.22 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (1.8.22)\n",
      "Requirement already satisfied: fonttools==4.38.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 19)) (4.38.0)\n",
      "Requirement already satisfied: gensim==4.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 20)) (4.2.0)\n",
      "Requirement already satisfied: geographiclib==1.52 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 21)) (1.52)\n",
      "Requirement already satisfied: geopandas==0.12.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 22)) (0.12.1)\n",
      "Requirement already satisfied: geopy==2.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 23)) (2.2.0)\n",
      "Requirement already satisfied: graphviz==0.20.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 24)) (0.20.1)\n",
      "Requirement already satisfied: ipykernel==6.17.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 25)) (6.17.0)\n",
      "Requirement already satisfied: ipython==8.6.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 26)) (8.6.0)\n",
      "Requirement already satisfied: jedi==0.18.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 27)) (0.18.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 28)) (1.2.0)\n",
      "Requirement already satisfied: jupyter_client==7.4.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 29)) (7.4.4)\n",
      "Requirement already satisfied: jupyter_core==4.11.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 30)) (4.11.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 31)) (1.4.4)\n",
      "Requirement already satisfied: matplotlib==3.6.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 32)) (3.6.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 33)) (0.1.6)\n",
      "Requirement already satisfied: munch==2.5.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 34)) (2.5.0)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 35)) (1.5.6)\n",
      "Requirement already satisfied: numpy==1.23.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 36)) (1.23.4)\n",
      "Requirement already satisfied: packaging==21.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 37)) (21.3)\n",
      "Requirement already satisfied: pandas==1.5.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 38)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 39)) (0.8.3)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 40)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==9.3.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 41)) (9.3.0)\n",
      "Requirement already satisfied: plotly==5.11.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 42)) (5.11.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.31 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 43)) (3.0.31)\n",
      "Requirement already satisfied: psutil==5.9.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 44)) (5.9.3)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 45)) (0.2.2)\n",
      "Requirement already satisfied: pyarrow==10.0.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 46)) (10.0.0)\n",
      "Requirement already satisfied: pycodestyle==2.9.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 47)) (2.9.1)\n",
      "Requirement already satisfied: pygeos==0.13 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 48)) (0.13)\n",
      "Requirement already satisfied: Pygments==2.13.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 49)) (2.13.0)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 50)) (3.0.9)\n",
      "Requirement already satisfied: pyproj==3.4.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 51)) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 52)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 53)) (2022.6)\n",
      "Requirement already satisfied: pyzmq==24.0.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 54)) (24.0.1)\n",
      "Requirement already satisfied: scikit-learn==1.1.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 55)) (1.1.3)\n",
      "Requirement already satisfied: scipy==1.9.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 56)) (1.9.3)\n",
      "Requirement already satisfied: seaborn==0.12.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 57)) (0.12.1)\n",
      "Requirement already satisfied: Shapely==1.8.5.post1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 58)) (1.8.5.post1)\n",
      "Requirement already satisfied: six==1.16.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 59)) (1.16.0)\n",
      "Requirement already satisfied: sklearn==0.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 60)) (0.0)\n",
      "Requirement already satisfied: smart-open==6.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 61)) (6.2.0)\n",
      "Requirement already satisfied: stack-data==0.6.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 62)) (0.6.0)\n",
      "Requirement already satisfied: tenacity==8.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 63)) (8.1.0)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 64)) (3.1.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 65)) (2.0.1)\n",
      "Requirement already satisfied: tornado==6.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 66)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.64.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 67)) (4.64.1)\n",
      "Requirement already satisfied: traitlets==5.5.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 68)) (5.5.0)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 69)) (0.2.5)\n",
      "Requirement already satisfied: xgboost==1.7.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 70)) (1.7.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.8/site-packages (from Fiona==1.8.22->-r requirements.txt (line 18)) (44.0.0)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in ./venv/lib/python3.8/site-packages (from ipython==8.6.0->-r requirements.txt (line 26)) (4.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython==8.6.0->-r requirements.txt (line 26)) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import warnings\n",
    "import os.path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import shutil\n",
    "import geopandas as gpd\n",
    "import catboost as cb\n",
    "import optuna\n",
    "\n",
    "from xgboost import XGBRegressor, plot_importance, to_graphviz, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "from k_fold import random_k_fold\n",
    "from shapely import wkt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from utils import squared_log, rmsle_xgb, add_city_centre_dist, group_ages, to_categorical, nan_to_string, object_encoder\n",
    "from k_fold import random_k_fold, xgb_cross_validation\n",
    "from objectives_and_metrics import rmsle, RmsleMetric, RmsleObjective, LogTargetsRmsleMetric, RmseObjective\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "spatial = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "age = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "income = pd.read_csv('data/grunnkrets_income_households.csv').set_index(['grunnkrets_id', 'year']).add_prefix('income_').reset_index()\n",
    "households = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "plaace = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "\n",
    "\n",
    "train = pd.read_csv('data/stores_train.csv')\n",
    "test = pd.read_csv('data/stores_test.csv') \n",
    "\n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "model_name = \"modeling/0002.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df: pd.DataFrame, min_val=0, max_val=100):\n",
    "    print('Length of data frame:', len(df))\n",
    "    df = df[(df.revenue > min_val) & (df.revenue < max_val)]\n",
    "    print('Length after removing extreme values and zero revenue retail stores:',  len(df))\n",
    "    plt.hist(np.log1p(train.revenue), 30)\n",
    "    plt.show()\n",
    "    return df.drop(columns=['revenue']), df.revenue\n",
    "\n",
    "\n",
    "label_name = 'revenue'\n",
    "X = train.drop(columns=[label_name])\n",
    "y = np.log1p(train[label_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df: pd.DataFrame, predictor: str = ''):\n",
    "    age_ranges = [\n",
    "        (0, 19),\n",
    "        (20, 39),\n",
    "        (40, 59),\n",
    "        (60, 79),\n",
    "        (80, 90),\n",
    "    ]\n",
    "    \n",
    "    # Define datasets to be merged\n",
    "    spatial_merge = spatial.drop(columns=['year']).drop_duplicates(subset=['grunnkrets_id'])\n",
    "    age_groups_merge = group_ages(age, age_ranges)\n",
    "    income_merge = income.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    households_merge = households.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    plaace_merge = plaace.drop_duplicates(subset='plaace_hierarchy_id')\n",
    "    bus_data_train_merge = gpd.read_parquet('derived_data/stores_bus_stops_lt_1km_train').drop(columns=['geometry'])\n",
    "    stores_vicinity_merge = gpd.read_parquet('derived_data/stores_count_lt_1km_train').drop(columns=['geometry'])\n",
    "\n",
    "    # Merge datasets\n",
    "    df = df.merge(spatial_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(age_groups_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(income_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(households_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(plaace_merge, how='left')\n",
    "    df = df.merge(bus_data_train_merge, on='store_id', how='left')\n",
    "    df = df.merge(stores_vicinity_merge, on='store_id', how='left')\n",
    "    df = add_city_centre_dist(df).drop(columns=['lon_center', 'lat_center'])\n",
    "\n",
    "    # Transformations\n",
    "    df.stores_count_lt_1km = df.stores_count_lt_1km.apply(np.log)\n",
    "\n",
    "    # Handle categories for different predictors\n",
    "    if predictor == 'xgb':\n",
    "        # df = to_categorical(df)\n",
    "        df = object_encoder(df)\n",
    "    elif predictor == 'catboost':\n",
    "        df = nan_to_string(df)\n",
    "    else: \n",
    "        raise ValueError('Invalid predictor')\n",
    "\n",
    "    features = [\n",
    "        'store_name', \n",
    "        'mall_name', \n",
    "        'chain_name',\n",
    "        # 'address', \n",
    "        'lat', 'lon',\n",
    "        \n",
    "        *age_groups_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *income_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *households_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        'lv1_desc', 'lv2_desc', # 'sales_channel_name', \n",
    "        *bus_data_train_merge.drop(columns=['store_id']).columns,\n",
    "        *stores_vicinity_merge.drop(columns=['store_id']).columns,\n",
    "        'dist_to_center'\n",
    "    ]\n",
    "\n",
    "    return df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(data):\n",
    "  df = data[['revenue', \n",
    "    # 'age_0_19', 'age_20_39', 'age_40_59', 'age_60_79', 'age_80_90', \n",
    "    # 'bus_stops_count', 'Mangler viktighetsnivÃ¥', 'Standard holdeplass', 'Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt', 'Annen viktig holdeplass', \n",
    "    'dist_to_center', 'lat','lon'\n",
    "    ]]\n",
    "  df['knutepunkt'] = data[['Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt']].sum(axis=1)\n",
    "  # df.revenue = np.exp(df.revenue)\n",
    "  # df.bus_stops_count = np.sqrt(df.bus_stops_count)\n",
    "  df = df[df.dist_to_center < 70_000]\n",
    "  # df.dist_to_center = np.log(df.dist_to_center)\n",
    "  \n",
    "  plt.figure(figsize=(15, 15))\n",
    "  pairplot = sns.pairplot(df)\n",
    "  # heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)\n",
    "\n",
    "\n",
    "# data_full =  pd.merge(X_train, y_train, left_index=True, right_index=True) \n",
    "# plot_corr(data_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_buffers(X_train, y_train, X_val, y_val):\n",
    "    # Clear buffers\n",
    "    folder = os.path.join(os.getcwd(), 'modeling')\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "            print(f'Deleted file: {file_path}')\n",
    "\n",
    "    train_buffer_path = 'modeling/train.buffer'\n",
    "    test_buffer_path = 'modeling/test.buffer'\n",
    "\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train, enable_categorical=True)\n",
    "    dtrain.save_binary(train_buffer_path)\n",
    "    print(f'--> {train_buffer_path} created and saved.')\n",
    "\n",
    "    dvalid = xgb.DMatrix(data=X_val, label=y_val, enable_categorical=True)\n",
    "    dvalid.save_binary(test_buffer_path)\n",
    "    print(f'--> {test_buffer_path} created and saved.')\n",
    "\n",
    "    return dtrain, dvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.best_score_)\n",
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(rmsle(y_train, y_pred_train))\n",
    "# print(rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model(X_train, y_train, X_val, y_val):\n",
    "    params = {'colsample_bytree': 0.7717138210314867, 'learning_rate': 0.047506668950627134, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 223, 'subsample': 0.9929036803032936}\n",
    "    print('Clearing and creating buffers...')\n",
    "    dtrain, dvalid = clear_buffers(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    rand_search_model = random_k_fold(X_train, y_train, verbose=1, n_iter=100)\n",
    "    model = rand_search_model\n",
    "    params = model.best_params_\n",
    "    print(rand_search_model.best_score_, params)\n",
    "    \n",
    "    # params = {'colsample_bytree': 0.8601277878899238, 'eval_metric': 'rmsle', 'gamma': 0.12760202929262826, 'learning_rate': 0.07356461924449906, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 306, 'objective': 'reg:squaredlogerror', 'subsample': 0.8993341396761092}\n",
    "    \n",
    "    params['disable_default_eval_metric'] = True\n",
    "    # model = XGBRegressor()\n",
    "    # model.set_params(**params)\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred_train = model.predict(X_train)\n",
    "    # y_pred_val = model.predict(X_val)\n",
    "    # print(rmsle(y_train, y_pred_train))\n",
    "    # print(rmsle(y_val, y_pred_val))\n",
    "\n",
    "    # num_round = 999\n",
    "    # watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "    # print(\"Attempting to start training...\")\n",
    "    # model = xgb.train(\n",
    "    #     params=params, \n",
    "    #     dtrain=dtrain, \n",
    "    #     num_boost_round=num_round, \n",
    "    #     evals=watchlist, \n",
    "    #     early_stopping_rounds=10, \n",
    "    #     verbose_eval=20)\n",
    "    # print(\"--> model trained.\")\n",
    "    # print('Best score:', model.best_score)\n",
    "\n",
    "    # print(\"Attempting to save model...\")\n",
    "    # model.save_model(model_name)\n",
    "    # print(\"--> model saved.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "# X_train, X_val = generate_features(X_train, predictor='xgb'), generate_features(X_val, predictor='xgb')\n",
    "\n",
    "# model = train_xgb_model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(rmsle(y_train, y_pred_train))\n",
    "# print(rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_prediction(X_test, model):\n",
    "    dtest = xgb.DMatrix(data=X_test, enable_categorical=True)\n",
    "\n",
    "    print(\"\\nAttempting to start prediction...\")\n",
    "    y_pred = model.predict(dtest, ntree_limit=model.best_iteration)\n",
    "    print(\"--> Prediction finished.\")\n",
    "\n",
    "    print(\"\\nAttempting to save prediction...\")\n",
    "    submission['predicted'] = np.array(y_pred)\n",
    "    submission.to_csv('submissions/submission.csv', index=False)\n",
    "    print(\"--> prediction saved with features as name in submission folder.\")\n",
    "\n",
    "\n",
    "# X_test = generate_features(test, predictor='xgb')\n",
    "# xgb_prediction(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = model.best_estimator_ if model.best_estimator_ is not None else model\n",
    "# xgb_model = model\n",
    "# plot_importance(xgb_model)\n",
    "# xgb.to_graphviz(xgb_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features for Catboost predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "# X_train, y_train = clean(pd.merge(X_train, y_train, left_index=True, right_index=True))\n",
    "\n",
    "X_train, X_val = generate_features(X_train, predictor='catboost'), generate_features(X_val, predictor='catboost')\n",
    "X_test = generate_features(test, predictor='catboost')\n",
    "\n",
    "# auxillary_columns = ['address']\n",
    "text_features = ['store_name', 'address']\n",
    "cat_features = ['mall_name', 'chain_name', 'lv1_desc', 'lv2_desc']\n",
    "\n",
    "train_pool = cb.Pool(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")\n",
    "\n",
    "valid_pool = cb.Pool(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-08 13:47:54,152]\u001b[0m A new study created in memory with name: catboost-tuning\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73094a1dcbb4de88b289efbee863d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-08 13:48:01,040]\u001b[0m Trial 0 finished with value: 0.7585999404434786 and parameters: {'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.7161555362368563}. Best is trial 0 with value: 0.7585999404434786.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:48:02,897]\u001b[0m Trial 1 finished with value: 0.7763539411493736 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.7585999404434786.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:48:12,865]\u001b[0m Trial 2 finished with value: 0.7592575016730437 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.7509522044690908}. Best is trial 0 with value: 0.7585999404434786.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:48:15,784]\u001b[0m Trial 3 finished with value: 0.7750021957784125 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.7585999404434786.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:48:24,735]\u001b[0m Trial 4 finished with value: 0.7599028707322828 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.2366220256839809}. Best is trial 0 with value: 0.7585999404434786.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:48:27,773]\u001b[0m Trial 5 finished with value: 0.7750656387757509 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.7585999404434786.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:48:32,402]\u001b[0m Trial 6 finished with value: 0.7616137731605569 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.14083947375218495}. Best is trial 0 with value: 0.7585999404434786.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:48:39,057]\u001b[0m Trial 7 finished with value: 0.7731206555247103 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.061779666906633}. Best is trial 0 with value: 0.7585999404434786.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:48:48,537]\u001b[0m Trial 8 finished with value: 0.7581253973945729 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5804804782705136}. Best is trial 8 with value: 0.7581253973945729.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:48:57,820]\u001b[0m Trial 9 finished with value: 0.7640111236852604 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.16002258455695184}. Best is trial 8 with value: 0.7581253973945729.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:49:13,827]\u001b[0m Trial 10 finished with value: 0.7544999107492222 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.845906959281272}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:49:26,757]\u001b[0m Trial 11 finished with value: 0.7561399820671649 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8484853271380044}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:49:40,398]\u001b[0m Trial 12 finished with value: 0.7577461107534894 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9880218840566871}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:49:55,082]\u001b[0m Trial 13 finished with value: 0.757315816906899 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6542175623541839}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:50:02,904]\u001b[0m Trial 14 finished with value: 0.7592088312596347 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.43897876992727186}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:50:10,506]\u001b[0m Trial 15 finished with value: 0.756993531031826 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9502167116165781}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:50:29,674]\u001b[0m Trial 16 finished with value: 0.756834210582548 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.328367855386733}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:50:37,736]\u001b[0m Trial 17 finished with value: 0.7565288829734413 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5906812253370244}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:51:13,795]\u001b[0m Trial 18 finished with value: 0.785665165952949 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.849798856238662}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:51:23,843]\u001b[0m Trial 19 finished with value: 0.7596897676446721 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:51:33,831]\u001b[0m Trial 20 finished with value: 0.756744809855489 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7341555530489945}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:51:43,078]\u001b[0m Trial 21 finished with value: 0.7582299733208698 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.48999597370703735}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:51:50,042]\u001b[0m Trial 22 finished with value: 0.7569486687959116 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7053312665711715}. Best is trial 10 with value: 0.7544999107492222.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:52:03,910]\u001b[0m Trial 23 finished with value: 0.7544850799178568 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.998824024637275}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:52:16,797]\u001b[0m Trial 24 finished with value: 0.7559534997530774 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9923637080950235}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:52:30,235]\u001b[0m Trial 25 finished with value: 0.7548696406478732 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9903845990968347}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:52:33,941]\u001b[0m Trial 26 finished with value: 0.759672583462891 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.36143864555197225}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:52:43,591]\u001b[0m Trial 27 finished with value: 0.7555842121192498 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7594845514046729}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:52:55,085]\u001b[0m Trial 28 finished with value: 0.7622197645416036 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:53:17,967]\u001b[0m Trial 29 finished with value: 0.7677893309589497 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 5.650680572889211}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:53:26,001]\u001b[0m Trial 30 finished with value: 0.7836707876143415 and parameters: {'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.188005533987159}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:53:34,194]\u001b[0m Trial 31 finished with value: 0.7567568424392905 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8116700324246162}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:53:47,238]\u001b[0m Trial 32 finished with value: 0.7580773338300602 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.783399618360389}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:53:52,500]\u001b[0m Trial 33 finished with value: 0.759675098810283 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.997244939624134}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:53:55,878]\u001b[0m Trial 34 finished with value: 0.7582360985292118 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5416057259106503}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:54:11,883]\u001b[0m Trial 35 finished with value: 0.7581846571792976 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:54:24,005]\u001b[0m Trial 36 finished with value: 0.7599861845518175 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.21910227290284462}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:54:27,025]\u001b[0m Trial 37 finished with value: 0.7562776217494838 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7830949124744503}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:54:44,407]\u001b[0m Trial 38 finished with value: 0.7550291374144372 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:54:47,298]\u001b[0m Trial 39 finished with value: 0.7750656387757509 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:55:04,962]\u001b[0m Trial 40 finished with value: 0.7574706852795633 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:55:19,922]\u001b[0m Trial 41 finished with value: 0.7596920842180678 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:55:31,305]\u001b[0m Trial 42 finished with value: 0.7595044822124023 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:55:49,685]\u001b[0m Trial 43 finished with value: 0.7633556039844409 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.9611865340259276}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:56:01,523]\u001b[0m Trial 44 finished with value: 0.761520535173699 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:56:09,650]\u001b[0m Trial 45 finished with value: 0.75746964455358 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.657039249399763}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:56:29,804]\u001b[0m Trial 46 finished with value: 0.7553833567942188 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.413708195514718}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:56:33,652]\u001b[0m Trial 47 finished with value: 0.7641127867569698 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.2425510760349452}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:56:51,062]\u001b[0m Trial 48 finished with value: 0.7655839343354829 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.10144249540408656}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:57:06,958]\u001b[0m Trial 49 finished with value: 0.7598183294671311 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:57:42,219]\u001b[0m Trial 50 finished with value: 0.7739752335036679 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.480252733841893}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:57:51,802]\u001b[0m Trial 51 finished with value: 0.7579634781654822 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4109190458825088}. Best is trial 23 with value: 0.7544850799178568.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:58:08,054]\u001b[0m Trial 52 finished with value: 0.7544400832964899 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8882982327044171}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:58:21,428]\u001b[0m Trial 53 finished with value: 0.7559909244898247 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8489440804010643}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:58:38,439]\u001b[0m Trial 54 finished with value: 0.7549078244629512 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.885917151931208}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:58:54,109]\u001b[0m Trial 55 finished with value: 0.7558894648574201 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8821270074697548}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:59:07,898]\u001b[0m Trial 56 finished with value: 0.7565437999263691 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6073492640780026}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:59:23,608]\u001b[0m Trial 57 finished with value: 0.7553044971967534 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8521402183916412}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:59:41,181]\u001b[0m Trial 58 finished with value: 0.757021086545377 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6883871786021318}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:59:48,139]\u001b[0m Trial 59 finished with value: 0.7575970624566819 and parameters: {'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8974111588033077}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 13:59:51,500]\u001b[0m Trial 60 finished with value: 0.7573312929822656 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5302161353947131}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 14:00:06,529]\u001b[0m Trial 61 finished with value: 0.755296649329937 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8644114715474877}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 14:00:22,591]\u001b[0m Trial 62 finished with value: 0.7557115153549618 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9086219239557657}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 14:00:42,281]\u001b[0m Trial 63 finished with value: 0.7554115302160026 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.999113863728464}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[32m[I 2022-11-08 14:01:01,825]\u001b[0m Trial 64 finished with value: 0.7555948347775832 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7537000604068377}. Best is trial 52 with value: 0.7544400832964899.\u001b[0m\n",
      "\u001b[33m[W 2022-11-08 14:01:03,917]\u001b[0m Trial 65 failed because of the following error: KeyboardInterrupt('')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/koholm/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_813359/3996472158.py\", line 27, in objective\n",
      "    cbr.fit(\n",
      "  File \"/home/koholm/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py\", line 5730, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/home/koholm/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py\", line 2355, in _fit\n",
      "    self._train(\n",
      "  File \"/home/koholm/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py\", line 1759, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4623, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4672, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [382], line 60\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mprint\u001b[39m(trial\u001b[39m.\u001b[39mparams)\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m trial\u001b[39m.\u001b[39mparams\n\u001b[0;32m---> 60\u001b[0m tuned_params \u001b[39m=\u001b[39m tuned_hyperparameters()\n\u001b[1;32m     61\u001b[0m \u001b[39m# tuned_params = {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7494756089749968}\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [382], line 46\u001b[0m, in \u001b[0;36mtuned_hyperparameters\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtuned_hyperparameters\u001b[39m():\n\u001b[1;32m     41\u001b[0m     study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[1;32m     42\u001b[0m         study_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcatboost-tuning\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     43\u001b[0m         pruner\u001b[39m=\u001b[39moptuna\u001b[39m.\u001b[39mpruners\u001b[39m.\u001b[39mMedianPruner(n_warmup_steps\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m), \n\u001b[1;32m     44\u001b[0m         direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0m     study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, timeout\u001b[39m=\u001b[39;49m\u001b[39m900\u001b[39;49m, show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \n\u001b[1;32m     48\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumber of finished trials: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(study\u001b[39m.\u001b[39mtrials)))\n\u001b[1;32m     50\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [382], line 27\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     24\u001b[0m     tunable_params[\u001b[39m'\u001b[39m\u001b[39msubsample\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m'\u001b[39m\u001b[39msubsample\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m cbr \u001b[39m=\u001b[39m cb\u001b[39m.\u001b[39mCatBoostRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnon_tunable_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtunable_params) \n\u001b[0;32m---> 27\u001b[0m cbr\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     28\u001b[0m     train_pool,\n\u001b[1;32m     29\u001b[0m     eval_set\u001b[39m=\u001b[39;49m[(X_val, y_val)],\n\u001b[1;32m     30\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     31\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m y_pred \u001b[39m=\u001b[39m cbr\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[1;32m     35\u001b[0m score \u001b[39m=\u001b[39m rmsle(np\u001b[39m.\u001b[39mexpm1(y_val), np\u001b[39m.\u001b[39mexpm1(y_pred))\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:5730\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5728\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[1;32m   5731\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[1;32m   5732\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[1;32m   5733\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2351\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2353\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2356\u001b[0m         train_pool,\n\u001b[1;32m   2357\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2358\u001b[0m         params,\n\u001b[1;32m   2359\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2360\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2361\u001b[0m     )\n\u001b[1;32m   2363\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4623\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4672\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from catboost.utils import get_gpu_device_count\n",
    "\n",
    "gpu_count = get_gpu_device_count()\n",
    "\n",
    "non_tunable_params = {\n",
    "    'objective': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'task_type': 'GPU' if gpu_count else 'CPU', \n",
    "    'devices': f'0:{gpu_count}'\n",
    "}\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    tunable_params = {\n",
    "        'depth': trial.suggest_int('depth', 4, 9),\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "        # 'iterations': trial.suggest_int('iterations', 1000, 2000),\n",
    "        # 'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 2, 4),\n",
    "    }\n",
    "\n",
    "    if tunable_params['bootstrap_type'] == 'Bayesian': \n",
    "        tunable_params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    elif tunable_params['bootstrap_type'] == 'Bernoulli':\n",
    "        tunable_params['subsample'] = trial.suggest_float('subsample', 0.1, 1, log=True)\n",
    "\n",
    "    cbr = cb.CatBoostRegressor(**non_tunable_params, **tunable_params) \n",
    "    cbr.fit(\n",
    "        train_pool,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=50,\n",
    "    )\n",
    "\n",
    "    y_pred = cbr.predict(X_val)\n",
    "    score = rmsle(np.expm1(y_val), np.expm1(y_pred))\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def tuned_hyperparameters():\n",
    "    study = optuna.create_study(\n",
    "        study_name='catboost-tuning',\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), \n",
    "        direction='minimize'\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=900, show_progress_bar=True) \n",
    "\n",
    "    print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "    print('Best trial:')\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print('Value:', trial.value)\n",
    "    print('Params:')\n",
    "    print(trial.params)\n",
    "\n",
    "    return trial.params\n",
    "\n",
    "\n",
    "tuned_params = tuned_hyperparameters()\n",
    "# tuned_params = {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7494756089749968}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6f41b94a4c495c95ad335a4bc24660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.110137\n",
      "0:\tlearn: 0.9778262\ttest: 0.9892557\tbest: 0.9892557 (0)\ttotal: 20.3ms\tremaining: 6.55s\n",
      "50:\tlearn: 0.7182412\ttest: 0.7672415\tbest: 0.7672415 (50)\ttotal: 707ms\tremaining: 3.79s\n",
      "100:\tlearn: 0.6889272\ttest: 0.7611773\tbest: 0.7611773 (100)\ttotal: 1.24s\tremaining: 2.74s\n",
      "150:\tlearn: 0.6708856\ttest: 0.7588583\tbest: 0.7588583 (150)\ttotal: 1.67s\tremaining: 1.92s\n",
      "200:\tlearn: 0.6544238\ttest: 0.7586469\tbest: 0.7582753 (172)\ttotal: 2.12s\tremaining: 1.3s\n",
      "250:\tlearn: 0.6407412\ttest: 0.7580009\tbest: 0.7579397 (236)\ttotal: 2.58s\tremaining: 751ms\n",
      "300:\tlearn: 0.6313647\ttest: 0.7572846\tbest: 0.7571980 (296)\ttotal: 3.03s\tremaining: 232ms\n",
      "323:\tlearn: 0.6245028\ttest: 0.7569111\tbest: 0.7568690 (311)\ttotal: 3.26s\tremaining: 0us\n",
      "bestTest = 0.7568689977\n",
      "bestIteration = 311\n",
      "Shrink model to first 312 iterations.\n"
     ]
    }
   ],
   "source": [
    "model = cb.CatBoostRegressor(**non_tunable_params, **tuned_params, iterations=324)\n",
    "model.fit(train_pool, eval_set=valid_pool, verbose=50, plot=True)\n",
    "\n",
    "y_pred = np.expm1(model.predict(X_test))\n",
    "submission['predicted'] = y_pred\n",
    "submission.to_csv('submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7568689626865944\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.expm1(model.predict(X_val))\n",
    "print(rmsle(np.expm1(y_val), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7568689626865944\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CatBoostRegressor' object has no attribute 'ge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [381], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpm1(model\u001b[39m.\u001b[39mpredict(X_val))\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(rmsle(np\u001b[39m.\u001b[39mexpm1(y_val), y_pred))\n\u001b[0;32m----> 4\u001b[0m best_model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mge\n\u001b[1;32m      5\u001b[0m \u001b[39m# y_pred_best = np.expm1(best_model.pre)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m best_model\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CatBoostRegressor' object has no attribute 'ge'"
     ]
    }
   ],
   "source": [
    "y_pred = np.expm1(model.predict(X_val))\n",
    "print(rmsle(np.expm1(y_val), y_pred))\n",
    "\n",
    "best_model = model.ge\n",
    "# y_pred_best = np.expm1(best_model.pre)\n",
    "best_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1beb4c19f9c9850d9088b15a4a1b3063555a573f9fb8d1ae667cbe7a8ada917e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
