{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==2.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: attrs==22.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (22.1.0)\n",
      "Requirement already satisfied: autopep8==2.0.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: catboost==1.1.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: certifi==2022.9.24 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (2022.9.24)\n",
      "Requirement already satisfied: click==8.1.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: click-plugins==1.1.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: cligj==0.7.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: colorama==0.4.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: contourpy==1.0.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (1.0.6)\n",
      "Requirement already satisfied: cycler==0.11.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.11.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (0.29.28)\n",
      "Requirement already satisfied: debugpy==1.6.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (1.6.3)\n",
      "Requirement already satisfied: decorator==5.1.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (5.1.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: executing==1.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: Fiona==1.8.22 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (1.8.22)\n",
      "Requirement already satisfied: fonttools==4.38.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 19)) (4.38.0)\n",
      "Requirement already satisfied: gensim==4.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 20)) (4.2.0)\n",
      "Requirement already satisfied: geographiclib==1.52 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 21)) (1.52)\n",
      "Requirement already satisfied: geopandas==0.12.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 22)) (0.12.1)\n",
      "Requirement already satisfied: geopy==2.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 23)) (2.2.0)\n",
      "Requirement already satisfied: graphviz==0.20.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 24)) (0.20.1)\n",
      "Requirement already satisfied: ipykernel==6.17.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 25)) (6.17.0)\n",
      "Requirement already satisfied: ipython==8.6.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 26)) (8.6.0)\n",
      "Requirement already satisfied: jedi==0.18.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 27)) (0.18.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 28)) (1.2.0)\n",
      "Requirement already satisfied: jupyter_client==7.4.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 29)) (7.4.4)\n",
      "Requirement already satisfied: jupyter_core==4.11.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 30)) (4.11.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 31)) (1.4.4)\n",
      "Requirement already satisfied: matplotlib==3.6.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 32)) (3.6.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 33)) (0.1.6)\n",
      "Requirement already satisfied: munch==2.5.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 34)) (2.5.0)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 35)) (1.5.6)\n",
      "Requirement already satisfied: numpy==1.23.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 36)) (1.23.4)\n",
      "Requirement already satisfied: packaging==21.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 37)) (21.3)\n",
      "Requirement already satisfied: pandas==1.5.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 38)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 39)) (0.8.3)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 40)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==9.3.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 41)) (9.3.0)\n",
      "Requirement already satisfied: plotly==5.11.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 42)) (5.11.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.31 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 43)) (3.0.31)\n",
      "Requirement already satisfied: psutil==5.9.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 44)) (5.9.3)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 45)) (0.2.2)\n",
      "Requirement already satisfied: pyarrow==10.0.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 46)) (10.0.0)\n",
      "Requirement already satisfied: pycodestyle==2.9.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 47)) (2.9.1)\n",
      "Requirement already satisfied: pygeos==0.13 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 48)) (0.13)\n",
      "Requirement already satisfied: Pygments==2.13.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 49)) (2.13.0)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 50)) (3.0.9)\n",
      "Requirement already satisfied: pyproj==3.4.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 51)) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 52)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 53)) (2022.6)\n",
      "Requirement already satisfied: pyzmq==24.0.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 54)) (24.0.1)\n",
      "Requirement already satisfied: scikit-learn==1.1.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 55)) (1.1.3)\n",
      "Requirement already satisfied: scipy==1.9.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 56)) (1.9.3)\n",
      "Requirement already satisfied: seaborn==0.12.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 57)) (0.12.1)\n",
      "Requirement already satisfied: Shapely==1.8.5.post1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 58)) (1.8.5.post1)\n",
      "Requirement already satisfied: six==1.16.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 59)) (1.16.0)\n",
      "Requirement already satisfied: sklearn==0.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 60)) (0.0)\n",
      "Requirement already satisfied: smart-open==6.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 61)) (6.2.0)\n",
      "Requirement already satisfied: stack-data==0.6.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 62)) (0.6.0)\n",
      "Requirement already satisfied: tenacity==8.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 63)) (8.1.0)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 64)) (3.1.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 65)) (2.0.1)\n",
      "Requirement already satisfied: tornado==6.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 66)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.64.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 67)) (4.64.1)\n",
      "Requirement already satisfied: traitlets==5.5.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 68)) (5.5.0)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 69)) (0.2.5)\n",
      "Requirement already satisfied: xgboost==1.7.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 70)) (1.7.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.8/site-packages (from Fiona==1.8.22->-r requirements.txt (line 18)) (44.0.0)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in ./venv/lib/python3.8/site-packages (from ipython==8.6.0->-r requirements.txt (line 26)) (4.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython==8.6.0->-r requirements.txt (line 26)) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import warnings\n",
    "import os.path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import shutil\n",
    "import geopandas as gpd\n",
    "import catboost as cb\n",
    "import optuna\n",
    "\n",
    "from xgboost import XGBRegressor, plot_importance, to_graphviz, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "from k_fold import random_k_fold\n",
    "from shapely import wkt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from utils import squared_log, rmsle_xgb, add_city_centre_dist, group_ages, to_categorical, nan_to_string, object_encoder\n",
    "from k_fold import random_k_fold, xgb_cross_validation\n",
    "from objectives_and_metrics import _rmsle, RmsleMetric, RmsleObjective, LogTargetsRmsleMetric, RmseObjective\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "spatial = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "age = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "income = pd.read_csv('data/grunnkrets_income_households.csv').set_index(['grunnkrets_id', 'year']).add_prefix('income_').reset_index()\n",
    "households = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "plaace = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "\n",
    "train = pd.read_csv('data/stores_train.csv')\n",
    "test = pd.read_csv('data/stores_test.csv')\n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "model_name = \"modeling/0002.model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df: pd.DataFrame, predictor: str = ''):\n",
    "    age_ranges = [\n",
    "        (0, 19),\n",
    "        (20, 39),\n",
    "        (40, 59),\n",
    "        (60, 79),\n",
    "        (80, 90),\n",
    "    ]\n",
    "    \n",
    "    # Define datasets to be merged\n",
    "    spatial_merge = spatial.drop(columns=['year']).drop_duplicates(subset=['grunnkrets_id'])\n",
    "    age_groups_merge = group_ages(age, age_ranges)\n",
    "    income_merge = income.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    households_merge = households.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    plaace_merge = plaace.drop_duplicates(subset='plaace_hierarchy_id')\n",
    "    bus_data_train_merge = gpd.read_parquet('derived_data/stores_bus_stops_lt_1km_train').drop(columns=['geometry'])\n",
    "\n",
    "    # Merge datasets\n",
    "    df = df.merge(spatial_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(age_groups_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(income_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(households_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(plaace_merge, how='left')\n",
    "    df = df.merge(bus_data_train_merge, on='store_id', how='left')\n",
    "    df = add_city_centre_dist(df).drop(columns=['lon_center', 'lat_center'])\n",
    "\n",
    "    # Handle categories for different predictors\n",
    "    if predictor == 'xgb':\n",
    "        # df = to_categorical(df)\n",
    "        df = object_encoder(df)\n",
    "    elif predictor == 'catboost':\n",
    "        df = nan_to_string(df)\n",
    "    else: \n",
    "        raise ValueError('Invalid predictor')\n",
    "\n",
    "    features = [\n",
    "        'store_name', \n",
    "        'mall_name', \n",
    "        'chain_name',\n",
    "        'address', \n",
    "        'lat', 'lon',\n",
    "        \n",
    "        *age_groups_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *income_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *households_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        'lv1_desc', 'lv2_desc',\n",
    "        *bus_data_train_merge.drop(columns=['store_id']).columns,\n",
    "        'dist_to_center'\n",
    "    ]\n",
    "\n",
    "    return df[features]\n",
    "\n",
    "\n",
    "label_name = 'revenue'\n",
    "X = train.drop(columns=[label_name])\n",
    "y = np.log1p(train[label_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(data):\n",
    "  df = data[['revenue', \n",
    "    # 'age_0_19', 'age_20_39', 'age_40_59', 'age_60_79', 'age_80_90', \n",
    "    # 'bus_stops_count', 'Mangler viktighetsniv√•', 'Standard holdeplass', 'Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt', 'Annen viktig holdeplass', \n",
    "    'dist_to_center', 'lat','lon'\n",
    "    ]]\n",
    "  df['knutepunkt'] = data[['Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt']].sum(axis=1)\n",
    "  # df.revenue = np.exp(df.revenue)\n",
    "  # df.bus_stops_count = np.sqrt(df.bus_stops_count)\n",
    "  df = df[df.dist_to_center < 70_000]\n",
    "  # df.dist_to_center = np.log(df.dist_to_center)\n",
    "  \n",
    "  plt.figure(figsize=(15, 15))\n",
    "  pairplot = sns.pairplot(df)\n",
    "  # heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)\n",
    "\n",
    "\n",
    "# data_full =  pd.merge(X_train, y_train, left_index=True, right_index=True) \n",
    "# plot_corr(data_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_buffers(X_train, y_train, X_val, y_val):\n",
    "    # Clear buffers\n",
    "    folder = os.path.join(os.getcwd(), 'modeling')\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "            print(f'Deleted file: {file_path}')\n",
    "\n",
    "    train_buffer_path = 'modeling/train.buffer'\n",
    "    test_buffer_path = 'modeling/test.buffer'\n",
    "\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train, enable_categorical=True)\n",
    "    dtrain.save_binary(train_buffer_path)\n",
    "    print(f'--> {train_buffer_path} created and saved.')\n",
    "\n",
    "    dvalid = xgb.DMatrix(data=X_val, label=y_val, enable_categorical=True)\n",
    "    dvalid.save_binary(test_buffer_path)\n",
    "    print(f'--> {test_buffer_path} created and saved.')\n",
    "\n",
    "    return dtrain, dvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.best_score_)\n",
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(_rmsle(y_train, y_pred_train))\n",
    "# print(_rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model(X_train, y_train, X_val, y_val):\n",
    "    params = {'colsample_bytree': 0.7717138210314867, 'learning_rate': 0.047506668950627134, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 223, 'subsample': 0.9929036803032936}\n",
    "    print('Clearing and creating buffers...')\n",
    "    dtrain, dvalid = clear_buffers(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    rand_search_model = random_k_fold(X_train, y_train, verbose=1, n_iter=100)\n",
    "    model = rand_search_model\n",
    "    params = model.best_params_\n",
    "    print(rand_search_model.best_score_, params)\n",
    "    \n",
    "    # params = {'colsample_bytree': 0.8601277878899238, 'eval_metric': 'rmsle', 'gamma': 0.12760202929262826, 'learning_rate': 0.07356461924449906, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 306, 'objective': 'reg:squaredlogerror', 'subsample': 0.8993341396761092}\n",
    "    \n",
    "    params['disable_default_eval_metric'] = True\n",
    "    # model = XGBRegressor()\n",
    "    # model.set_params(**params)\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred_train = model.predict(X_train)\n",
    "    # y_pred_val = model.predict(X_val)\n",
    "    # print(_rmsle(y_train, y_pred_train))\n",
    "    # print(_rmsle(y_val, y_pred_val))\n",
    "\n",
    "    # num_round = 999\n",
    "    # watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "    # print(\"Attempting to start training...\")\n",
    "    # model = xgb.train(\n",
    "    #     params=params, \n",
    "    #     dtrain=dtrain, \n",
    "    #     num_boost_round=num_round, \n",
    "    #     evals=watchlist, \n",
    "    #     early_stopping_rounds=10, \n",
    "    #     verbose_eval=20)\n",
    "    # print(\"--> model trained.\")\n",
    "    # print('Best score:', model.best_score)\n",
    "\n",
    "    # print(\"Attempting to save model...\")\n",
    "    # model.save_model(model_name)\n",
    "    # print(\"--> model saved.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "# X_train, X_val = generate_features(X_train, predictor='xgb'), generate_features(X_val, predictor='xgb')\n",
    "\n",
    "# model = train_xgb_model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(_rmsle(y_train, y_pred_train))\n",
    "# print(_rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_prediction(X_test, model):\n",
    "    dtest = xgb.DMatrix(data=X_test, enable_categorical=True)\n",
    "\n",
    "    print(\"\\nAttempting to start prediction...\")\n",
    "    y_pred = model.predict(dtest, ntree_limit=model.best_iteration)\n",
    "    print(\"--> Prediction finished.\")\n",
    "\n",
    "    print(\"\\nAttempting to save prediction...\")\n",
    "    submission['predicted'] = np.array(y_pred)\n",
    "    submission.to_csv('submissions/submission.csv', index=False)\n",
    "    print(\"--> prediction saved with features as name in submission folder.\")\n",
    "\n",
    "\n",
    "# X_test = generate_features(test, predictor='xgb')\n",
    "# xgb_prediction(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = model.best_estimator_ if model.best_estimator_ is not None else model\n",
    "# xgb_model = model\n",
    "# plot_importance(xgb_model)\n",
    "# xgb.to_graphviz(xgb_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features for Catboost predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "X_train, X_val = generate_features(X_train, predictor='catboost'), generate_features(X_val, predictor='catboost')\n",
    "X_test = generate_features(test, predictor='catboost')\n",
    "\n",
    "auxillary_columns = ['address']\n",
    "text_features = ['store_name', 'address']\n",
    "cat_features = ['mall_name', 'chain_name', 'lv1_desc', 'lv2_desc']\n",
    "\n",
    "train_pool = cb.Pool(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")\n",
    "\n",
    "valid_pool = cb.Pool(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-07 13:10:08,547]\u001b[0m A new study created in memory with name: no-name-e47795cd-97bb-4dae-b0dc-a415628dfa6f\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:10:12,510]\u001b[0m Trial 0 finished with value: 0.7571892038444874 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.7571892038444874.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:10:14,757]\u001b[0m Trial 1 finished with value: 0.7685709761763868 and parameters: {'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.7571892038444874.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:10:25,347]\u001b[0m Trial 2 finished with value: 0.7757865642706976 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.907726673993754}. Best is trial 0 with value: 0.7571892038444874.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:10:34,093]\u001b[0m Trial 3 finished with value: 0.759918741339497 and parameters: {'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 4.570533303367985}. Best is trial 0 with value: 0.7571892038444874.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:10:37,576]\u001b[0m Trial 4 finished with value: 0.752531919659182 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.11725384778653342}. Best is trial 4 with value: 0.752531919659182.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:10:40,191]\u001b[0m Trial 5 finished with value: 0.7678552132318758 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 4 with value: 0.752531919659182.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:10:48,163]\u001b[0m Trial 6 finished with value: 0.752143674308194 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 6 with value: 0.752143674308194.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:10:56,286]\u001b[0m Trial 7 finished with value: 0.7574094816169868 and parameters: {'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 4.935978099241708}. Best is trial 6 with value: 0.752143674308194.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:11:00,718]\u001b[0m Trial 8 finished with value: 0.7591895615935489 and parameters: {'depth': 3, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 3.3675953218150356}. Best is trial 6 with value: 0.752143674308194.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:11:03,233]\u001b[0m Trial 9 finished with value: 0.7678552132318758 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 6 with value: 0.752143674308194.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:11:18,420]\u001b[0m Trial 10 finished with value: 0.7487999911552742 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8338515919916568}. Best is trial 10 with value: 0.7487999911552742.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:11:30,910]\u001b[0m Trial 11 finished with value: 0.7500914821425292 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9897697141364669}. Best is trial 10 with value: 0.7487999911552742.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:11:49,783]\u001b[0m Trial 12 finished with value: 0.7455432028677232 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9358508808430841}. Best is trial 12 with value: 0.7455432028677232.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:12:09,534]\u001b[0m Trial 13 finished with value: 0.7450311813049298 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.856484682854198}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:12:22,335]\u001b[0m Trial 14 finished with value: 0.7471832921585347 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4504305116845304}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:12:42,657]\u001b[0m Trial 15 finished with value: 0.747338159929664 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5247966768467145}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:12:53,920]\u001b[0m Trial 16 finished with value: 0.7515159376819615 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.21604725786671455}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:13:04,857]\u001b[0m Trial 17 finished with value: 0.7480916192990754 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6379988407749343}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:13:14,905]\u001b[0m Trial 18 finished with value: 0.7512847426605074 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.29487038142129063}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:13:31,723]\u001b[0m Trial 19 finished with value: 0.7467270383298844 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9209769882334564}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:13:50,049]\u001b[0m Trial 20 finished with value: 0.7478144016071105 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3538518291726847}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:14:04,337]\u001b[0m Trial 21 finished with value: 0.7478881628603083 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9729248371865122}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:14:19,963]\u001b[0m Trial 22 finished with value: 0.7480155431918216 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6655840113462347}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:14:39,994]\u001b[0m Trial 23 finished with value: 0.7470266342539901 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6842866401136801}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:14:51,460]\u001b[0m Trial 24 finished with value: 0.7454271827851476 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7793404348540908}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:15:01,542]\u001b[0m Trial 25 finished with value: 0.7470426559248226 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.498692957362153}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:15:05,768]\u001b[0m Trial 26 finished with value: 0.7456643326562173 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7425530054404648}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:15:19,998]\u001b[0m Trial 27 finished with value: 0.7473391038274476 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5602395657511782}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:15:34,404]\u001b[0m Trial 28 finished with value: 0.7480510344484838 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3905727366806201}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:15:44,869]\u001b[0m Trial 29 finished with value: 0.7480313857702428 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.26011180950153534}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:15:50,358]\u001b[0m Trial 30 finished with value: 0.7626198037554007 and parameters: {'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:15:54,145]\u001b[0m Trial 31 finished with value: 0.7467391176099908 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7585254545525186}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:15:58,037]\u001b[0m Trial 32 finished with value: 0.7480789648864525 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7407344857626535}. Best is trial 13 with value: 0.7450311813049298.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:03,590]\u001b[0m Trial 33 finished with value: 0.7443440776720129 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8358001091868329}. Best is trial 33 with value: 0.7443440776720129.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:08,858]\u001b[0m Trial 34 finished with value: 0.7453045022842198 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8629330368942747}. Best is trial 33 with value: 0.7443440776720129.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:14,369]\u001b[0m Trial 35 finished with value: 0.7445671468577689 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.595507977317338}. Best is trial 33 with value: 0.7443440776720129.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:18,025]\u001b[0m Trial 36 finished with value: 0.8186728359727802 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.804171567482797}. Best is trial 33 with value: 0.7443440776720129.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:19,728]\u001b[0m Trial 37 finished with value: 0.7731915958887686 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 33 with value: 0.7443440776720129.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:25,142]\u001b[0m Trial 38 finished with value: 0.7443239250054213 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6062387408756248}. Best is trial 38 with value: 0.7443239250054213.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:29,461]\u001b[0m Trial 39 finished with value: 0.7484914777728109 and parameters: {'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6239154993553884}. Best is trial 38 with value: 0.7443239250054213.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:30,876]\u001b[0m Trial 40 finished with value: 0.7836628547779316 and parameters: {'depth': 3, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 38 with value: 0.7443239250054213.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:37,040]\u001b[0m Trial 41 finished with value: 0.7466334474951832 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5834864195965648}. Best is trial 38 with value: 0.7443239250054213.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:42,241]\u001b[0m Trial 42 finished with value: 0.7449925486886372 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8359995500337876}. Best is trial 38 with value: 0.7443239250054213.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:48,683]\u001b[0m Trial 43 finished with value: 0.7432044519085643 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.635180352520854}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:54,728]\u001b[0m Trial 44 finished with value: 0.7457960544332612 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4370130920741963}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:16:57,941]\u001b[0m Trial 45 finished with value: 0.7486917635580206 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.558817331666829}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:02,882]\u001b[0m Trial 46 finished with value: 0.7550792480415651 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.10070717052982515}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:08,634]\u001b[0m Trial 47 finished with value: 0.7688259352572548 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.314273201125445}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:13,420]\u001b[0m Trial 48 finished with value: 0.7502384216137193 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.2962275772945494}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:16,056]\u001b[0m Trial 49 finished with value: 0.7678552132318758 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:20,968]\u001b[0m Trial 50 finished with value: 0.7490359489239217 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.21238358172802735}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:26,090]\u001b[0m Trial 51 finished with value: 0.7455991304733482 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8172362190056693}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:31,425]\u001b[0m Trial 52 finished with value: 0.7470419485370021 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6265324680778008}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:35,807]\u001b[0m Trial 53 finished with value: 0.7457933213462787 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8306511407928227}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:39,282]\u001b[0m Trial 54 finished with value: 0.7478213342783994 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6822619855639244}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:43,668]\u001b[0m Trial 55 finished with value: 0.7459279360534553 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9965301758333855}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:49,511]\u001b[0m Trial 56 finished with value: 0.7462579368566469 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4756788555622754}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:53,610]\u001b[0m Trial 57 finished with value: 0.7455797236898611 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8484141430444487}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:17:57,444]\u001b[0m Trial 58 finished with value: 0.7491623172561882 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6416344080931872}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:00,474]\u001b[0m Trial 59 finished with value: 0.7547920149395002 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.1892537638389581}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:04,694]\u001b[0m Trial 60 finished with value: 0.7516352201761456 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.14861608283310396}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:09,000]\u001b[0m Trial 61 finished with value: 0.7496007819561453 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8841705675016737}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:13,517]\u001b[0m Trial 62 finished with value: 0.7446164067380534 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8890456068534885}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:18,764]\u001b[0m Trial 63 finished with value: 0.744786708053165 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7187039979923814}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:23,865]\u001b[0m Trial 64 finished with value: 0.7455525391197683 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7286213751311236}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:29,371]\u001b[0m Trial 65 finished with value: 0.7456089917953922 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6031444503307722}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:32,145]\u001b[0m Trial 66 finished with value: 0.7475394393327037 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9128328985363329}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:38,240]\u001b[0m Trial 67 finished with value: 0.7557620262236956 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.565546031517452}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:44,336]\u001b[0m Trial 68 finished with value: 0.746833795528766 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5221184799885494}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:47,098]\u001b[0m Trial 69 finished with value: 0.7670558367447754 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:51,201]\u001b[0m Trial 70 finished with value: 0.7473369079450156 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7131084232678195}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:18:56,693]\u001b[0m Trial 71 finished with value: 0.7474698489675203 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8079974813083464}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:19:00,121]\u001b[0m Trial 72 finished with value: 0.7466842914981182 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9906713849824439}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:19:04,753]\u001b[0m Trial 73 finished with value: 0.7469899324809908 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6675310538325819}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:19:09,019]\u001b[0m Trial 74 finished with value: 0.7461390589438923 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7831016946702272}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:19:24,424]\u001b[0m Trial 75 finished with value: 0.7467373534204428 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8649804463751759}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:19:27,295]\u001b[0m Trial 76 finished with value: 0.7470744623444936 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9234787534620774}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:19:31,091]\u001b[0m Trial 77 finished with value: 0.7493823954872492 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.42690166294266957}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:19:52,364]\u001b[0m Trial 78 finished with value: 0.7463492261971294 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7087098474851405}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:19:56,194]\u001b[0m Trial 79 finished with value: 0.7879946018396724 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.312434086082478}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:19:59,043]\u001b[0m Trial 80 finished with value: 0.7670558367447754 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:20:04,336]\u001b[0m Trial 81 finished with value: 0.7448096937039229 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7850354984321756}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:20:08,387]\u001b[0m Trial 82 finished with value: 0.7469500086527162 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7827446155560797}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:20:13,072]\u001b[0m Trial 83 finished with value: 0.7487646125285132 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5643205371619652}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:20:18,438]\u001b[0m Trial 84 finished with value: 0.74592476344874 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6293974103719303}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:20:38,826]\u001b[0m Trial 85 finished with value: 0.7454692581691374 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7592108403705977}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:20:42,992]\u001b[0m Trial 86 finished with value: 0.7467109030223257 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9047412710670825}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:20:46,584]\u001b[0m Trial 87 finished with value: 0.7471915372751774 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6811572004309921}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:20:51,283]\u001b[0m Trial 88 finished with value: 0.7461847156534086 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5337069012120776}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:21:14,691]\u001b[0m Trial 89 finished with value: 0.7478244328583894 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6051161285196107}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:21:18,155]\u001b[0m Trial 90 finished with value: 0.7463782077556572 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8265665891971641}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:21:22,335]\u001b[0m Trial 91 finished with value: 0.7462945796962402 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9376921928945123}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:21:27,571]\u001b[0m Trial 92 finished with value: 0.7461861677705884 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8716247157278729}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:21:33,070]\u001b[0m Trial 93 finished with value: 0.7451924703621928 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7433418259125715}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:21:38,341]\u001b[0m Trial 94 finished with value: 0.7441827394606382 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.754865981327718}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:21:43,832]\u001b[0m Trial 95 finished with value: 0.7481378643583287 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3379850221830417}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:21:48,107]\u001b[0m Trial 96 finished with value: 0.7466983266157959 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6540906026062374}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:21:52,424]\u001b[0m Trial 97 finished with value: 0.8203803799560317 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.951579888386627}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:21:55,531]\u001b[0m Trial 98 finished with value: 0.7465058750262948 and parameters: {'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8216593009705914}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 13:22:10,520]\u001b[0m Trial 99 finished with value: 0.751677419578115 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 43 with value: 0.7432044519085643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "Value: 0.7432044519085643\n",
      "Params:\n",
      "{'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.635180352520854}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    param = {\n",
    "        # 'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 3, 9),\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "        'iterations': 1000,\n",
    "        # 'objective': RmseObjective(),\n",
    "        # 'eval_metric': LogTargetsRmsleMetric(),\n",
    "        'objective': 'RMSE',\n",
    "        'eval_metric': 'RMSE'\n",
    "    }\n",
    "\n",
    "    if param['bootstrap_type'] == 'Bayesian': \n",
    "        param['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    elif param['bootstrap_type'] == 'Bernoulli':\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.1, 1, log=True)\n",
    "\n",
    "    cbr = cb.CatBoostRegressor(**param, task_type='GPU', devices='0:1')\n",
    "    \n",
    "    # pruning_callback = optuna.integration.CatBoostPruningCallback(trial, 'LogTargetsRmsleMetric')\n",
    "    cbr.fit(\n",
    "        train_pool,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=50,\n",
    "        # callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    # pruning_callback.check_pruned()\n",
    "\n",
    "    y_pred = np.expm1(cbr.predict(X_val))\n",
    "    score = _rmsle(np.expm1(y_val), y_pred)[1]\n",
    "\n",
    "    # score = np.sqrt(mean_squared_log_error(np.expm1(y_val), y_pred))\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction='minimize')\n",
    "study.optimize(objective, n_trials=100) # timeout=600\n",
    "\n",
    "print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Value:', trial.value)\n",
    "print('Params:')\n",
    "print(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7270089548135714 {'colsample_bylevel': 0.07329097359385545, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.1734504015536018}\n"
     ]
    }
   ],
   "source": [
    "print(trial.value, trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_summary(cv_data):\n",
    "    cv_data.head(10)\n",
    "\n",
    "    best_value = cv_data['test-Logloss-mean'].min()\n",
    "    best_iter = cv_data['test-Logloss-mean'].values.argmin()\n",
    "\n",
    "    print('Best validation Logloss score : {:.4f}¬±{:.4f} on step {}'.format(\n",
    "        best_value,\n",
    "        cv_data['test-Logloss-std'][best_iter],\n",
    "        best_iter)\n",
    "    )\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 9),\n",
    "    'iterations': [1000]\n",
    "}\n",
    "\n",
    "cbr = cb.CatBoostRegressor(\n",
    "    objective=RmseObjective(), \n",
    "    eval_metric=LogTargetsRmsleMetric(),\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# cbr.randomized_search(param_dist, X=train_pool, cv=3, n_iter=20, shuffle=True, stratified=True, plot=True)\n",
    "\n",
    "# feature_importance = cbr.get_feature_importance(prettified=True)\n",
    "# print('Feature importance:', feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acfef384a704be8894301173d3cb578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.8410715\ttest: 1.8806790\tbest: 1.8806790 (0)\ttotal: 283ms\tremaining: 4m 42s\n",
      "50:\tlearn: 0.9037483\ttest: 0.9133867\tbest: 0.9133867 (50)\ttotal: 15s\tremaining: 4m 39s\n",
      "100:\tlearn: 0.7946943\ttest: 0.7925219\tbest: 0.7925219 (100)\ttotal: 30s\tremaining: 4m 27s\n",
      "150:\tlearn: 0.7723114\ttest: 0.7744926\tbest: 0.7744926 (150)\ttotal: 44.6s\tremaining: 4m 10s\n",
      "200:\tlearn: 0.7627387\ttest: 0.7686614\tbest: 0.7686614 (200)\ttotal: 59.3s\tremaining: 3m 55s\n",
      "250:\tlearn: 0.7560784\ttest: 0.7651931\tbest: 0.7651931 (250)\ttotal: 1m 13s\tremaining: 3m 40s\n",
      "300:\tlearn: 0.7503074\ttest: 0.7628645\tbest: 0.7628645 (300)\ttotal: 1m 28s\tremaining: 3m 25s\n",
      "350:\tlearn: 0.7410254\ttest: 0.7602637\tbest: 0.7602335 (348)\ttotal: 1m 43s\tremaining: 3m 12s\n",
      "400:\tlearn: 0.7316951\ttest: 0.7579294\tbest: 0.7579294 (400)\ttotal: 1m 59s\tremaining: 2m 57s\n",
      "450:\tlearn: 0.7225471\ttest: 0.7555986\tbest: 0.7555986 (450)\ttotal: 2m 14s\tremaining: 2m 43s\n",
      "500:\tlearn: 0.7148193\ttest: 0.7534449\tbest: 0.7534237 (499)\ttotal: 2m 29s\tremaining: 2m 28s\n",
      "550:\tlearn: 0.7073033\ttest: 0.7521592\tbest: 0.7520062 (546)\ttotal: 2m 44s\tremaining: 2m 13s\n",
      "600:\tlearn: 0.6997765\ttest: 0.7510890\tbest: 0.7510147 (596)\ttotal: 2m 59s\tremaining: 1m 59s\n",
      "650:\tlearn: 0.6954346\ttest: 0.7501974\tbest: 0.7501974 (650)\ttotal: 3m 14s\tremaining: 1m 44s\n",
      "700:\tlearn: 0.6904162\ttest: 0.7493964\tbest: 0.7493964 (700)\ttotal: 3m 29s\tremaining: 1m 29s\n",
      "750:\tlearn: 0.6833051\ttest: 0.7484426\tbest: 0.7484426 (750)\ttotal: 3m 44s\tremaining: 1m 14s\n",
      "800:\tlearn: 0.6794273\ttest: 0.7479470\tbest: 0.7478884 (799)\ttotal: 3m 59s\tremaining: 59.4s\n",
      "850:\tlearn: 0.6747235\ttest: 0.7477749\tbest: 0.7477277 (848)\ttotal: 4m 14s\tremaining: 44.5s\n",
      "900:\tlearn: 0.6692142\ttest: 0.7474745\tbest: 0.7472654 (890)\ttotal: 4m 29s\tremaining: 29.6s\n",
      "950:\tlearn: 0.6654026\ttest: 0.7472373\tbest: 0.7471820 (939)\ttotal: 4m 44s\tremaining: 14.7s\n",
      "999:\tlearn: 0.6620101\ttest: 0.7470469\tbest: 0.7469003 (975)\ttotal: 4m 59s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7469003365\n",
      "bestIteration = 975\n",
      "\n",
      "Shrink model to first 976 iterations.\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.03,\n",
    "    # 'objective': RmsleObjective(),\n",
    "    # 'eval_metric': RmsleMetric()\n",
    "    'objective': RmseObjective(),\n",
    "    'eval_metric': LogTargetsRmsleMetric()\n",
    "}\n",
    "\n",
    "params = {'iterations': 1000,\n",
    " 'loss_function': 'RMSE',\n",
    " 'eval_metric': LogTargetsRmsleMetric(),\n",
    " 'objective': RmseObjective(),\n",
    " 'depth': 7.0,\n",
    " 'learning_rate': 0.0494195212108839}\n",
    "\n",
    "params = {'colsample_bylevel': 0.07329097359385545, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.1734504015536018}\n",
    "params = {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.635180352520854}\n",
    "\n",
    "model = cb.CatBoostRegressor(**params, objective=RmseObjective(), eval_metric=LogTargetsRmsleMetric())\n",
    "model.fit(train_pool, eval_set=valid_pool, verbose=50, plot=True)\n",
    "\n",
    "y_pred = np.expm1(model.predict(X_test))\n",
    "submission['predicted'] = y_pred\n",
    "submission.to_csv('submissions/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.expm1(model.predict(X_test))\n",
    "submission['predicted'] = y_pred\n",
    "submission.to_csv('submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10.000000000000002\n"
     ]
    }
   ],
   "source": [
    "# y_pred = model.predict(test)\n",
    "# y_pred\n",
    "\n",
    "a = 10\n",
    "log_a = np.log1p(a)\n",
    "exp_log_a = np.expm1(log_a)\n",
    "\n",
    "print(a, exp_log_a)\n",
    "\n",
    "model.best_score_\n",
    "\n",
    "y_pred = np.expm1()\n",
    "submission['predicted'] = np.array(y_pred)\n",
    "submission.to_csv('submissions/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "There is no trained model to use predict(). Use fit() to train model. Then use this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [228], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[39m=\u001b[39m cb\u001b[39m.\u001b[39mCatBoostRegressor(loss_function\u001b[39m=\u001b[39mRmsleObjective, eval_metric\u001b[39m=\u001b[39mRmsleMetric)\n\u001b[1;32m     10\u001b[0m \u001b[39m# model.randomized_search(train_pool, param_distributions=params, cv=5)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_val)\n\u001b[1;32m     13\u001b[0m rmsle \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39msqrt(mean_squared_log_error(y_val, pred)))\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTesting performance\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:5775\u001b[0m, in \u001b[0;36mCatBoostRegressor.predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5773\u001b[0m \u001b[39mif\u001b[39;00m prediction_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5774\u001b[0m     prediction_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_default_prediction_type()\n\u001b[0;32m-> 5775\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, \u001b[39m'\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m'\u001b[39;49m, task_type)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:2541\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2540\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 2541\u001b[0m data, data_is_single_object \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[1;32m   2542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[1;32m   2544\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:2517\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_process_predict_input_data\u001b[39m(\u001b[39mself\u001b[39m, data, parent_method_name, thread_count, label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2516\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_fitted() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_count_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2517\u001b[0m         \u001b[39mraise\u001b[39;00m CatBoostError((\u001b[39m\"\u001b[39m\u001b[39mThere is no trained model to use \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m(). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2518\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39mUse fit() to train model. Then use this method.\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mformat(parent_method_name))\n\u001b[1;32m   2519\u001b[0m     is_single_object \u001b[39m=\u001b[39m _is_data_single_object(data)\n\u001b[1;32m   2520\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Pool):\n",
      "\u001b[0;31mCatBoostError\u001b[0m: There is no trained model to use predict(). Use fit() to train model. Then use this method."
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'depth': randint(2, 20),\n",
    "    'learning_rate': uniform(0.01, 0.4),\n",
    "    'iterations': randint(10, 1000)\n",
    "}\n",
    "\n",
    "model = cb.CatBoostRegressor(loss_function=RmsleObjective, eval_metric=RmsleMetric)\n",
    "\n",
    "\n",
    "# model.randomized_search(train_pool, param_distributions=params, cv=5)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "rmsle = (np.sqrt(mean_squared_log_error(y_val, pred)))\n",
    "print('Testing performance')\n",
    "print('RMSLE: {:.2f}'.format(rmsle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1beb4c19f9c9850d9088b15a4a1b3063555a573f9fb8d1ae667cbe7a8ada917e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
