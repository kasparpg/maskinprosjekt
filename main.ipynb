{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: asttokens==2.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: attrs==22.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 2)) (22.1.0)\n",
      "Requirement already satisfied: autopep8==2.0.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: catboost==1.1.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: certifi==2022.9.24 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 6)) (2022.9.24)\n",
      "Requirement already satisfied: click==8.1.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: click-plugins==1.1.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: cligj==0.7.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: colorama==0.4.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: contourpy==1.0.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 11)) (1.0.6)\n",
      "Requirement already satisfied: cycler==0.11.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 12)) (0.11.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 13)) (0.29.28)\n",
      "Requirement already satisfied: debugpy==1.6.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 14)) (1.6.3)\n",
      "Requirement already satisfied: decorator==5.1.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 15)) (5.1.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: executing==1.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: fonttools==4.38.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 18)) (4.38.0)\n",
      "Requirement already satisfied: gensim==4.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 19)) (4.2.0)\n",
      "Requirement already satisfied: geopy==2.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 20)) (2.2.0)\n",
      "Requirement already satisfied: graphviz==0.20.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 21)) (0.20.1)\n",
      "Requirement already satisfied: ipykernel==6.17.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 22)) (6.17.0)\n",
      "Requirement already satisfied: ipython==8.6.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 23)) (8.6.0)\n",
      "Requirement already satisfied: jedi==0.18.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 24)) (0.18.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 25)) (1.2.0)\n",
      "Requirement already satisfied: jupyter_client==7.4.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 26)) (7.4.4)\n",
      "Requirement already satisfied: jupyter_core==4.11.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 27)) (4.11.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 28)) (1.4.4)\n",
      "Requirement already satisfied: matplotlib==3.6.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 29)) (3.6.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 30)) (0.1.6)\n",
      "Requirement already satisfied: munch==2.5.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 31)) (2.5.0)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 32)) (1.5.6)\n",
      "Requirement already satisfied: numpy==1.23.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 33)) (1.23.4)\n",
      "Requirement already satisfied: packaging==21.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 34)) (21.3)\n",
      "Requirement already satisfied: pandas==1.5.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 35)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 36)) (0.8.3)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 37)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==9.3.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 38)) (9.3.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.31 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 39)) (3.0.31)\n",
      "Requirement already satisfied: psutil==5.9.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 40)) (5.9.3)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 41)) (0.2.2)\n",
      "Requirement already satisfied: pyarrow==10.0.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 42)) (10.0.0)\n",
      "Requirement already satisfied: pycodestyle==2.9.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 43)) (2.9.1)\n",
      "Requirement already satisfied: Pygments==2.13.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 44)) (2.13.0)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 45)) (3.0.9)\n",
      "Requirement already satisfied: pyproj==3.4.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 46)) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 47)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 48)) (2022.6)\n",
      "Requirement already satisfied: pyzmq==24.0.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 49)) (24.0.1)\n",
      "Requirement already satisfied: scikit-learn==1.1.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 50)) (1.1.3)\n",
      "Requirement already satisfied: scipy==1.9.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 51)) (1.9.3)\n",
      "Requirement already satisfied: seaborn==0.12.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 52)) (0.12.1)\n",
      "Requirement already satisfied: Shapely==1.8.5.post1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 53)) (1.8.5.post1)\n",
      "Requirement already satisfied: six==1.16.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 54)) (1.16.0)\n",
      "Requirement already satisfied: sklearn==0.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 55)) (0.0)\n",
      "Requirement already satisfied: smart-open==6.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 56)) (6.2.0)\n",
      "Requirement already satisfied: stack-data==0.6.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 57)) (0.6.0)\n",
      "Requirement already satisfied: tenacity==8.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 58)) (8.1.0)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 59)) (3.1.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 60)) (2.0.1)\n",
      "Requirement already satisfied: tornado==6.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 61)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.64.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 62)) (4.64.1)\n",
      "Requirement already satisfied: traitlets==5.5.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 63)) (5.5.0)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 64)) (0.2.5)\n",
      "Requirement already satisfied: xgboost==1.7.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 65)) (1.7.0)\n",
      "Requirement already satisfied: plotly in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from catboost==1.1.1->-r requirements_nogeo.txt (line 5)) (5.11.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from geopy==2.2.0->-r requirements_nogeo.txt (line 20)) (1.52)\n",
      "Requirement already satisfied: appnope in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.17.0->-r requirements_nogeo.txt (line 22)) (0.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from ipython==8.6.0->-r requirements_nogeo.txt (line 23)) (4.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->ipython==8.6.0->-r requirements_nogeo.txt (line 23)) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements_nogeo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/grunnkrets_norway_stripped.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m pd\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mchained_assignment \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# default='warn'\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m spatial \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../data/grunnkrets_norway_stripped.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     35\u001b[0m age \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../data/grunnkrets_age_distribution.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m income \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../data/grunnkrets_income_households.csv\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mset_index([\u001b[39m'\u001b[39m\u001b[39mgrunnkrets_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39madd_prefix(\u001b[39m'\u001b[39m\u001b[39mincome_\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/grunnkrets_norway_stripped.csv'"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "import warnings\n",
    "import os.path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import geopy\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import shutil\n",
    "# import geopandas as gpd\n",
    "import catboost as cb\n",
    "import optuna\n",
    "from pyproj import Geod\n",
    "import joblib\n",
    "\n",
    "from xgboost import XGBRegressor, plot_importance, to_graphviz, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.cluster import KMeans\n",
    "from k_fold import random_k_fold\n",
    "from shapely import wkt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from utils import squared_log, rmsle_xgb, add_city_centre_dist, group_ages, to_categorical, nan_to_string, object_encoder, only_2016_data\n",
    "from k_fold import random_k_fold, xgb_cross_validation\n",
    "from objectives_and_metrics import rmsle, RmsleMetric, RmsleObjective, LogTargetsRmsleMetric, RmseObjective\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "spatial = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "age = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "income = pd.read_csv('data/grunnkrets_income_households.csv').set_index(['grunnkrets_id', 'year']).add_prefix('income_').reset_index()\n",
    "households = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "plaace = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "\n",
    "train = pd.read_csv('data/stores_train.csv')\n",
    "test = pd.read_csv('data/stores_test.csv') \n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "model_name = \"modeling/0002.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df: pd.DataFrame, min_val=0, max_val=100):\n",
    "    print('Length of data frame:', len(df))\n",
    "    df = df[(df.revenue > min_val) & (df.revenue < max_val)]\n",
    "    print('Length after removing extreme values and zero revenue retail stores:',  len(df))\n",
    "    plt.hist(np.log1p(train.revenue), 30)\n",
    "    plt.show()\n",
    "    return df.drop(columns=['revenue']), df.revenue\n",
    "\n",
    "\n",
    "label_name = 'revenue'\n",
    "X = train.drop(columns=[label_name])\n",
    "y = np.log1p(train[label_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.x Data cleaning\n",
    "\n",
    "The train and test data only contains data from 2016, so for the other datasets with an age column\n",
    "we only use the values from 2016, where possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_2016 = only_2016_data(spatial)\n",
    "income_2016 = only_2016_data(income)\n",
    "households_2016 = only_2016_data(households)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Futhermore, we noticed that the datasets in the cell above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spatial_no_nan = train_spatial[pd.notnull(train_spatial.grunnkrets_name)]\n",
    "train_income_no_nan = train_income[pd.notnull(train_income.income_all_households)]\n",
    "train_house_no_nan = train_house[pd.notnull(train_house.couple_children_0_to_5_years)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df: pd.DataFrame, min_val=0, max_val=100):\n",
    "    print('Length of data frame:', len(df))\n",
    "    df = df[(df.revenue > min_val) & (df.revenue < max_val)]\n",
    "    print('Length after removing extreme values and zero revenue retail stores:',  len(df))\n",
    "    plt.hist(np.log1p(train.revenue), 30)\n",
    "    plt.show()\n",
    "    return df.drop(columns=['revenue']), df.revenue\n",
    "\n",
    "\n",
    "def clean_out_nan_heavy_rows(df: pd.DataFrame):\n",
    "    \"\"\"Cleans out rows that have no match in the age, spatial, income or household datasets.\"\"\"\n",
    "\n",
    "    df2 = df.merge(group_ages(age, age_ranges), on='grunnkrets_id', how='left')\n",
    "    df2 = df2.merge(spatial_2016.drop(columns=['year']), on='grunnkrets_id', how='left')\n",
    "    df2 = df2.merge(income_2016.drop(columns=['year']), on='grunnkrets_id', how='left')\n",
    "    df2 = df2.merge(households_2016.drop(columns=['year']), on='grunnkrets_id', how='left')\n",
    "\n",
    "    df_cleaned = df[\n",
    "        ~(df2.age_0_19.isna() | df2.couple_children_0_to_5_years.isna() | df2.grunnkrets_name.isna() | df2.income_all_households.isna())  \n",
    "    ]\n",
    "\n",
    "    print(f'Cleaned out {len(df) - len(df_cleaned)} out of {len(df)} rows.')\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "train = clean_out_nan_heavy_rows(train)\n",
    "label_name = 'revenue'\n",
    "X = train.drop(columns=[label_name])\n",
    "y = train[label_name]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8) # , random_state=SEED\n",
    "X_train, y_train = clean(pd.merge(X_train, y_train, left_index=True, right_index=True))\n",
    "\n",
    "y_train = np.log1p(y_train)\n",
    "y_val = np.log1p(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df: pd.DataFrame, data_origin: str, predictor: str = ''):\n",
    "    age_ranges = [\n",
    "        (0, 19),\n",
    "        (20, 39),\n",
    "        (40, 59),\n",
    "        (60, 79),\n",
    "        (80, 90),\n",
    "    ]\n",
    "    \n",
    "    # Define datasets to be merged\n",
    "    age_groups_merge = group_ages(age, age_ranges)\n",
    "    # spatial_merge = spatial.drop(columns=['year']).drop_duplicates(subset=['grunnkrets_id'])\n",
    "    # income_merge = income.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    # households_merge = households.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    spatial_merge = spatial_2016.drop(columns=['year'])\n",
    "    income_merge = income_2016.drop(columns=['year'])\n",
    "    households_merge = households_2016.drop(columns=['year'])\n",
    "    plaace_merge = plaace.drop_duplicates(subset='plaace_hierarchy_id')\n",
    "    bus_data_train_merge = gpd.read_parquet(f'derived_data/stores_bus_stops_lt_1km_{data_origin}').drop(columns=['geometry'])\n",
    "    stores_vicinity_merge = gpd.read_parquet(f'derived_data/stores_count_lt_1km_{data_origin}').drop(columns=['geometry'])\n",
    "\n",
    "    # Merge datasets\n",
    "    df = df.merge(spatial_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(age_groups_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(income_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(households_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(plaace_merge, how='left')\n",
    "    df = df.merge(bus_data_train_merge, on='store_id', how='left')\n",
    "    df = df.merge(stores_vicinity_merge, on='store_id', how='left')\n",
    "    df = add_city_centre_dist(df).drop(columns=['lon_center', 'lat_center'])\n",
    "\n",
    "    # Transformations\n",
    "    df.stores_count_lt_1km = df.stores_count_lt_1km.apply(np.log)\n",
    "\n",
    "    # Handle categories for different predictors\n",
    "    if predictor == 'xgb':\n",
    "        # df = to_categorical(df)\n",
    "        df = object_encoder(df)\n",
    "    elif predictor == 'catboost':\n",
    "        df = nan_to_string(df)\n",
    "    else: \n",
    "        raise ValueError('Invalid predictor')\n",
    "\n",
    "    features = [\n",
    "        'store_name', \n",
    "        'mall_name', \n",
    "        'chain_name',\n",
    "        'address', \n",
    "        'lat', 'lon',\n",
    "        \n",
    "        *age_groups_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *income_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *households_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        'lv1_desc', 'lv2_desc', 'sales_channel_name',\n",
    "        *bus_data_train_merge.drop(columns=['store_id']).columns,\n",
    "        *stores_vicinity_merge.drop(columns=['store_id']).columns,\n",
    "        'dist_to_center'\n",
    "    ]\n",
    "\n",
    "    return df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kmeans(df: pd.DataFrame, clusters: int, filter: str):\n",
    "    if filter and filter in df:\n",
    "        data = []\n",
    "        for column in df[filter].unique():\n",
    "            data.append(df[df[filter] == column])\n",
    "        kmeans = []\n",
    "        for i in range(len(data)):\n",
    "            k = KMeans(n_clusters=clusters, random_state=0, verbose=False, max_iter=300).fit(np.column_stack((data[i]['lat'], data[i]['lon'])))\n",
    "            joblib.dump(k, \"kmeans/kmeans\"+str(clusters)+\"_\"+str(filter)+\"_\"+str(df[filter].unique()[i])+\".joblib\")\n",
    "            kmeans.append(k)\n",
    "    else: \n",
    "        kmeans = KMeans(n_clusters=clusters, random_state=0, verbose=False, max_iter=300).fit(np.column_stack((df['lat'], df['lon'])))\n",
    "        joblib.dump(kmeans, \"kmeans/kmeans\"+str(clusters)+\"_\"+str(filter)+\".joblib\")\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_kmeans(df:pd.DataFrame, kmeans: KMeans, filter: str, clusters: int):\n",
    "    if filter and filter in df:\n",
    "        columns = df[filter].unique()\n",
    "        for i in range(len(df[filter].unique())):\n",
    "            column = columns[i]\n",
    "            df.loc[df[filter]== column, 'cluster'] = kmeans[i].predict(np.column_stack((df[df[filter] == column]['lat'], df[df[filter] == column]['lon'])))\n",
    "            #df[df[filter] == column]['cluster'] = kmeans[i].predict(np.column_stack((df[df[filter] == column]['lat'], df[df[filter] == column]['lon'])))\n",
    "    else:\n",
    "        df['cluster'] = kmeans.predict(np.column_stack((df['lat'], df['lon'])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(data):\n",
    "  df = data[['revenue', \n",
    "    # 'age_0_19', 'age_20_39', 'age_40_59', 'age_60_79', 'age_80_90', \n",
    "    # 'bus_stops_count', 'Mangler viktighetsnivå', 'Standard holdeplass', 'Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt', 'Annen viktig holdeplass', \n",
    "    'dist_to_center', 'lat','lon'\n",
    "    ]]\n",
    "  df['knutepunkt'] = data[['Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt']].sum(axis=1)\n",
    "  # df.revenue = np.exp(df.revenue)\n",
    "  # df.bus_stops_count = np.sqrt(df.bus_stops_count)\n",
    "  df = df[df.dist_to_center < 70_000]\n",
    "  # df.dist_to_center = np.log(df.dist_to_center)\n",
    "  \n",
    "  plt.figure(figsize=(15, 15))\n",
    "  pairplot = sns.pairplot(df)\n",
    "  # heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)\n",
    "\n",
    "\n",
    "# data_full =  pd.merge(X_train, y_train, left_index=True, right_index=True) \n",
    "# plot_corr(data_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_buffers(X_train, y_train, X_val, y_val):\n",
    "    # Clear buffers\n",
    "    folder = os.path.join(os.getcwd(), 'modeling')\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "            print(f'Deleted file: {file_path}')\n",
    "\n",
    "    train_buffer_path = 'modeling/train.buffer'\n",
    "    test_buffer_path = 'modeling/test.buffer'\n",
    "\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train, enable_categorical=True)\n",
    "    dtrain.save_binary(train_buffer_path)\n",
    "    print(f'--> {train_buffer_path} created and saved.')\n",
    "\n",
    "    dvalid = xgb.DMatrix(data=X_val, label=y_val, enable_categorical=True)\n",
    "    dvalid.save_binary(test_buffer_path)\n",
    "    print(f'--> {test_buffer_path} created and saved.')\n",
    "\n",
    "    return dtrain, dvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.best_score_)\n",
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(rmsle(y_train, y_pred_train))\n",
    "# print(rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model(X_train, y_train, X_val, y_val):\n",
    "    params = {'colsample_bytree': 0.7717138210314867, 'learning_rate': 0.047506668950627134, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 223, 'subsample': 0.9929036803032936}\n",
    "    print('Clearing and creating buffers...')\n",
    "    dtrain, dvalid = clear_buffers(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    rand_search_model = random_k_fold(X_train, y_train, verbose=1, n_iter=100)\n",
    "    model = rand_search_model\n",
    "    params = model.best_params_\n",
    "    print(rand_search_model.best_score_, params)\n",
    "    \n",
    "    # params = {'colsample_bytree': 0.8601277878899238, 'eval_metric': 'rmsle', 'gamma': 0.12760202929262826, 'learning_rate': 0.07356461924449906, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 306, 'objective': 'reg:squaredlogerror', 'subsample': 0.8993341396761092}\n",
    "    \n",
    "    params['disable_default_eval_metric'] = True\n",
    "    # model = XGBRegressor()\n",
    "    # model.set_params(**params)\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred_train = model.predict(X_train)\n",
    "    # y_pred_val = model.predict(X_val)\n",
    "    # print(rmsle(y_train, y_pred_train))\n",
    "    # print(rmsle(y_val, y_pred_val))\n",
    "\n",
    "    # num_round = 999\n",
    "    # watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "    # print(\"Attempting to start training...\")\n",
    "    # model = xgb.train(\n",
    "    #     params=params, \n",
    "    #     dtrain=dtrain, \n",
    "    #     num_boost_round=num_round, \n",
    "    #     evals=watchlist, \n",
    "    #     early_stopping_rounds=10, \n",
    "    #     verbose_eval=20)\n",
    "    # print(\"--> model trained.\")\n",
    "    # print('Best score:', model.best_score)\n",
    "\n",
    "    # print(\"Attempting to save model...\")\n",
    "    # model.save_model(model_name)\n",
    "    # print(\"--> model saved.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "# X_train, X_val = generate_features(X_train, predictor='xgb'), generate_features(X_val, predictor='xgb')\n",
    "\n",
    "# model = train_xgb_model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(rmsle(y_train, y_pred_train))\n",
    "# print(rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_prediction(X_test, model):\n",
    "    dtest = xgb.DMatrix(data=X_test, enable_categorical=True)\n",
    "\n",
    "    print(\"\\nAttempting to start prediction...\")\n",
    "    y_pred = model.predict(dtest, ntree_limit=model.best_iteration)\n",
    "    print(\"--> Prediction finished.\")\n",
    "\n",
    "    print(\"\\nAttempting to save prediction...\")\n",
    "    submission['predicted'] = np.array(y_pred)\n",
    "    submission.to_csv('submissions/submission.csv', index=False)\n",
    "    print(\"--> prediction saved with features as name in submission folder.\")\n",
    "\n",
    "\n",
    "# X_test = generate_features(test, predictor='xgb')\n",
    "# xgb_prediction(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = model.best_estimator_ if model.best_estimator_ is not None else model\n",
    "# xgb_model = model\n",
    "# plot_importance(xgb_model)\n",
    "# xgb.to_graphviz(xgb_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features for Catboost predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " store_id                                    0\n",
      "year                                        0\n",
      "store_name                                  0\n",
      "plaace_hierarchy_id                         0\n",
      "sales_channel_name                          0\n",
      "grunnkrets_id                               0\n",
      "address                                  1424\n",
      "lat                                         0\n",
      "lon                                         0\n",
      "chain_name                               7328\n",
      "mall_name                                8437\n",
      "grunnkrets_name                         10287\n",
      "district_name                           10287\n",
      "municipality_name                       10287\n",
      "geometry                                10287\n",
      "area_km2                                10287\n",
      "age_0_19                                  609\n",
      "age_20_39                                 609\n",
      "age_40_59                                 609\n",
      "age_60_79                                 609\n",
      "age_80_90                                 609\n",
      "income_all_households                      23\n",
      "income_singles                             23\n",
      "income_couple_without_children             23\n",
      "income_couple_with_children                23\n",
      "income_other_households                    23\n",
      "income_single_parent_with_children         23\n",
      "couple_children_0_to_5_years               84\n",
      "couple_children_18_or_above                84\n",
      "couple_children_6_to_17_years              84\n",
      "couple_without_children                    84\n",
      "single_parent_children_0_to_5_years        84\n",
      "single_parent_children_18_or_above         84\n",
      "single_parent_children_6_to_17_years       84\n",
      "singles                                    84\n",
      "lv1                                         0\n",
      "lv1_desc                                    0\n",
      "lv2                                         0\n",
      "lv2_desc                                    0\n",
      "lv3                                         0\n",
      "lv3_desc                                    0\n",
      "lv4                                         0\n",
      "lv4_desc                                    0\n",
      "bus_stops_count                             0\n",
      "Mangler viktighetsnivå                      0\n",
      "Standard holdeplass                         0\n",
      "Lokalt knutepunkt                           0\n",
      "Nasjonalt knutepunkt                        0\n",
      "Regionalt knutepunkt                        0\n",
      "Annen viktig holdeplass                     0\n",
      "stores_count_lt_1km                         0\n",
      "dist_to_center                              0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      " store_id                                   0\n",
      "year                                       0\n",
      "store_name                                 0\n",
      "plaace_hierarchy_id                        0\n",
      "sales_channel_name                         0\n",
      "grunnkrets_id                              0\n",
      "address                                  350\n",
      "lat                                        0\n",
      "lon                                        0\n",
      "chain_name                              1794\n",
      "mall_name                               2142\n",
      "grunnkrets_name                         2572\n",
      "district_name                           2572\n",
      "municipality_name                       2572\n",
      "geometry                                2572\n",
      "area_km2                                2572\n",
      "age_0_19                                 196\n",
      "age_20_39                                196\n",
      "age_40_59                                196\n",
      "age_60_79                                196\n",
      "age_80_90                                196\n",
      "income_all_households                     10\n",
      "income_singles                            10\n",
      "income_couple_without_children            10\n",
      "income_couple_with_children               10\n",
      "income_other_households                   10\n",
      "income_single_parent_with_children        10\n",
      "couple_children_0_to_5_years              40\n",
      "couple_children_18_or_above               40\n",
      "couple_children_6_to_17_years             40\n",
      "couple_without_children                   40\n",
      "single_parent_children_0_to_5_years       40\n",
      "single_parent_children_18_or_above        40\n",
      "single_parent_children_6_to_17_years      40\n",
      "singles                                   40\n",
      "lv1                                        0\n",
      "lv1_desc                                   0\n",
      "lv2                                        0\n",
      "lv2_desc                                   0\n",
      "lv3                                        0\n",
      "lv3_desc                                   0\n",
      "lv4                                        0\n",
      "lv4_desc                                   0\n",
      "bus_stops_count                            0\n",
      "Mangler viktighetsnivå                     0\n",
      "Standard holdeplass                        0\n",
      "Lokalt knutepunkt                          0\n",
      "Nasjonalt knutepunkt                       0\n",
      "Regionalt knutepunkt                       0\n",
      "Annen viktig holdeplass                    0\n",
      "stores_count_lt_1km                        0\n",
      "dist_to_center                             0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      " store_id                                   0\n",
      "year                                       0\n",
      "store_name                                 0\n",
      "plaace_hierarchy_id                        0\n",
      "sales_channel_name                         0\n",
      "grunnkrets_id                              0\n",
      "address                                 1237\n",
      "lat                                        0\n",
      "lon                                        0\n",
      "chain_name                              6099\n",
      "mall_name                               7084\n",
      "grunnkrets_name                         8577\n",
      "district_name                           8577\n",
      "municipality_name                       8577\n",
      "geometry                                8577\n",
      "area_km2                                8577\n",
      "age_0_19                                 511\n",
      "age_20_39                                511\n",
      "age_40_59                                511\n",
      "age_60_79                                511\n",
      "age_80_90                                511\n",
      "income_all_households                     27\n",
      "income_singles                            27\n",
      "income_couple_without_children            27\n",
      "income_couple_with_children               27\n",
      "income_other_households                   27\n",
      "income_single_parent_with_children        27\n",
      "couple_children_0_to_5_years              70\n",
      "couple_children_18_or_above               70\n",
      "couple_children_6_to_17_years             70\n",
      "couple_without_children                   70\n",
      "single_parent_children_0_to_5_years       70\n",
      "single_parent_children_18_or_above        70\n",
      "single_parent_children_6_to_17_years      70\n",
      "singles                                   70\n",
      "lv1                                        0\n",
      "lv1_desc                                   0\n",
      "lv2                                        0\n",
      "lv2_desc                                   0\n",
      "lv3                                        0\n",
      "lv3_desc                                   0\n",
      "lv4                                        0\n",
      "lv4_desc                                   0\n",
      "bus_stops_count                            0\n",
      "Mangler viktighetsnivå                     0\n",
      "Standard holdeplass                        0\n",
      "Lokalt knutepunkt                          0\n",
      "Nasjonalt knutepunkt                       0\n",
      "Regionalt knutepunkt                       0\n",
      "Annen viktig holdeplass                    0\n",
      "stores_count_lt_1km                        0\n",
      "dist_to_center                             0\n",
      "dtype: int64\n",
      "10287 2572\n"
     ]
    }
   ],
   "source": [
    "filter = 'lv1_desc'\n",
    "clusters = 10\n",
    "\n",
    "X_train_extra = pd.concat([train, extra])\n",
    "X_train_extra = generate_features(X_train_extra, predictor='catboost')\n",
    "kmeans = generate_kmeans(X_train_extra, clusters=clusters, filter=filter)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "# X_train, y_train = clean(pd.merge(X_train, y_train, left_index=True, right_index=True))\n",
    "\n",
    "X_train = generate_features(X_train, data_origin='train', predictor='catboost')\n",
    "X_val = generate_features(X_val, data_origin='train', predictor='catboost')\n",
    "X_test = generate_features(test, data_origin='test', predictor='catboost')\n",
    "\n",
    "# auxillary_columns = ['address']\n",
    "text_features = ['store_name', 'address', 'sales_channel_name'] \n",
    "cat_features = ['mall_name', 'chain_name', 'lv1_desc', 'lv2_desc']\n",
    "\n",
    "X_train.to_csv('xtrain.csv', index=False)\n",
    "train_pool = cb.Pool(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")\n",
    "\n",
    "valid_pool = cb.Pool(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")\n",
    "\n",
    "print(len(X_train), len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-09 13:40:52,812]\u001b[0m A new study created in memory with name: catboost-tuning\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc43f2bd41742cd96c481ffde84073b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-09 13:41:18,283]\u001b[0m Trial 0 finished with value: 0.726526253877934 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3982817713250909}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:41:20,352]\u001b[0m Trial 1 finished with value: 0.7501095022059352 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:41:24,963]\u001b[0m Trial 2 finished with value: 0.7736112551215502 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 8.117373101773806}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:41:29,446]\u001b[0m Trial 3 finished with value: 0.7282037013062744 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9849527582125648}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:41:44,118]\u001b[0m Trial 4 finished with value: 0.726625529880392 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:42:01,868]\u001b[0m Trial 5 finished with value: 0.752746159831501 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.215985707569979}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:42:09,157]\u001b[0m Trial 6 finished with value: 0.7282401098516393 and parameters: {'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.3830846621643544}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:42:18,580]\u001b[0m Trial 7 finished with value: 0.729040279779496 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.860707649912776}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:42:24,828]\u001b[0m Trial 8 finished with value: 0.7290578490010204 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8968191864920909}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:42:30,594]\u001b[0m Trial 9 finished with value: 0.7274355382297978 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9240929037747342}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:42:33,895]\u001b[0m Trial 10 finished with value: 0.7379742485038354 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.1789599524458749}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:42:40,062]\u001b[0m Trial 11 finished with value: 0.7460727870718881 and parameters: {'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:42:47,068]\u001b[0m Trial 12 finished with value: 0.7417904212899079 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:42:52,873]\u001b[0m Trial 13 finished with value: 0.7375806142491798 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:43:08,680]\u001b[0m Trial 14 finished with value: 0.7377109783649796 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:43:23,292]\u001b[0m Trial 15 finished with value: 0.7278192122614298 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:43:34,477]\u001b[0m Trial 16 finished with value: 0.7296726032628781 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.34430873045544447}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:43:44,430]\u001b[0m Trial 17 finished with value: 0.7271354354148403 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:43:48,055]\u001b[0m Trial 18 finished with value: 0.7279281171757556 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3600154733239399}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:44:02,399]\u001b[0m Trial 19 finished with value: 0.72934463827677 and parameters: {'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4264617625371061}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:44:05,723]\u001b[0m Trial 20 finished with value: 0.7383828090641903 and parameters: {'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:44:12,875]\u001b[0m Trial 21 finished with value: 0.7318662554561659 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:44:23,889]\u001b[0m Trial 22 finished with value: 0.728284310584041 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:44:32,552]\u001b[0m Trial 23 finished with value: 0.7294574006331046 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:44:38,154]\u001b[0m Trial 24 finished with value: 0.7341397619045342 and parameters: {'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:44:53,064]\u001b[0m Trial 25 finished with value: 0.7314542266637934 and parameters: {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.11538537569729926}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:44:55,337]\u001b[0m Trial 26 finished with value: 0.7472807754498603 and parameters: {'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:45:01,436]\u001b[0m Trial 27 finished with value: 0.7274066143329464 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5181576007844023}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:45:18,726]\u001b[0m Trial 28 finished with value: 0.7287226984156702 and parameters: {'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 4.061303643641643}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:45:21,295]\u001b[0m Trial 29 finished with value: 0.7539558384423806 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:45:28,872]\u001b[0m Trial 30 finished with value: 0.7301476904596205 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:45:34,693]\u001b[0m Trial 31 finished with value: 0.7294904449323876 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.546038900636301}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:45:40,308]\u001b[0m Trial 32 finished with value: 0.7287616065405232 and parameters: {'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.50788136537141}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:45:46,917]\u001b[0m Trial 33 finished with value: 0.7305333255915225 and parameters: {'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.23866821835986282}. Best is trial 0 with value: 0.726526253877934.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:45:50,851]\u001b[0m Trial 34 finished with value: 0.7262710686082202 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5440626479056618}. Best is trial 34 with value: 0.7262710686082202.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:45:54,538]\u001b[0m Trial 35 finished with value: 0.803875789754684 and parameters: {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.527492660578169}. Best is trial 34 with value: 0.7262710686082202.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:45:58,236]\u001b[0m Trial 36 finished with value: 0.7241278761610153 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6282459279350283}. Best is trial 36 with value: 0.7241278761610153.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:02,146]\u001b[0m Trial 37 finished with value: 0.7240542543813596 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6289157788726831}. Best is trial 37 with value: 0.7240542543813596.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:06,060]\u001b[0m Trial 38 finished with value: 0.7240593552318421 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.635788486618146}. Best is trial 37 with value: 0.7240542543813596.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:08,786]\u001b[0m Trial 39 finished with value: 0.7271964278149853 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.630784815959324}. Best is trial 37 with value: 0.7240542543813596.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:13,487]\u001b[0m Trial 40 finished with value: 0.7238610010254907 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.662047075530231}. Best is trial 40 with value: 0.7238610010254907.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:17,258]\u001b[0m Trial 41 finished with value: 0.7256761248676465 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6815142157850569}. Best is trial 40 with value: 0.7238610010254907.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:22,051]\u001b[0m Trial 42 finished with value: 0.7234093186907611 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7075641530459916}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:26,254]\u001b[0m Trial 43 finished with value: 0.7240452766238107 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7139640561737679}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:29,428]\u001b[0m Trial 44 finished with value: 0.7252144966691254 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7340039533876481}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:33,484]\u001b[0m Trial 45 finished with value: 0.7238375659494479 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7337263666923214}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:37,362]\u001b[0m Trial 46 finished with value: 0.7238961254103595 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7535371310608324}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:40,743]\u001b[0m Trial 47 finished with value: 0.7257765861984299 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7678573103823637}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:44,596]\u001b[0m Trial 48 finished with value: 0.724874016409811 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.44465257394675034}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:48,230]\u001b[0m Trial 49 finished with value: 0.7237853905400541 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7807895452444127}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:51,858]\u001b[0m Trial 50 finished with value: 0.7255585917891411 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8006486830063653}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:55,910]\u001b[0m Trial 51 finished with value: 0.7245298738504969 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7608313363829664}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:46:58,359]\u001b[0m Trial 52 finished with value: 0.7276791497147534 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7765695095633943}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:01,238]\u001b[0m Trial 53 finished with value: 0.7271427776778718 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6926123660661309}. Best is trial 42 with value: 0.7234093186907611.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:05,326]\u001b[0m Trial 54 finished with value: 0.7228888694155761 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9820598794985642}. Best is trial 54 with value: 0.7228888694155761.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:08,987]\u001b[0m Trial 55 finished with value: 0.7243343492623334 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9388717687040639}. Best is trial 54 with value: 0.7228888694155761.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:12,699]\u001b[0m Trial 56 finished with value: 0.725155279190537 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9963770960393508}. Best is trial 54 with value: 0.7228888694155761.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:17,601]\u001b[0m Trial 57 finished with value: 0.7325573035057992 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 3.9667891018109103}. Best is trial 54 with value: 0.7228888694155761.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:20,432]\u001b[0m Trial 58 finished with value: 0.7238976401590492 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8598603001428139}. Best is trial 54 with value: 0.7228888694155761.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:24,264]\u001b[0m Trial 59 finished with value: 0.7231400504862104 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.865773105431216}. Best is trial 54 with value: 0.7228888694155761.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:28,051]\u001b[0m Trial 60 finished with value: 0.722866699912874 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.875850470715977}. Best is trial 60 with value: 0.722866699912874.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:31,605]\u001b[0m Trial 61 finished with value: 0.7217851485153627 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8738872739763993}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:34,297]\u001b[0m Trial 62 finished with value: 0.7247949277021465 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9810173481233899}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:37,647]\u001b[0m Trial 63 finished with value: 0.7235160060241412 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8464426210978576}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:40,950]\u001b[0m Trial 64 finished with value: 0.7237428271445336 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8766274314196567}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:44,321]\u001b[0m Trial 65 finished with value: 0.7237559532399898 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8889401055388083}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:48,651]\u001b[0m Trial 66 finished with value: 0.7492423090678115 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.341028000668974}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:51,602]\u001b[0m Trial 67 finished with value: 0.725612007795082 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8748636690315875}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:55,543]\u001b[0m Trial 68 finished with value: 0.7227638233797553 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8731565485549917}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:47:59,643]\u001b[0m Trial 69 finished with value: 0.7260307897716092 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.998728947124183}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:04,239]\u001b[0m Trial 70 finished with value: 0.7289180305729638 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.25104882324362116}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:07,143]\u001b[0m Trial 71 finished with value: 0.7250655040330025 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8653276944638549}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:10,304]\u001b[0m Trial 72 finished with value: 0.72539941154626 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8484841594072092}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:13,609]\u001b[0m Trial 73 finished with value: 0.7249925477810002 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9134856495611139}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:17,200]\u001b[0m Trial 74 finished with value: 0.7249946753028711 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8318572310757528}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:20,429]\u001b[0m Trial 75 finished with value: 0.7255292089497626 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.921205225852661}. Best is trial 61 with value: 0.7217851485153627.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:25,043]\u001b[0m Trial 76 finished with value: 0.7216150638721303 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8288508104485234}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:30,277]\u001b[0m Trial 77 finished with value: 0.7307185556564465 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.652557109883676}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:33,918]\u001b[0m Trial 78 finished with value: 0.7253279926904732 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5852044909070534}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:36,952]\u001b[0m Trial 79 finished with value: 0.724014530420677 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8230841529293653}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:39,670]\u001b[0m Trial 80 finished with value: 0.7246456643911459 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9947676288434207}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:43,490]\u001b[0m Trial 81 finished with value: 0.7244836780237935 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9076734283041763}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:46,226]\u001b[0m Trial 82 finished with value: 0.7255698117125748 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8444827556560107}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:49,924]\u001b[0m Trial 83 finished with value: 0.7248329689381706 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.708751615594187}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:53,535]\u001b[0m Trial 84 finished with value: 0.7236471849560153 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8124086741143207}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:48:58,314]\u001b[0m Trial 85 finished with value: 0.7301964741622632 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.1417811031828637}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:02,334]\u001b[0m Trial 86 finished with value: 0.7260413461181774 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6775327950602218}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:06,177]\u001b[0m Trial 87 finished with value: 0.7237941068076605 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8216703778782426}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:09,313]\u001b[0m Trial 88 finished with value: 0.7267607187170321 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4394170789049796}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:12,733]\u001b[0m Trial 89 finished with value: 0.7290728820389464 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.2965216630693812}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:16,389]\u001b[0m Trial 90 finished with value: 0.7238153704404703 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6045133411173396}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:20,121]\u001b[0m Trial 91 finished with value: 0.7256618080821677 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9387954884112977}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:23,408]\u001b[0m Trial 92 finished with value: 0.7238714066327708 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7988494113904451}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:28,030]\u001b[0m Trial 93 finished with value: 0.7234471027314914 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7343150806161355}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:31,409]\u001b[0m Trial 94 finished with value: 0.7255850741935447 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7273599377750705}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:35,018]\u001b[0m Trial 95 finished with value: 0.7233178003145458 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7714647044029165}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:41,219]\u001b[0m Trial 96 finished with value: 0.7958722106697528 and parameters: {'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.813563234597046}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:44,889]\u001b[0m Trial 97 finished with value: 0.7242017641661801 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6612321201170799}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:50,013]\u001b[0m Trial 98 finished with value: 0.7217047162547683 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.743203051762809}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "\u001b[32m[I 2022-11-09 13:49:52,477]\u001b[0m Trial 99 finished with value: 0.7539558384423806 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 76 with value: 0.7216150638721303.\u001b[0m\n",
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "Value: 0.7216150638721303\n",
      "Params:\n",
      "{'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8288508104485234}\n"
     ]
    }
   ],
   "source": [
    "from catboost.utils import get_gpu_device_count\n",
    "\n",
    "gpu_count = get_gpu_device_count()\n",
    "\n",
    "non_tunable_params = {\n",
    "    'objective': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'task_type': 'GPU' if gpu_count else 'CPU', \n",
    "    'devices': f'0:{gpu_count}'\n",
    "}\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    tunable_params = {\n",
    "        'depth': trial.suggest_int('depth', 4, 9),\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "        # 'iterations': trial.suggest_int('iterations', 1000, 2000),\n",
    "        # 'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 2, 4),\n",
    "    }\n",
    "\n",
    "    kmeans_param = {\n",
    "        'clusters': trial.suggest_int('clusters', 10, 50),\n",
    "        'filter': trial.suggest_categorical('filter', ['lv1_desc', 'lv2_desc', False])\n",
    "    }\n",
    "    \n",
    "    kmeans = generate_kmeans(X_train_extra, **kmeans_param)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "    X_train, X_val = generate_features(X_train, predictor='catboost'), generate_features(X_val, predictor='catboost')\n",
    "    X_train, X_val = predict_kmeans(X_train, kmeans, **kmeans_param), predict_kmeans(X_val, kmeans, **kmeans_param)\n",
    "    y_train, \n",
    "    train_pool = cb.Pool(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cat_features=cat_features,\n",
    "        text_features=text_features,\n",
    "        feature_names=list(X_train)\n",
    "    )\n",
    "\n",
    "    valid_pool = cb.Pool(\n",
    "        X_val,\n",
    "        y_val,\n",
    "        cat_features=cat_features,\n",
    "        text_features=text_features,\n",
    "        feature_names=list(X_train)\n",
    "    )\n",
    "\n",
    "    if param['bootstrap_type'] == 'Bayesian': \n",
    "        param['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    elif param['bootstrap_type'] == 'Bernoulli':\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.1, 1, log=True)\n",
    "\n",
    "    cbr = cb.CatBoostRegressor(**param, task_type='CPU', devices='0:1')\n",
    "    \n",
    "    # pruning_callback = optuna.integration.CatBoostPruningCallback(trial, 'LogTargetsRmsleMetric')\n",
    "    if tunable_params['bootstrap_type'] == 'Bayesian': \n",
    "        tunable_params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    elif tunable_params['bootstrap_type'] == 'Bernoulli':\n",
    "        tunable_params['subsample'] = trial.suggest_float('subsample', 0.1, 1, log=True)\n",
    "\n",
    "    cbr = cb.CatBoostRegressor(**non_tunable_params, **tunable_params) \n",
    "    cbr.fit(\n",
    "        train_pool,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=True,\n",
    "        early_stopping_rounds=50,\n",
    "    )\n",
    "\n",
    "    y_pred = cbr.predict(X_val)\n",
    "    score = rmsle(np.expm1(y_val), np.expm1(y_pred))\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def tuned_hyperparameters():\n",
    "    study = optuna.create_study(\n",
    "        study_name='catboost-tuning',\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), \n",
    "        direction='minimize'\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=900, show_progress_bar=True) \n",
    "\n",
    "    print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "    print('Best trial:')\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print('Value:', trial.value)\n",
    "    print('Params:')\n",
    "    print(trial.params)\n",
    "\n",
    "    return trial.params\n",
    "\n",
    "\n",
    "tuned_params = tuned_hyperparameters()\n",
    "# tuned_params = {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7494756089749968}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd08bad282e44283a4d8812a5c3a9718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.073422\n",
      "0:\tlearn: 1.0040598\ttest: 0.9895524\tbest: 0.9895524 (0)\ttotal: 21.9ms\tremaining: 21.9s\n",
      "50:\tlearn: 0.7651243\ttest: 0.7574132\tbest: 0.7574132 (50)\ttotal: 1.1s\tremaining: 20.5s\n",
      "100:\tlearn: 0.7463352\ttest: 0.7454019\tbest: 0.7454019 (100)\ttotal: 2.09s\tremaining: 18.6s\n",
      "150:\tlearn: 0.7324013\ttest: 0.7385452\tbest: 0.7385452 (150)\ttotal: 3.07s\tremaining: 17.3s\n",
      "200:\tlearn: 0.7199191\ttest: 0.7348295\tbest: 0.7348295 (200)\ttotal: 4.07s\tremaining: 16.2s\n",
      "250:\tlearn: 0.7109668\ttest: 0.7330781\tbest: 0.7330781 (250)\ttotal: 5.05s\tremaining: 15.1s\n",
      "300:\tlearn: 0.7036817\ttest: 0.7321571\tbest: 0.7321332 (291)\ttotal: 6.03s\tremaining: 14s\n",
      "350:\tlearn: 0.6964346\ttest: 0.7303929\tbest: 0.7303607 (349)\ttotal: 7.1s\tremaining: 13.1s\n",
      "400:\tlearn: 0.6914414\ttest: 0.7292969\tbest: 0.7292529 (397)\ttotal: 8.18s\tremaining: 12.2s\n",
      "450:\tlearn: 0.6861766\ttest: 0.7283429\tbest: 0.7283367 (449)\ttotal: 9.24s\tremaining: 11.2s\n",
      "500:\tlearn: 0.6812082\ttest: 0.7275097\tbest: 0.7275097 (500)\ttotal: 10.3s\tremaining: 10.2s\n",
      "550:\tlearn: 0.6757590\ttest: 0.7269327\tbest: 0.7268978 (536)\ttotal: 11.3s\tremaining: 9.17s\n",
      "600:\tlearn: 0.6712506\ttest: 0.7264423\tbest: 0.7264423 (600)\ttotal: 12.2s\tremaining: 8.12s\n",
      "650:\tlearn: 0.6671882\ttest: 0.7262773\tbest: 0.7262327 (649)\ttotal: 13.2s\tremaining: 7.1s\n",
      "700:\tlearn: 0.6632976\ttest: 0.7259311\tbest: 0.7257753 (696)\ttotal: 14.2s\tremaining: 6.06s\n",
      "750:\tlearn: 0.6590154\ttest: 0.7256710\tbest: 0.7256384 (749)\ttotal: 15.2s\tremaining: 5.04s\n",
      "800:\tlearn: 0.6550711\ttest: 0.7255335\tbest: 0.7254577 (769)\ttotal: 16.2s\tremaining: 4.02s\n",
      "850:\tlearn: 0.6515604\ttest: 0.7255484\tbest: 0.7254577 (769)\ttotal: 17.2s\tremaining: 3s\n",
      "900:\tlearn: 0.6484650\ttest: 0.7255092\tbest: 0.7253194 (859)\ttotal: 18.1s\tremaining: 1.99s\n",
      "950:\tlearn: 0.6459477\ttest: 0.7253097\tbest: 0.7252556 (935)\ttotal: 19.1s\tremaining: 986ms\n",
      "999:\tlearn: 0.6432491\ttest: 0.7252158\tbest: 0.7251565 (992)\ttotal: 20.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7251565052\n",
      "bestIteration = 992\n",
      "\n",
      "Shrink model to first 993 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Slower, but due to an issue with Catboost, training on the CPU often yields a better result than on the GPU \n",
    "non_tunable_params['task_type'] = 'CPU'\n",
    "\n",
    "model = cb.CatBoostRegressor(**non_tunable_params, **tuned_params, iterations=1000)\n",
    "model.fit(train_pool, eval_set=valid_pool, verbose=50, plot=True)\n",
    "\n",
    "y_pred = np.expm1(model.predict(X_test))\n",
    "submission['predicted'] = y_pred\n",
    "submission.to_csv('submissions/submission.csv', index=False)\n",
    "\n",
    "# model.save_model(f'models/{model.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = cb.CatBoostRegressor(**non_tunable_params, **tuned_params, iterations=1000).load_model('models/070034')\n",
    "# y_pred = np.expm1(loaded_model.predict(X_val))\n",
    "# rmsle(np.expm1(y_val), y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
