{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==2.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: attrs==22.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (22.1.0)\n",
      "Requirement already satisfied: autopep8==2.0.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: catboost==1.1.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: certifi==2022.9.24 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (2022.9.24)\n",
      "Requirement already satisfied: click==8.1.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: click-plugins==1.1.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: cligj==0.7.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: colorama==0.4.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: contourpy==1.0.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (1.0.6)\n",
      "Requirement already satisfied: cycler==0.11.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.11.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (0.29.28)\n",
      "Requirement already satisfied: debugpy==1.6.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (1.6.3)\n",
      "Requirement already satisfied: decorator==5.1.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (5.1.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: executing==1.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: Fiona==1.8.22 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (1.8.22)\n",
      "Requirement already satisfied: fonttools==4.38.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 19)) (4.38.0)\n",
      "Requirement already satisfied: gensim==4.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 20)) (4.2.0)\n",
      "Requirement already satisfied: geographiclib==1.52 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 21)) (1.52)\n",
      "Requirement already satisfied: geopandas==0.12.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 22)) (0.12.1)\n",
      "Requirement already satisfied: geopy==2.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 23)) (2.2.0)\n",
      "Requirement already satisfied: graphviz==0.20.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 24)) (0.20.1)\n",
      "Requirement already satisfied: ipykernel==6.17.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 25)) (6.17.0)\n",
      "Requirement already satisfied: ipython==8.6.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 26)) (8.6.0)\n",
      "Requirement already satisfied: jedi==0.18.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 27)) (0.18.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 28)) (1.2.0)\n",
      "Requirement already satisfied: jupyter_client==7.4.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 29)) (7.4.4)\n",
      "Requirement already satisfied: jupyter_core==4.11.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 30)) (4.11.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 31)) (1.4.4)\n",
      "Requirement already satisfied: matplotlib==3.6.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 32)) (3.6.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 33)) (0.1.6)\n",
      "Requirement already satisfied: munch==2.5.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 34)) (2.5.0)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 35)) (1.5.6)\n",
      "Requirement already satisfied: numpy==1.23.4 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 36)) (1.23.4)\n",
      "Requirement already satisfied: packaging==21.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 37)) (21.3)\n",
      "Requirement already satisfied: pandas==1.5.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 38)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 39)) (0.8.3)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 40)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==9.3.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 41)) (9.3.0)\n",
      "Requirement already satisfied: plotly==5.11.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 42)) (5.11.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.31 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 43)) (3.0.31)\n",
      "Requirement already satisfied: psutil==5.9.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 44)) (5.9.3)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 45)) (0.2.2)\n",
      "Requirement already satisfied: pyarrow==10.0.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 46)) (10.0.0)\n",
      "Requirement already satisfied: pycodestyle==2.9.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 47)) (2.9.1)\n",
      "Requirement already satisfied: pygeos==0.13 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 48)) (0.13)\n",
      "Requirement already satisfied: Pygments==2.13.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 49)) (2.13.0)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 50)) (3.0.9)\n",
      "Requirement already satisfied: pyproj==3.4.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 51)) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 52)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 53)) (2022.6)\n",
      "Requirement already satisfied: pyzmq==24.0.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 54)) (24.0.1)\n",
      "Requirement already satisfied: scikit-learn==1.1.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 55)) (1.1.3)\n",
      "Requirement already satisfied: scipy==1.9.3 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 56)) (1.9.3)\n",
      "Requirement already satisfied: seaborn==0.12.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 57)) (0.12.1)\n",
      "Requirement already satisfied: Shapely==1.8.5.post1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 58)) (1.8.5.post1)\n",
      "Requirement already satisfied: six==1.16.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 59)) (1.16.0)\n",
      "Requirement already satisfied: sklearn==0.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 60)) (0.0)\n",
      "Requirement already satisfied: smart-open==6.2.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 61)) (6.2.0)\n",
      "Requirement already satisfied: stack-data==0.6.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 62)) (0.6.0)\n",
      "Requirement already satisfied: tenacity==8.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 63)) (8.1.0)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 64)) (3.1.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 65)) (2.0.1)\n",
      "Requirement already satisfied: tornado==6.2 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 66)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.64.1 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 67)) (4.64.1)\n",
      "Requirement already satisfied: traitlets==5.5.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 68)) (5.5.0)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 69)) (0.2.5)\n",
      "Requirement already satisfied: xgboost==1.7.0 in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 70)) (1.7.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.8/site-packages (from Fiona==1.8.22->-r requirements.txt (line 18)) (44.0.0)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in ./venv/lib/python3.8/site-packages (from ipython==8.6.0->-r requirements.txt (line 26)) (4.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython==8.6.0->-r requirements.txt (line 26)) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import warnings\n",
    "import os.path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import shutil\n",
    "import geopandas as gpd\n",
    "import catboost as cb\n",
    "import optuna\n",
    "\n",
    "from xgboost import XGBRegressor, plot_importance, to_graphviz, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "from k_fold import random_k_fold\n",
    "from shapely import wkt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from utils import squared_log, rmsle_xgb, add_city_centre_dist, group_ages, to_categorical, nan_to_string, object_encoder\n",
    "from k_fold import random_k_fold, xgb_cross_validation\n",
    "from objectives_and_metrics import rmsle, RmsleMetric, RmsleObjective, LogTargetsRmsleMetric, RmseObjective\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "spatial = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "age = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "income = pd.read_csv('data/grunnkrets_income_households.csv').set_index(['grunnkrets_id', 'year']).add_prefix('income_').reset_index()\n",
    "households = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "plaace = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "\n",
    "train = pd.read_csv('data/stores_train.csv')\n",
    "test = pd.read_csv('data/stores_test.csv')\n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "model_name = \"modeling/0002.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "train = train.drop(train[0 < train.revenue < 50 ])\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df: pd.DataFrame, predictor: str = ''):\n",
    "    age_ranges = [\n",
    "        (0, 19),\n",
    "        (20, 39),\n",
    "        (40, 59),\n",
    "        (60, 79),\n",
    "        (80, 90),\n",
    "    ]\n",
    "    \n",
    "    # Define datasets to be merged\n",
    "    spatial_merge = spatial.drop(columns=['year']).drop_duplicates(subset=['grunnkrets_id'])\n",
    "    age_groups_merge = group_ages(age, age_ranges)\n",
    "    income_merge = income.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    households_merge = households.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    plaace_merge = plaace.drop_duplicates(subset='plaace_hierarchy_id')\n",
    "    bus_data_train_merge = gpd.read_parquet('derived_data/stores_bus_stops_lt_1km_train').drop(columns=['geometry'])\n",
    "\n",
    "    # Merge datasets\n",
    "    df = df.merge(spatial_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(age_groups_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(income_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(households_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(plaace_merge, how='left')\n",
    "    df = df.merge(bus_data_train_merge, on='store_id', how='left')\n",
    "    df = add_city_centre_dist(df).drop(columns=['lon_center', 'lat_center'])\n",
    "\n",
    "    # Handle categories for different predictors\n",
    "    if predictor == 'xgb':\n",
    "        # df = to_categorical(df)\n",
    "        df = object_encoder(df)\n",
    "    elif predictor == 'catboost':\n",
    "        df = nan_to_string(df)\n",
    "    else: \n",
    "        raise ValueError('Invalid predictor')\n",
    "\n",
    "    features = [\n",
    "        'store_name', \n",
    "        'mall_name', \n",
    "        'chain_name',\n",
    "        'address', \n",
    "        'lat', 'lon',\n",
    "        \n",
    "        *age_groups_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *income_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *households_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        'lv1_desc', 'lv2_desc',\n",
    "        *bus_data_train_merge.drop(columns=['store_id']).columns,\n",
    "        'dist_to_center'\n",
    "    ]\n",
    "\n",
    "    return df[features]\n",
    "\n",
    "\n",
    "label_name = 'revenue'\n",
    "X = train.drop(columns=[label_name])\n",
    "y = np.log1p(train[label_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(data):\n",
    "  df = data[['revenue', \n",
    "    # 'age_0_19', 'age_20_39', 'age_40_59', 'age_60_79', 'age_80_90', \n",
    "    # 'bus_stops_count', 'Mangler viktighetsnivå', 'Standard holdeplass', 'Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt', 'Annen viktig holdeplass', \n",
    "    'dist_to_center', 'lat','lon'\n",
    "    ]]\n",
    "  df['knutepunkt'] = data[['Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt']].sum(axis=1)\n",
    "  # df.revenue = np.exp(df.revenue)\n",
    "  # df.bus_stops_count = np.sqrt(df.bus_stops_count)\n",
    "  df = df[df.dist_to_center < 70_000]\n",
    "  # df.dist_to_center = np.log(df.dist_to_center)\n",
    "  \n",
    "  plt.figure(figsize=(15, 15))\n",
    "  pairplot = sns.pairplot(df)\n",
    "  # heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)\n",
    "\n",
    "\n",
    "# data_full =  pd.merge(X_train, y_train, left_index=True, right_index=True) \n",
    "# plot_corr(data_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_buffers(X_train, y_train, X_val, y_val):\n",
    "    # Clear buffers\n",
    "    folder = os.path.join(os.getcwd(), 'modeling')\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "            print(f'Deleted file: {file_path}')\n",
    "\n",
    "    train_buffer_path = 'modeling/train.buffer'\n",
    "    test_buffer_path = 'modeling/test.buffer'\n",
    "\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train, enable_categorical=True)\n",
    "    dtrain.save_binary(train_buffer_path)\n",
    "    print(f'--> {train_buffer_path} created and saved.')\n",
    "\n",
    "    dvalid = xgb.DMatrix(data=X_val, label=y_val, enable_categorical=True)\n",
    "    dvalid.save_binary(test_buffer_path)\n",
    "    print(f'--> {test_buffer_path} created and saved.')\n",
    "\n",
    "    return dtrain, dvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.best_score_)\n",
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(rmsle(y_train, y_pred_train))\n",
    "# print(rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model(X_train, y_train, X_val, y_val):\n",
    "    params = {'colsample_bytree': 0.7717138210314867, 'learning_rate': 0.047506668950627134, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 223, 'subsample': 0.9929036803032936}\n",
    "    print('Clearing and creating buffers...')\n",
    "    dtrain, dvalid = clear_buffers(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    rand_search_model = random_k_fold(X_train, y_train, verbose=1, n_iter=100)\n",
    "    model = rand_search_model\n",
    "    params = model.best_params_\n",
    "    print(rand_search_model.best_score_, params)\n",
    "    \n",
    "    # params = {'colsample_bytree': 0.8601277878899238, 'eval_metric': 'rmsle', 'gamma': 0.12760202929262826, 'learning_rate': 0.07356461924449906, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 306, 'objective': 'reg:squaredlogerror', 'subsample': 0.8993341396761092}\n",
    "    \n",
    "    params['disable_default_eval_metric'] = True\n",
    "    # model = XGBRegressor()\n",
    "    # model.set_params(**params)\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred_train = model.predict(X_train)\n",
    "    # y_pred_val = model.predict(X_val)\n",
    "    # print(rmsle(y_train, y_pred_train))\n",
    "    # print(rmsle(y_val, y_pred_val))\n",
    "\n",
    "    # num_round = 999\n",
    "    # watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "    # print(\"Attempting to start training...\")\n",
    "    # model = xgb.train(\n",
    "    #     params=params, \n",
    "    #     dtrain=dtrain, \n",
    "    #     num_boost_round=num_round, \n",
    "    #     evals=watchlist, \n",
    "    #     early_stopping_rounds=10, \n",
    "    #     verbose_eval=20)\n",
    "    # print(\"--> model trained.\")\n",
    "    # print('Best score:', model.best_score)\n",
    "\n",
    "    # print(\"Attempting to save model...\")\n",
    "    # model.save_model(model_name)\n",
    "    # print(\"--> model saved.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "# X_train, X_val = generate_features(X_train, predictor='xgb'), generate_features(X_val, predictor='xgb')\n",
    "\n",
    "# model = train_xgb_model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(rmsle(y_train, y_pred_train))\n",
    "# print(rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_prediction(X_test, model):\n",
    "    dtest = xgb.DMatrix(data=X_test, enable_categorical=True)\n",
    "\n",
    "    print(\"\\nAttempting to start prediction...\")\n",
    "    y_pred = model.predict(dtest, ntree_limit=model.best_iteration)\n",
    "    print(\"--> Prediction finished.\")\n",
    "\n",
    "    print(\"\\nAttempting to save prediction...\")\n",
    "    submission['predicted'] = np.array(y_pred)\n",
    "    submission.to_csv('submissions/submission.csv', index=False)\n",
    "    print(\"--> prediction saved with features as name in submission folder.\")\n",
    "\n",
    "\n",
    "# X_test = generate_features(test, predictor='xgb')\n",
    "# xgb_prediction(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = model.best_estimator_ if model.best_estimator_ is not None else model\n",
    "# xgb_model = model\n",
    "# plot_importance(xgb_model)\n",
    "# xgb.to_graphviz(xgb_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features for Catboost predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "X_train, X_val = generate_features(X_train, predictor='catboost'), generate_features(X_val, predictor='catboost')\n",
    "X_test = generate_features(test, predictor='catboost')\n",
    "\n",
    "auxillary_columns = ['address']\n",
    "text_features = ['store_name', 'address']\n",
    "cat_features = ['mall_name', 'chain_name', 'lv1_desc', 'lv2_desc']\n",
    "\n",
    "train_pool = cb.Pool(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")\n",
    "\n",
    "valid_pool = cb.Pool(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import get_gpu_device_count\n",
    "\n",
    "gpu_count = get_gpu_device_count()\n",
    "\n",
    "non_tunable_params = {\n",
    "    'objective': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    # 'task_type': 'GPU' if gpu_count else 'CPU', \n",
    "    # 'devices': f'0:{gpu_count}'\n",
    "}\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    tunable_params = {\n",
    "        'depth': trial.suggest_int('depth', 4, 9),\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "        # 'iterations': trial.suggest_int('iterations', 1000, 2000),\n",
    "        # 'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 2, 5),\n",
    "    }\n",
    "\n",
    "    if tunable_params['bootstrap_type'] == 'Bayesian': \n",
    "        tunable_params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    elif tunable_params['bootstrap_type'] == 'Bernoulli':\n",
    "        tunable_params['subsample'] = trial.suggest_float('subsample', 0.1, 1, log=True)\n",
    "\n",
    "    cbr = cb.CatBoostRegressor(**non_tunable_params, **tunable_params) \n",
    "    cbr.fit(\n",
    "        train_pool,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=50,\n",
    "    )\n",
    "\n",
    "    y_pred = cbr.predict(X_val)\n",
    "    score = rmsle(np.expm1(y_val), np.expm1(y_pred))\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def tuned_hyperparameters():\n",
    "    study = optuna.create_study(\n",
    "        study_name='catboost-tuning',\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), \n",
    "        direction='minimize'\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=900, show_progress_bar=True) \n",
    "\n",
    "    print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "    print('Best trial:')\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print('Value:', trial.value)\n",
    "    print('Params:')\n",
    "    print(trial.params)\n",
    "\n",
    "    return trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-07 20:58:47,926]\u001b[0m A new study created in memory with name: catboost-tuning\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f553779b20be4ef0949d412818096ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-07 20:59:10,361]\u001b[0m Trial 0 finished with value: 0.7428208610419315 and parameters: {'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.475207901582971}. Best is trial 0 with value: 0.7428208610419315.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 20:59:20,798]\u001b[0m Trial 1 finished with value: 0.7393468700770415 and parameters: {'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7921852969001372}. Best is trial 1 with value: 0.7393468700770415.\u001b[0m\n",
      "\u001b[32m[I 2022-11-07 21:00:22,199]\u001b[0m Trial 2 finished with value: 0.7773825788045545 and parameters: {'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 8.385734245539695}. Best is trial 1 with value: 0.7393468700770415.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tuned_params = tuned_hyperparameters()\n",
    "\n",
    "print(non_tunable_params)\n",
    "\n",
    "model = cb.CatBoostRegressor(**non_tunable_params, **tuned_params)\n",
    "model.fit(train_pool, eval_set=valid_pool, verbose=50, plot=True)\n",
    "\n",
    "y_pred = np.expm1(model.predict(X_test))\n",
    "submission['predicted'] = y_pred\n",
    "submission.to_csv('submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.expm1(model.predict(X_test))\n",
    "submission['predicted'] = y_pred\n",
    "submission.to_csv('submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(test)\n",
    "# y_pred\n",
    "\n",
    "a = 10\n",
    "log_a = np.log1p(a)\n",
    "exp_log_a = np.expm1(log_a)\n",
    "\n",
    "print(a, exp_log_a)\n",
    "\n",
    "model.best_score_\n",
    "\n",
    "y_pred = np.expm1()\n",
    "submission['predicted'] = np.array(y_pred)\n",
    "submission.to_csv('submissions/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'depth': randint(2, 20),\n",
    "    'learning_rate': uniform(0.01, 0.4),\n",
    "    'iterations': randint(10, 1000)\n",
    "}\n",
    "\n",
    "model = cb.CatBoostRegressor(loss_function=RmsleObjective, eval_metric=RmsleMetric)\n",
    "\n",
    "\n",
    "# model.randomized_search(train_pool, param_distributions=params, cv=5)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "rmsle = (np.sqrt(mean_squared_log_error(y_val, pred)))\n",
    "print('Testing performance')\n",
    "print('RMSLE: {:.2f}'.format(rmsle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1beb4c19f9c9850d9088b15a4a1b3063555a573f9fb8d1ae667cbe7a8ada917e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
