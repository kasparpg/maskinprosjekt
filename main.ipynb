{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: asttokens==2.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: attrs==22.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 2)) (22.1.0)\n",
      "Requirement already satisfied: autopep8==2.0.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: catboost==1.1.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: certifi==2022.9.24 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 6)) (2022.9.24)\n",
      "Requirement already satisfied: click==8.1.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: click-plugins==1.1.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: cligj==0.7.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: colorama==0.4.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: contourpy==1.0.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 11)) (1.0.6)\n",
      "Requirement already satisfied: cycler==0.11.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 12)) (0.11.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 13)) (0.29.28)\n",
      "Requirement already satisfied: debugpy==1.6.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 14)) (1.6.3)\n",
      "Requirement already satisfied: decorator==5.1.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 15)) (5.1.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: executing==1.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: fonttools==4.38.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 18)) (4.38.0)\n",
      "Requirement already satisfied: gensim==4.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 19)) (4.2.0)\n",
      "Requirement already satisfied: geopy==2.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 20)) (2.2.0)\n",
      "Requirement already satisfied: graphviz==0.20.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 21)) (0.20.1)\n",
      "Requirement already satisfied: ipykernel==6.17.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 22)) (6.17.0)\n",
      "Requirement already satisfied: ipython==8.6.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 23)) (8.6.0)\n",
      "Requirement already satisfied: jedi==0.18.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 24)) (0.18.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 25)) (1.2.0)\n",
      "Requirement already satisfied: jupyter_client==7.4.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 26)) (7.4.4)\n",
      "Requirement already satisfied: jupyter_core==4.11.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 27)) (4.11.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 28)) (1.4.4)\n",
      "Requirement already satisfied: matplotlib==3.6.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 29)) (3.6.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 30)) (0.1.6)\n",
      "Requirement already satisfied: munch==2.5.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 31)) (2.5.0)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 32)) (1.5.6)\n",
      "Requirement already satisfied: numpy==1.23.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 33)) (1.23.4)\n",
      "Requirement already satisfied: packaging==21.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 34)) (21.3)\n",
      "Requirement already satisfied: pandas==1.5.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 35)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 36)) (0.8.3)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 37)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==9.3.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 38)) (9.3.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.31 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 39)) (3.0.31)\n",
      "Requirement already satisfied: psutil==5.9.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 40)) (5.9.3)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 41)) (0.2.2)\n",
      "Requirement already satisfied: pyarrow==10.0.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 42)) (10.0.0)\n",
      "Requirement already satisfied: pycodestyle==2.9.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 43)) (2.9.1)\n",
      "Requirement already satisfied: Pygments==2.13.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 44)) (2.13.0)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 45)) (3.0.9)\n",
      "Requirement already satisfied: pyproj==3.4.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 46)) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 47)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 48)) (2022.6)\n",
      "Requirement already satisfied: pyzmq==24.0.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 49)) (24.0.1)\n",
      "Requirement already satisfied: scikit-learn==1.1.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 50)) (1.1.3)\n",
      "Requirement already satisfied: scipy==1.9.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 51)) (1.9.3)\n",
      "Requirement already satisfied: seaborn==0.12.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 52)) (0.12.1)\n",
      "Requirement already satisfied: Shapely==1.8.5.post1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 53)) (1.8.5.post1)\n",
      "Requirement already satisfied: six==1.16.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 54)) (1.16.0)\n",
      "Requirement already satisfied: sklearn==0.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 55)) (0.0)\n",
      "Requirement already satisfied: smart-open==6.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 56)) (6.2.0)\n",
      "Requirement already satisfied: stack-data==0.6.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 57)) (0.6.0)\n",
      "Requirement already satisfied: tenacity==8.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 58)) (8.1.0)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 59)) (3.1.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 60)) (2.0.1)\n",
      "Requirement already satisfied: tornado==6.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 61)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.64.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 62)) (4.64.1)\n",
      "Requirement already satisfied: traitlets==5.5.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 63)) (5.5.0)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 64)) (0.2.5)\n",
      "Requirement already satisfied: xgboost==1.7.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 65)) (1.7.0)\n",
      "Requirement already satisfied: plotly in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from catboost==1.1.1->-r requirements_nogeo.txt (line 5)) (5.11.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from geopy==2.2.0->-r requirements_nogeo.txt (line 20)) (1.52)\n",
      "Requirement already satisfied: appnope in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.17.0->-r requirements_nogeo.txt (line 22)) (0.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from ipython==8.6.0->-r requirements_nogeo.txt (line 23)) (4.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->ipython==8.6.0->-r requirements_nogeo.txt (line 23)) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements_nogeo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import warnings\n",
    "import os.path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import geopy\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import shutil\n",
    "# import geopandas as gpd\n",
    "import catboost as cb\n",
    "import optuna\n",
    "from pyproj import Geod\n",
    "import joblib\n",
    "\n",
    "from xgboost import XGBRegressor, plot_importance, to_graphviz, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.cluster import KMeans\n",
    "from k_fold import random_k_fold\n",
    "from shapely import wkt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from utils import squared_log, rmsle_xgb, add_city_centre_dist, group_ages, to_categorical, nan_to_string, object_encoder\n",
    "from k_fold import random_k_fold, xgb_cross_validation\n",
    "from objectives_and_metrics import _rmsle, RmsleMetric, RmsleObjective, LogTargetsRmsleMetric, RmseObjective\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "spatial = pd.read_csv('../data/grunnkrets_norway_stripped.csv')\n",
    "age = pd.read_csv('../data/grunnkrets_age_distribution.csv')\n",
    "income = pd.read_csv('../data/grunnkrets_income_households.csv').set_index(['grunnkrets_id', 'year']).add_prefix('income_').reset_index()\n",
    "households = pd.read_csv('../data/grunnkrets_households_num_persons.csv')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "plaace = pd.read_csv('../data/plaace_hierarchy.csv')\n",
    "busstops = pd.read_csv('../data/busstops_norway.csv')\n",
    "\n",
    "train = pd.read_csv('../data/stores_train.csv')\n",
    "extra = pd.read_csv('../data/stores_extra.csv')\n",
    "test = pd.read_csv('../data/stores_test.csv')\n",
    "\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "model_name = \"modeling/0002.model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df: pd.DataFrame, predictor: str = ''):\n",
    "    age_ranges = [\n",
    "        (0, 19),\n",
    "        (20, 39),\n",
    "        (40, 59),\n",
    "        (60, 79),\n",
    "        (80, 90),\n",
    "    ]\n",
    "    \n",
    "    # Define datasets to be merged\n",
    "    spatial_merge = spatial.drop(columns=['year']).drop_duplicates(subset=['grunnkrets_id'])\n",
    "    age_groups_merge = group_ages(age, age_ranges)\n",
    "    income_merge = income.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    households_merge = households.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    plaace_merge = plaace.drop_duplicates(subset='plaace_hierarchy_id')\n",
    "    bus_data_train_merge = pd.read_parquet('derived_data/stores_bus_stops_lt_1km_train').drop(columns=['geometry'])\n",
    "\n",
    "    # Merge datasets\n",
    "    df = df.merge(spatial_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(age_groups_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(income_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(households_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(plaace_merge, how='left')\n",
    "    df = df.merge(bus_data_train_merge, on='store_id', how='left')\n",
    "    # df = add_city_centre_dist(df).drop(columns=['lon_center', 'lat_center'])\n",
    "    \n",
    "    # Handle categories for different predictors\n",
    "    if predictor == 'xgb':\n",
    "        # df = to_categorical(df)\n",
    "        df = object_encoder(df)\n",
    "    elif predictor == 'catboost':\n",
    "        df = nan_to_string(df)\n",
    "    else: \n",
    "        raise ValueError('Invalid predictor')\n",
    "\n",
    "    features = [\n",
    "        'store_name', \n",
    "        'mall_name', \n",
    "        'chain_name',\n",
    "        'address', \n",
    "        'lat', 'lon',\n",
    "        \n",
    "        *age_groups_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *income_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *households_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        'lv1_desc', 'lv2_desc',\n",
    "        *bus_data_train_merge.drop(columns=['store_id']).columns\n",
    "    ]\n",
    "\n",
    "    return df[features]\n",
    "\n",
    "\n",
    "label_name = 'revenue'\n",
    "X = train.drop(columns=[label_name])\n",
    "y = np.log1p(train[label_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kmeans(df: pd.DataFrame, clusters: int, filter: str):\n",
    "    if filter and filter in df:\n",
    "        data = []\n",
    "        for column in df[filter].unique():\n",
    "            data.append(df[df[filter] == column])\n",
    "        kmeans = []\n",
    "        for i in range(len(data)):\n",
    "            k = KMeans(n_clusters=clusters, random_state=0, verbose=False, max_iter=300).fit(np.column_stack((data[i]['lat'], data[i]['lon'])))\n",
    "            joblib.dump(k, \"kmeans/kmeans_\"+str(filter)+\"_\"+str(df[filter].unique()[i])+\".joblib\")\n",
    "            kmeans.append(k)\n",
    "    else: \n",
    "        kmeans = KMeans(n_clusters=clusters, random_state=0, verbose=False, max_iter=300).fit(np.column_stack((df['lat'], df['lon'])))\n",
    "        joblib.dump(kmeans, \"kmeans/kmeans_\"+str(filter)+\".joblib\")\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_kmeans(df:pd.DataFrame, kmeans: KMeans, filter: str):\n",
    "    if filter and filter in df:\n",
    "        columns = df[filter].unique()\n",
    "        for i in range(len(df[filter].unique())):\n",
    "            column = columns[i]\n",
    "            df.loc[df[filter]== column, 'cluster'] = kmeans[i].predict(np.column_stack((df[df[filter] == column]['lat'], df[df[filter] == column]['lon'])))\n",
    "            #df[df[filter] == column]['cluster'] = kmeans[i].predict(np.column_stack((df[df[filter] == column]['lat'], df[df[filter] == column]['lon'])))\n",
    "    else:\n",
    "        df['cluster'] = kmeans.predict(np.column_stack((df['lat'], df['lon'])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(data):\n",
    "  df = data[['revenue', \n",
    "    # 'age_0_19', 'age_20_39', 'age_40_59', 'age_60_79', 'age_80_90', \n",
    "    # 'bus_stops_count', 'Mangler viktighetsnivå', 'Standard holdeplass', 'Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt', 'Annen viktig holdeplass', \n",
    "    'dist_to_center', 'lat','lon'\n",
    "    ]]\n",
    "  df['knutepunkt'] = data[['Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt']].sum(axis=1)\n",
    "  # df.revenue = np.exp(df.revenue)\n",
    "  # df.bus_stops_count = np.sqrt(df.bus_stops_count)\n",
    "  df = df[df.dist_to_center < 70_000]\n",
    "  # df.dist_to_center = np.log(df.dist_to_center)\n",
    "  \n",
    "  plt.figure(figsize=(15, 15))\n",
    "  pairplot = sns.pairplot(df)\n",
    "  # heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)\n",
    "\n",
    "\n",
    "# data_full =  pd.merge(X_train, y_train, left_index=True, right_index=True) \n",
    "# plot_corr(data_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_buffers(X_train, y_train, X_val, y_val):\n",
    "    # Clear buffers\n",
    "    folder = os.path.join(os.getcwd(), 'modeling')\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "            print(f'Deleted file: {file_path}')\n",
    "\n",
    "    train_buffer_path = 'modeling/train.buffer'\n",
    "    test_buffer_path = 'modeling/test.buffer'\n",
    "\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train, enable_categorical=True)\n",
    "    dtrain.save_binary(train_buffer_path)\n",
    "    print(f'--> {train_buffer_path} created and saved.')\n",
    "\n",
    "    dvalid = xgb.DMatrix(data=X_val, label=y_val, enable_categorical=True)\n",
    "    dvalid.save_binary(test_buffer_path)\n",
    "    print(f'--> {test_buffer_path} created and saved.')\n",
    "\n",
    "    return dtrain, dvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.best_score_)\n",
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(_rmsle(y_train, y_pred_train))\n",
    "# print(_rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model(X_train, y_train, X_val, y_val):\n",
    "    params = {'colsample_bytree': 0.7717138210314867, 'learning_rate': 0.047506668950627134, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 223, 'subsample': 0.9929036803032936}\n",
    "    print('Clearing and creating buffers...')\n",
    "    dtrain, dvalid = clear_buffers(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    rand_search_model = random_k_fold(X_train, y_train, verbose=1, n_iter=100)\n",
    "    model = rand_search_model\n",
    "    params = model.best_params_\n",
    "    print(rand_search_model.best_score_, params)\n",
    "    \n",
    "    # params = {'colsample_bytree': 0.8601277878899238, 'eval_metric': 'rmsle', 'gamma': 0.12760202929262826, 'learning_rate': 0.07356461924449906, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 306, 'objective': 'reg:squaredlogerror', 'subsample': 0.8993341396761092}\n",
    "    \n",
    "    params['disable_default_eval_metric'] = True\n",
    "    # model = XGBRegressor()\n",
    "    # model.set_params(**params)\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred_train = model.predict(X_train)\n",
    "    # y_pred_val = model.predict(X_val)\n",
    "    # print(_rmsle(y_train, y_pred_train))\n",
    "    # print(_rmsle(y_val, y_pred_val))\n",
    "\n",
    "    # num_round = 999\n",
    "    # watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "    # print(\"Attempting to start training...\")\n",
    "    # model = xgb.train(\n",
    "    #     params=params, \n",
    "    #     dtrain=dtrain, \n",
    "    #     num_boost_round=num_round, \n",
    "    #     evals=watchlist, \n",
    "    #     early_stopping_rounds=10, \n",
    "    #     verbose_eval=20)\n",
    "    # print(\"--> model trained.\")\n",
    "    # print('Best score:', model.best_score)\n",
    "\n",
    "    # print(\"Attempting to save model...\")\n",
    "    # model.save_model(model_name)\n",
    "    # print(\"--> model saved.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "# X_train, X_val = generate_features(X_train, predictor='xgb'), generate_features(X_val, predictor='xgb')\n",
    "\n",
    "# model = train_xgb_model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(_rmsle(y_train, y_pred_train))\n",
    "# print(_rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_prediction(X_test, model):\n",
    "    dtest = xgb.DMatrix(data=X_test, enable_categorical=True)\n",
    "\n",
    "    print(\"\\nAttempting to start prediction...\")\n",
    "    y_pred = model.predict(dtest, ntree_limit=model.best_iteration)\n",
    "    print(\"--> Prediction finished.\")\n",
    "\n",
    "    print(\"\\nAttempting to save prediction...\")\n",
    "    submission['predicted'] = np.array(y_pred)\n",
    "    submission.to_csv('submissions/submission.csv', index=False)\n",
    "    print(\"--> prediction saved with features as name in submission folder.\")\n",
    "\n",
    "\n",
    "# X_test = generate_features(test, predictor='xgb')\n",
    "# xgb_prediction(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = model.best_estimator_ if model.best_estimator_ is not None else model\n",
    "# xgb_model = model\n",
    "# plot_importance(xgb_model)\n",
    "# xgb.to_graphviz(xgb_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features for Catboost predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10287 entries, 0 to 10286\n",
      "Data columns (total 35 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   store_name                            10287 non-null  object \n",
      " 1   mall_name                             10287 non-null  object \n",
      " 2   chain_name                            10287 non-null  object \n",
      " 3   address                               10287 non-null  object \n",
      " 4   lat                                   10287 non-null  float64\n",
      " 5   lon                                   10287 non-null  float64\n",
      " 6   age_0_19                              10287 non-null  object \n",
      " 7   age_20_39                             10287 non-null  object \n",
      " 8   age_40_59                             10287 non-null  object \n",
      " 9   age_60_79                             10287 non-null  object \n",
      " 10  age_80_90                             10287 non-null  object \n",
      " 11  income_all_households                 10287 non-null  object \n",
      " 12  income_singles                        10287 non-null  object \n",
      " 13  income_couple_without_children        10287 non-null  object \n",
      " 14  income_couple_with_children           10287 non-null  object \n",
      " 15  income_other_households               10287 non-null  object \n",
      " 16  income_single_parent_with_children    10287 non-null  object \n",
      " 17  couple_children_0_to_5_years          10287 non-null  object \n",
      " 18  couple_children_18_or_above           10287 non-null  object \n",
      " 19  couple_children_6_to_17_years         10287 non-null  object \n",
      " 20  couple_without_children               10287 non-null  object \n",
      " 21  single_parent_children_0_to_5_years   10287 non-null  object \n",
      " 22  single_parent_children_18_or_above    10287 non-null  object \n",
      " 23  single_parent_children_6_to_17_years  10287 non-null  object \n",
      " 24  singles                               10287 non-null  object \n",
      " 25  lv1_desc                              10287 non-null  object \n",
      " 26  lv2_desc                              10287 non-null  object \n",
      " 27  bus_stops_count                       10287 non-null  int64  \n",
      " 28  Mangler viktighetsnivå                10287 non-null  int64  \n",
      " 29  Standard holdeplass                   10287 non-null  int64  \n",
      " 30  Lokalt knutepunkt                     10287 non-null  int64  \n",
      " 31  Nasjonalt knutepunkt                  10287 non-null  int64  \n",
      " 32  Regionalt knutepunkt                  10287 non-null  int64  \n",
      " 33  Annen viktig holdeplass               10287 non-null  int64  \n",
      " 34  cluster                               10287 non-null  float64\n",
      "dtypes: float64(3), int64(7), object(25)\n",
      "memory usage: 2.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "filter = 'lv1_desc'\n",
    "X_train_extra = pd.concat([train, extra])\n",
    "X_train_extra = generate_features(X_train_extra, predictor='catboost')\n",
    "kmeans = generate_kmeans(X_train_extra, clusters=110, filter=filter)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "X_train, X_val = generate_features(X_train, predictor='catboost'), generate_features(X_val, predictor='catboost')\n",
    "X_train, X_val = predict_kmeans(X_train, kmeans, filter), predict_kmeans(X_val, kmeans, filter)\n",
    "\n",
    "X_test = generate_features(test, predictor='catboost')\n",
    "\n",
    "auxillary_columns = ['address']\n",
    "text_features = ['store_name', 'address']\n",
    "cat_features = ['mall_name', 'chain_name', 'lv1_desc', 'lv2_desc']\n",
    "\n",
    "train_pool = cb.Pool(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")\n",
    "\n",
    "valid_pool = cb.Pool(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-08 15:37:38,739]\u001b[0m A new study created in memory with name: no-name-2e9fe2fb-5670-4505-a0a6-e7245230ea09\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    param = {\n",
    "        # 'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 3, 9),\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "        'iterations': 1000,\n",
    "        # 'objective': RmseObjective(),\n",
    "        # 'eval_metric': LogTargetsRmsleMetric(),\n",
    "        'objective': 'RMSE',\n",
    "        'eval_metric': 'RMSE'\n",
    "    }\n",
    "\n",
    "    if param['bootstrap_type'] == 'Bayesian': \n",
    "        param['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    elif param['bootstrap_type'] == 'Bernoulli':\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.1, 1, log=True)\n",
    "\n",
    "    cbr = cb.CatBoostRegressor(**param, task_type='CPU', devices='0:1')\n",
    "    \n",
    "    # pruning_callback = optuna.integration.CatBoostPruningCallback(trial, 'LogTargetsRmsleMetric')\n",
    "    cbr.fit(\n",
    "        train_pool,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=50,\n",
    "        # callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    # pruning_callback.check_pruned()\n",
    "\n",
    "    y_pred = np.expm1(cbr.predict(X_val))\n",
    "    score = _rmsle(np.expm1(y_val), y_pred)[1]\n",
    "\n",
    "    # score = np.sqrt(mean_squared_log_error(np.expm1(y_val), y_pred))\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction='minimize')\n",
    "study.optimize(objective, n_trials=100) # timeout=600\n",
    "\n",
    "print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Value:', trial.value)\n",
    "print('Params:')\n",
    "print(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7270089548135714 {'colsample_bylevel': 0.07329097359385545, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.1734504015536018}\n"
     ]
    }
   ],
   "source": [
    "print(trial.value, trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_summary(cv_data):\n",
    "    cv_data.head(10)\n",
    "\n",
    "    best_value = cv_data['test-Logloss-mean'].min()\n",
    "    best_iter = cv_data['test-Logloss-mean'].values.argmin()\n",
    "\n",
    "    print('Best validation Logloss score : {:.4f}±{:.4f} on step {}'.format(\n",
    "        best_value,\n",
    "        cv_data['test-Logloss-std'][best_iter],\n",
    "        best_iter)\n",
    "    )\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 9),\n",
    "    'iterations': [1000]\n",
    "}\n",
    "\n",
    "cbr = cb.CatBoostRegressor(\n",
    "    objective=RmseObjective(), \n",
    "    eval_metric=LogTargetsRmsleMetric(),\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# cbr.randomized_search(param_dist, X=train_pool, cv=3, n_iter=20, shuffle=True, stratified=True, plot=True)\n",
    "\n",
    "# feature_importance = cbr.get_feature_importance(prettified=True)\n",
    "# print('Feature importance:', feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acfef384a704be8894301173d3cb578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.8410715\ttest: 1.8806790\tbest: 1.8806790 (0)\ttotal: 283ms\tremaining: 4m 42s\n",
      "50:\tlearn: 0.9037483\ttest: 0.9133867\tbest: 0.9133867 (50)\ttotal: 15s\tremaining: 4m 39s\n",
      "100:\tlearn: 0.7946943\ttest: 0.7925219\tbest: 0.7925219 (100)\ttotal: 30s\tremaining: 4m 27s\n",
      "150:\tlearn: 0.7723114\ttest: 0.7744926\tbest: 0.7744926 (150)\ttotal: 44.6s\tremaining: 4m 10s\n",
      "200:\tlearn: 0.7627387\ttest: 0.7686614\tbest: 0.7686614 (200)\ttotal: 59.3s\tremaining: 3m 55s\n",
      "250:\tlearn: 0.7560784\ttest: 0.7651931\tbest: 0.7651931 (250)\ttotal: 1m 13s\tremaining: 3m 40s\n",
      "300:\tlearn: 0.7503074\ttest: 0.7628645\tbest: 0.7628645 (300)\ttotal: 1m 28s\tremaining: 3m 25s\n",
      "350:\tlearn: 0.7410254\ttest: 0.7602637\tbest: 0.7602335 (348)\ttotal: 1m 43s\tremaining: 3m 12s\n",
      "400:\tlearn: 0.7316951\ttest: 0.7579294\tbest: 0.7579294 (400)\ttotal: 1m 59s\tremaining: 2m 57s\n",
      "450:\tlearn: 0.7225471\ttest: 0.7555986\tbest: 0.7555986 (450)\ttotal: 2m 14s\tremaining: 2m 43s\n",
      "500:\tlearn: 0.7148193\ttest: 0.7534449\tbest: 0.7534237 (499)\ttotal: 2m 29s\tremaining: 2m 28s\n",
      "550:\tlearn: 0.7073033\ttest: 0.7521592\tbest: 0.7520062 (546)\ttotal: 2m 44s\tremaining: 2m 13s\n",
      "600:\tlearn: 0.6997765\ttest: 0.7510890\tbest: 0.7510147 (596)\ttotal: 2m 59s\tremaining: 1m 59s\n",
      "650:\tlearn: 0.6954346\ttest: 0.7501974\tbest: 0.7501974 (650)\ttotal: 3m 14s\tremaining: 1m 44s\n",
      "700:\tlearn: 0.6904162\ttest: 0.7493964\tbest: 0.7493964 (700)\ttotal: 3m 29s\tremaining: 1m 29s\n",
      "750:\tlearn: 0.6833051\ttest: 0.7484426\tbest: 0.7484426 (750)\ttotal: 3m 44s\tremaining: 1m 14s\n",
      "800:\tlearn: 0.6794273\ttest: 0.7479470\tbest: 0.7478884 (799)\ttotal: 3m 59s\tremaining: 59.4s\n",
      "850:\tlearn: 0.6747235\ttest: 0.7477749\tbest: 0.7477277 (848)\ttotal: 4m 14s\tremaining: 44.5s\n",
      "900:\tlearn: 0.6692142\ttest: 0.7474745\tbest: 0.7472654 (890)\ttotal: 4m 29s\tremaining: 29.6s\n",
      "950:\tlearn: 0.6654026\ttest: 0.7472373\tbest: 0.7471820 (939)\ttotal: 4m 44s\tremaining: 14.7s\n",
      "999:\tlearn: 0.6620101\ttest: 0.7470469\tbest: 0.7469003 (975)\ttotal: 4m 59s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7469003365\n",
      "bestIteration = 975\n",
      "\n",
      "Shrink model to first 976 iterations.\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.03,\n",
    "    # 'objective': RmsleObjective(),\n",
    "    # 'eval_metric': RmsleMetric()\n",
    "    'objective': RmseObjective(),\n",
    "    'eval_metric': LogTargetsRmsleMetric()\n",
    "}\n",
    "\n",
    "params = {'iterations': 1000,\n",
    " 'loss_function': 'RMSE',\n",
    " 'eval_metric': LogTargetsRmsleMetric(),\n",
    " 'objective': RmseObjective(),\n",
    " 'depth': 7.0,\n",
    " 'learning_rate': 0.0494195212108839}\n",
    "\n",
    "params = {'colsample_bylevel': 0.07329097359385545, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.1734504015536018}\n",
    "params = {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.635180352520854}\n",
    "\n",
    "model = cb.CatBoostRegressor(**params, objective=RmseObjective(), eval_metric=LogTargetsRmsleMetric())\n",
    "model.fit(train_pool, eval_set=valid_pool, verbose=50, plot=True)\n",
    "\n",
    "y_pred = np.expm1(model.predict(X_test))\n",
    "submission['predicted'] = y_pred\n",
    "submission.to_csv('submissions/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.expm1(model.predict(X_test))\n",
    "submission['predicted'] = y_pred\n",
    "submission.to_csv('submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10.000000000000002\n"
     ]
    }
   ],
   "source": [
    "# y_pred = model.predict(test)\n",
    "# y_pred\n",
    "\n",
    "a = 10\n",
    "log_a = np.log1p(a)\n",
    "exp_log_a = np.expm1(log_a)\n",
    "\n",
    "print(a, exp_log_a)\n",
    "\n",
    "model.best_score_\n",
    "\n",
    "y_pred = np.expm1()\n",
    "submission['predicted'] = np.array(y_pred)\n",
    "submission.to_csv('submissions/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "There is no trained model to use predict(). Use fit() to train model. Then use this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [228], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[39m=\u001b[39m cb\u001b[39m.\u001b[39mCatBoostRegressor(loss_function\u001b[39m=\u001b[39mRmsleObjective, eval_metric\u001b[39m=\u001b[39mRmsleMetric)\n\u001b[1;32m     10\u001b[0m \u001b[39m# model.randomized_search(train_pool, param_distributions=params, cv=5)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_val)\n\u001b[1;32m     13\u001b[0m rmsle \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39msqrt(mean_squared_log_error(y_val, pred)))\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTesting performance\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:5775\u001b[0m, in \u001b[0;36mCatBoostRegressor.predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5773\u001b[0m \u001b[39mif\u001b[39;00m prediction_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5774\u001b[0m     prediction_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_default_prediction_type()\n\u001b[0;32m-> 5775\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, \u001b[39m'\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m'\u001b[39;49m, task_type)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:2541\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2540\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 2541\u001b[0m data, data_is_single_object \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[1;32m   2542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[1;32m   2544\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:2517\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_process_predict_input_data\u001b[39m(\u001b[39mself\u001b[39m, data, parent_method_name, thread_count, label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2516\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_fitted() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_count_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2517\u001b[0m         \u001b[39mraise\u001b[39;00m CatBoostError((\u001b[39m\"\u001b[39m\u001b[39mThere is no trained model to use \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m(). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2518\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39mUse fit() to train model. Then use this method.\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mformat(parent_method_name))\n\u001b[1;32m   2519\u001b[0m     is_single_object \u001b[39m=\u001b[39m _is_data_single_object(data)\n\u001b[1;32m   2520\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Pool):\n",
      "\u001b[0;31mCatBoostError\u001b[0m: There is no trained model to use predict(). Use fit() to train model. Then use this method."
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'depth': randint(2, 20),\n",
    "    'learning_rate': uniform(0.01, 0.4),\n",
    "    'iterations': randint(10, 1000)\n",
    "}\n",
    "\n",
    "model = cb.CatBoostRegressor(loss_function=RmsleObjective, eval_metric=RmsleMetric)\n",
    "\n",
    "\n",
    "# model.randomized_search(train_pool, param_distributions=params, cv=5)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "rmsle = (np.sqrt(mean_squared_log_error(y_val, pred)))\n",
    "print('Testing performance')\n",
    "print('RMSLE: {:.2f}'.format(rmsle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
