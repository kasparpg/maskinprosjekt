{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: asttokens==2.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: attrs==22.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 2)) (22.1.0)\n",
      "Requirement already satisfied: autopep8==2.0.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: catboost==1.1.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: certifi==2022.9.24 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 6)) (2022.9.24)\n",
      "Requirement already satisfied: click==8.1.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: click-plugins==1.1.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: cligj==0.7.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: colorama==0.4.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: contourpy==1.0.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 11)) (1.0.6)\n",
      "Requirement already satisfied: cycler==0.11.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 12)) (0.11.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 13)) (0.29.28)\n",
      "Requirement already satisfied: debugpy==1.6.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 14)) (1.6.3)\n",
      "Requirement already satisfied: decorator==5.1.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 15)) (5.1.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: executing==1.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: fonttools==4.38.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 18)) (4.38.0)\n",
      "Requirement already satisfied: gensim==4.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 19)) (4.2.0)\n",
      "Requirement already satisfied: geopy==2.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 20)) (2.2.0)\n",
      "Requirement already satisfied: graphviz==0.20.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 21)) (0.20.1)\n",
      "Requirement already satisfied: ipykernel==6.17.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 22)) (6.17.0)\n",
      "Requirement already satisfied: ipython==8.6.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 23)) (8.6.0)\n",
      "Requirement already satisfied: jedi==0.18.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 24)) (0.18.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 25)) (1.2.0)\n",
      "Requirement already satisfied: jupyter_client==7.4.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 26)) (7.4.4)\n",
      "Requirement already satisfied: jupyter_core==4.11.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 27)) (4.11.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 28)) (1.4.4)\n",
      "Requirement already satisfied: matplotlib==3.6.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 29)) (3.6.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 30)) (0.1.6)\n",
      "Requirement already satisfied: munch==2.5.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 31)) (2.5.0)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 32)) (1.5.6)\n",
      "Requirement already satisfied: numpy==1.23.4 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 33)) (1.23.4)\n",
      "Requirement already satisfied: packaging==21.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 34)) (21.3)\n",
      "Requirement already satisfied: pandas==1.5.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 35)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 36)) (0.8.3)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 37)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==9.3.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 38)) (9.3.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.31 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 39)) (3.0.31)\n",
      "Requirement already satisfied: psutil==5.9.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 40)) (5.9.3)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 41)) (0.2.2)\n",
      "Requirement already satisfied: pyarrow==10.0.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 42)) (10.0.0)\n",
      "Requirement already satisfied: pycodestyle==2.9.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 43)) (2.9.1)\n",
      "Requirement already satisfied: Pygments==2.13.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 44)) (2.13.0)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 45)) (3.0.9)\n",
      "Requirement already satisfied: pyproj==3.4.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 46)) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 47)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 48)) (2022.6)\n",
      "Requirement already satisfied: pyzmq==24.0.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 49)) (24.0.1)\n",
      "Requirement already satisfied: scikit-learn==1.1.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 50)) (1.1.3)\n",
      "Requirement already satisfied: scipy==1.9.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 51)) (1.9.3)\n",
      "Requirement already satisfied: seaborn==0.12.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 52)) (0.12.1)\n",
      "Requirement already satisfied: Shapely==1.8.5.post1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 53)) (1.8.5.post1)\n",
      "Requirement already satisfied: six==1.16.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 54)) (1.16.0)\n",
      "Requirement already satisfied: sklearn==0.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 55)) (0.0)\n",
      "Requirement already satisfied: smart-open==6.2.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 56)) (6.2.0)\n",
      "Requirement already satisfied: stack-data==0.6.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 57)) (0.6.0)\n",
      "Requirement already satisfied: tenacity==8.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 58)) (8.1.0)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 59)) (3.1.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 60)) (2.0.1)\n",
      "Requirement already satisfied: tornado==6.2 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 61)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.64.1 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 62)) (4.64.1)\n",
      "Requirement already satisfied: traitlets==5.5.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 63)) (5.5.0)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 64)) (0.2.5)\n",
      "Requirement already satisfied: xgboost==1.7.0 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from -r requirements_nogeo.txt (line 65)) (1.7.0)\n",
      "Requirement already satisfied: plotly in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from catboost==1.1.1->-r requirements_nogeo.txt (line 5)) (5.11.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from geopy==2.2.0->-r requirements_nogeo.txt (line 20)) (1.52)\n",
      "Requirement already satisfied: appnope in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from ipykernel==6.17.0->-r requirements_nogeo.txt (line 22)) (0.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from ipython==8.6.0->-r requirements_nogeo.txt (line 23)) (4.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/Jobb/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->ipython==8.6.0->-r requirements_nogeo.txt (line 23)) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements_nogeo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import warnings\n",
    "import os.path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import geopy\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import shutil\n",
    "# import geopandas as gpd\n",
    "import catboost as cb\n",
    "import optuna\n",
    "from pyproj import Geod\n",
    "import joblib\n",
    "\n",
    "from xgboost import XGBRegressor, plot_importance, to_graphviz, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.cluster import KMeans\n",
    "from k_fold import random_k_fold\n",
    "from shapely import wkt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from utils import squared_log, rmsle_xgb, add_city_centre_dist, group_ages, to_categorical, nan_to_string, object_encoder\n",
    "from k_fold import random_k_fold, xgb_cross_validation\n",
    "from objectives_and_metrics import _rmsle, RmsleMetric, RmsleObjective, LogTargetsRmsleMetric, RmseObjective\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "spatial = pd.read_csv('../data/grunnkrets_norway_stripped.csv')\n",
    "age = pd.read_csv('../data/grunnkrets_age_distribution.csv')\n",
    "income = pd.read_csv('../data/grunnkrets_income_households.csv').set_index(['grunnkrets_id', 'year']).add_prefix('income_').reset_index()\n",
    "households = pd.read_csv('../data/grunnkrets_households_num_persons.csv')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "plaace = pd.read_csv('../data/plaace_hierarchy.csv')\n",
    "busstops = pd.read_csv('../data/busstops_norway.csv')\n",
    "\n",
    "train = pd.read_csv('../data/stores_train.csv')\n",
    "extra = pd.read_csv('../data/stores_extra.csv')\n",
    "test = pd.read_csv('../data/stores_test.csv')\n",
    "\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "model_name = \"modeling/0002.model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df: pd.DataFrame, predictor: str = ''):\n",
    "    age_ranges = [\n",
    "        (0, 19),\n",
    "        (20, 39),\n",
    "        (40, 59),\n",
    "        (60, 79),\n",
    "        (80, 90),\n",
    "    ]\n",
    "    \n",
    "    # Define datasets to be merged\n",
    "    spatial_merge = spatial.drop(columns=['year']).drop_duplicates(subset=['grunnkrets_id'])\n",
    "    age_groups_merge = group_ages(age, age_ranges)\n",
    "    income_merge = income.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    households_merge = households.drop(columns=['year']).drop_duplicates(subset='grunnkrets_id')\n",
    "    plaace_merge = plaace.drop_duplicates(subset='plaace_hierarchy_id')\n",
    "    bus_data_train_merge = pd.read_parquet('derived_data/stores_bus_stops_lt_1km_train').drop(columns=['geometry'])\n",
    "\n",
    "    # Merge datasets\n",
    "    df = df.merge(spatial_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(age_groups_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(income_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(households_merge, on='grunnkrets_id', how='left')\n",
    "    df = df.merge(plaace_merge, how='left')\n",
    "    df = df.merge(bus_data_train_merge, on='store_id', how='left')\n",
    "    # df = add_city_centre_dist(df).drop(columns=['lon_center', 'lat_center'])\n",
    "    \n",
    "    # Handle categories for different predictors\n",
    "    if predictor == 'xgb':\n",
    "        # df = to_categorical(df)\n",
    "        df = object_encoder(df)\n",
    "    elif predictor == 'catboost':\n",
    "        df = nan_to_string(df)\n",
    "    else: \n",
    "        raise ValueError('Invalid predictor')\n",
    "\n",
    "    features = [\n",
    "        'store_name', \n",
    "        'mall_name', \n",
    "        'chain_name',\n",
    "        'address', \n",
    "        'lat', 'lon',\n",
    "        \n",
    "        *age_groups_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *income_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        *households_merge.drop(columns=['grunnkrets_id']).columns,\n",
    "        'lv1_desc', 'lv2_desc',\n",
    "        *bus_data_train_merge.drop(columns=['store_id']).columns\n",
    "    ]\n",
    "\n",
    "    return df[features]\n",
    "\n",
    "\n",
    "label_name = 'revenue'\n",
    "X = train.drop(columns=[label_name])\n",
    "y = np.log1p(train[label_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kmeans(df: pd.DataFrame, clusters: int, filter: str):\n",
    "    if filter and filter in df:\n",
    "        data = []\n",
    "        for column in df[filter].unique():\n",
    "            data.append(df[df[filter] == column])\n",
    "        kmeans = []\n",
    "        for i in range(len(data)):\n",
    "            k = KMeans(n_clusters=clusters, random_state=0, verbose=False, max_iter=300).fit(np.column_stack((data[i]['lat'], data[i]['lon'])))\n",
    "            joblib.dump(k, \"kmeans/kmeans\"+str(clusters)+\"_\"+str(filter)+\"_\"+str(df[filter].unique()[i])+\".joblib\")\n",
    "            kmeans.append(k)\n",
    "    else: \n",
    "        kmeans = KMeans(n_clusters=clusters, random_state=0, verbose=False, max_iter=300).fit(np.column_stack((df['lat'], df['lon'])))\n",
    "        joblib.dump(kmeans, \"kmeans/kmeans\"+str(clusters)+\"_\"+str(filter)+\".joblib\")\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_kmeans(df:pd.DataFrame, kmeans: KMeans, filter: str, clusters: int):\n",
    "    if filter and filter in df:\n",
    "        columns = df[filter].unique()\n",
    "        for i in range(len(df[filter].unique())):\n",
    "            column = columns[i]\n",
    "            df.loc[df[filter]== column, 'cluster'] = kmeans[i].predict(np.column_stack((df[df[filter] == column]['lat'], df[df[filter] == column]['lon'])))\n",
    "            #df[df[filter] == column]['cluster'] = kmeans[i].predict(np.column_stack((df[df[filter] == column]['lat'], df[df[filter] == column]['lon'])))\n",
    "    else:\n",
    "        df['cluster'] = kmeans.predict(np.column_stack((df['lat'], df['lon'])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(data):\n",
    "  df = data[['revenue', \n",
    "    # 'age_0_19', 'age_20_39', 'age_40_59', 'age_60_79', 'age_80_90', \n",
    "    # 'bus_stops_count', 'Mangler viktighetsnivå', 'Standard holdeplass', 'Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt', 'Annen viktig holdeplass', \n",
    "    'dist_to_center', 'lat','lon'\n",
    "    ]]\n",
    "  df['knutepunkt'] = data[['Lokalt knutepunkt', 'Nasjonalt knutepunkt', 'Regionalt knutepunkt']].sum(axis=1)\n",
    "  # df.revenue = np.exp(df.revenue)\n",
    "  # df.bus_stops_count = np.sqrt(df.bus_stops_count)\n",
    "  df = df[df.dist_to_center < 70_000]\n",
    "  # df.dist_to_center = np.log(df.dist_to_center)\n",
    "  \n",
    "  plt.figure(figsize=(15, 15))\n",
    "  pairplot = sns.pairplot(df)\n",
    "  # heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)\n",
    "\n",
    "\n",
    "# data_full =  pd.merge(X_train, y_train, left_index=True, right_index=True) \n",
    "# plot_corr(data_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_buffers(X_train, y_train, X_val, y_val):\n",
    "    # Clear buffers\n",
    "    folder = os.path.join(os.getcwd(), 'modeling')\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "            print(f'Deleted file: {file_path}')\n",
    "\n",
    "    train_buffer_path = 'modeling/train.buffer'\n",
    "    test_buffer_path = 'modeling/test.buffer'\n",
    "\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train, enable_categorical=True)\n",
    "    dtrain.save_binary(train_buffer_path)\n",
    "    print(f'--> {train_buffer_path} created and saved.')\n",
    "\n",
    "    dvalid = xgb.DMatrix(data=X_val, label=y_val, enable_categorical=True)\n",
    "    dvalid.save_binary(test_buffer_path)\n",
    "    print(f'--> {test_buffer_path} created and saved.')\n",
    "\n",
    "    return dtrain, dvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.best_score_)\n",
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(_rmsle(y_train, y_pred_train))\n",
    "# print(_rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model(X_train, y_train, X_val, y_val):\n",
    "    params = {'colsample_bytree': 0.7717138210314867, 'learning_rate': 0.047506668950627134, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 223, 'subsample': 0.9929036803032936}\n",
    "    print('Clearing and creating buffers...')\n",
    "    dtrain, dvalid = clear_buffers(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    rand_search_model = random_k_fold(X_train, y_train, verbose=1, n_iter=100)\n",
    "    model = rand_search_model\n",
    "    params = model.best_params_\n",
    "    print(rand_search_model.best_score_, params)\n",
    "    \n",
    "    # params = {'colsample_bytree': 0.8601277878899238, 'eval_metric': 'rmsle', 'gamma': 0.12760202929262826, 'learning_rate': 0.07356461924449906, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 306, 'objective': 'reg:squaredlogerror', 'subsample': 0.8993341396761092}\n",
    "    \n",
    "    params['disable_default_eval_metric'] = True\n",
    "    # model = XGBRegressor()\n",
    "    # model.set_params(**params)\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred_train = model.predict(X_train)\n",
    "    # y_pred_val = model.predict(X_val)\n",
    "    # print(_rmsle(y_train, y_pred_train))\n",
    "    # print(_rmsle(y_val, y_pred_val))\n",
    "\n",
    "    # num_round = 999\n",
    "    # watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "    # print(\"Attempting to start training...\")\n",
    "    # model = xgb.train(\n",
    "    #     params=params, \n",
    "    #     dtrain=dtrain, \n",
    "    #     num_boost_round=num_round, \n",
    "    #     evals=watchlist, \n",
    "    #     early_stopping_rounds=10, \n",
    "    #     verbose_eval=20)\n",
    "    # print(\"--> model trained.\")\n",
    "    # print('Best score:', model.best_score)\n",
    "\n",
    "    # print(\"Attempting to save model...\")\n",
    "    # model.save_model(model_name)\n",
    "    # print(\"--> model saved.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "# X_train, X_val = generate_features(X_train, predictor='xgb'), generate_features(X_val, predictor='xgb')\n",
    "\n",
    "# model = train_xgb_model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# print(_rmsle(y_train, y_pred_train))\n",
    "# print(_rmsle(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_prediction(X_test, model):\n",
    "    dtest = xgb.DMatrix(data=X_test, enable_categorical=True)\n",
    "\n",
    "    print(\"\\nAttempting to start prediction...\")\n",
    "    y_pred = model.predict(dtest, ntree_limit=model.best_iteration)\n",
    "    print(\"--> Prediction finished.\")\n",
    "\n",
    "    print(\"\\nAttempting to save prediction...\")\n",
    "    submission['predicted'] = np.array(y_pred)\n",
    "    submission.to_csv('submissions/submission.csv', index=False)\n",
    "    print(\"--> prediction saved with features as name in submission folder.\")\n",
    "\n",
    "\n",
    "# X_test = generate_features(test, predictor='xgb')\n",
    "# xgb_prediction(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = model.best_estimator_ if model.best_estimator_ is not None else model\n",
    "# xgb_model = model\n",
    "# plot_importance(xgb_model)\n",
    "# xgb.to_graphviz(xgb_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features for Catboost predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = 'lv1_desc'\n",
    "clusters = 10\n",
    "\n",
    "X_train_extra = pd.concat([train, extra])\n",
    "X_train_extra = generate_features(X_train_extra, predictor='catboost')\n",
    "kmeans = generate_kmeans(X_train_extra, clusters=clusters, filter=filter)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "X_train, X_val = generate_features(X_train, predictor='catboost'), generate_features(X_val, predictor='catboost')\n",
    "X_train, X_val = predict_kmeans(X_train, kmeans, filter, 0), predict_kmeans(X_val, kmeans, filter, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = generate_features(test, predictor='catboost')\n",
    "X_test = predict_kmeans(X_test, kmeans, filter, 0)\n",
    "\n",
    "auxillary_columns = ['address']\n",
    "text_features = ['store_name', 'address']\n",
    "cat_features = ['mall_name', 'chain_name', 'lv1_desc', 'lv2_desc']\n",
    "\n",
    "train_pool = cb.Pool(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")\n",
    "\n",
    "valid_pool = cb.Pool(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    feature_names=list(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-09 10:44:25,190]\u001b[0m A new study created in memory with name: no-name-97cd8293-9ad1-4303-ac0c-04972d99297f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.073422\n",
      "0:\tlearn: 1.0044292\ttest: 1.0008698\tbest: 1.0008698 (0)\ttotal: 75ms\tremaining: 1m 14s\n",
      "1:\tlearn: 0.9809962\ttest: 0.9759936\tbest: 0.9759936 (1)\ttotal: 98.5ms\tremaining: 49.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-11-09 10:44:30,705]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt('')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Jobb/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/55/fnz5gpdd2vn8_5ncwxtldqww0000gp/T/ipykernel_83206/4117015890.py\", line 48, in objective\n",
      "    cbr.fit(\n",
      "  File \"/Users/Jobb/Library/Python/3.9/lib/python/site-packages/catboost/core.py\", line 5730, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/Users/Jobb/Library/Python/3.9/lib/python/site-packages/catboost/core.py\", line 2355, in _fit\n",
      "    self._train(\n",
      "  File \"/Users/Jobb/Library/Python/3.9/lib/python/site-packages/catboost/core.py\", line 1759, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4623, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4672, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 67\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m score\n\u001b[1;32m     66\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(pruner\u001b[39m=\u001b[39moptuna\u001b[39m.\u001b[39mpruners\u001b[39m.\u001b[39mMedianPruner(n_warmup_steps\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m), direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m) \u001b[39m# timeout=600\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumber of finished trials: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(study\u001b[39m.\u001b[39mtrials)))\n\u001b[1;32m     71\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [17], line 48\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     45\u001b[0m cbr \u001b[39m=\u001b[39m cb\u001b[39m.\u001b[39mCatBoostRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparam, task_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCPU\u001b[39m\u001b[39m'\u001b[39m, devices\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m0:1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[39m# pruning_callback = optuna.integration.CatBoostPruningCallback(trial, 'LogTargetsRmsleMetric')\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m cbr\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     49\u001b[0m     train_pool,\n\u001b[1;32m     50\u001b[0m     eval_set\u001b[39m=\u001b[39;49m[(X_val, y_val)],\n\u001b[1;32m     51\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     52\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     53\u001b[0m     \u001b[39m# callbacks=[pruning_callback]\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[39m# pruning_callback.check_pruned()\u001b[39;00m\n\u001b[1;32m     58\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpm1(cbr\u001b[39m.\u001b[39mpredict(X_val))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/catboost/core.py:5730\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5728\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[1;32m   5731\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[1;32m   5732\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[1;32m   5733\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/catboost/core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2351\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2353\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2356\u001b[0m         train_pool,\n\u001b[1;32m   2357\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2358\u001b[0m         params,\n\u001b[1;32m   2359\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2360\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2361\u001b[0m     )\n\u001b[1;32m   2363\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/catboost/core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4623\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4672\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    param = {\n",
    "        # 'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 3, 9),\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "        'iterations': 1000,\n",
    "        # 'objective': RmseObjective(),\n",
    "        # 'eval_metric': LogTargetsRmsleMetric(),\n",
    "        'objective': 'RMSE',\n",
    "        'eval_metric': 'RMSE'\n",
    "    }\n",
    "\n",
    "    kmeans_param = {\n",
    "        'clusters': trial.suggest_int('clusters', 10, 50),\n",
    "        'filter': trial.suggest_categorical('filter', ['lv1_desc', 'lv2_desc', False])\n",
    "    }\n",
    "    \n",
    "    kmeans = generate_kmeans(X_train_extra, **kmeans_param)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=.8)\n",
    "    X_train, X_val = generate_features(X_train, predictor='catboost'), generate_features(X_val, predictor='catboost')\n",
    "    X_train, X_val = predict_kmeans(X_train, kmeans, **kmeans_param), predict_kmeans(X_val, kmeans, **kmeans_param)\n",
    "    y_train, \n",
    "    train_pool = cb.Pool(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cat_features=cat_features,\n",
    "        text_features=text_features,\n",
    "        feature_names=list(X_train)\n",
    "    )\n",
    "\n",
    "    valid_pool = cb.Pool(\n",
    "        X_val,\n",
    "        y_val,\n",
    "        cat_features=cat_features,\n",
    "        text_features=text_features,\n",
    "        feature_names=list(X_train)\n",
    "    )\n",
    "\n",
    "    if param['bootstrap_type'] == 'Bayesian': \n",
    "        param['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    elif param['bootstrap_type'] == 'Bernoulli':\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.1, 1, log=True)\n",
    "\n",
    "    cbr = cb.CatBoostRegressor(**param, task_type='CPU', devices='0:1')\n",
    "    \n",
    "    # pruning_callback = optuna.integration.CatBoostPruningCallback(trial, 'LogTargetsRmsleMetric')\n",
    "    cbr.fit(\n",
    "        train_pool,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=True,\n",
    "        early_stopping_rounds=50,\n",
    "        # callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    # pruning_callback.check_pruned()\n",
    "\n",
    "    y_pred = np.expm1(cbr.predict(X_val))\n",
    "    score = _rmsle(np.expm1(y_val), y_pred)[1]\n",
    "\n",
    "    # score = np.sqrt(mean_squared_log_error(np.expm1(y_val), y_pred))\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction='minimize')\n",
    "study.optimize(objective, n_trials=100) # timeout=600\n",
    "\n",
    "print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Value:', trial.value)\n",
    "print('Params:')\n",
    "print(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7132706162206984 {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS', 'clusters': 10, 'filter': 'lv1_desc'}\n"
     ]
    }
   ],
   "source": [
    "print(trial.value, trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_summary(cv_data):\n",
    "    cv_data.head(10)\n",
    "\n",
    "    best_value = cv_data['test-Logloss-mean'].min()\n",
    "    best_iter = cv_data['test-Logloss-mean'].values.argmin()\n",
    "\n",
    "    print('Best validation Logloss score : {:.4f}±{:.4f} on step {}'.format(\n",
    "        best_value,\n",
    "        cv_data['test-Logloss-std'][best_iter],\n",
    "        best_iter)\n",
    "    )\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 9),\n",
    "    'iterations': [1000]\n",
    "}\n",
    "\n",
    "cbr = cb.CatBoostRegressor(\n",
    "    objective=RmseObjective(), \n",
    "    eval_metric=LogTargetsRmsleMetric(),\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# cbr.randomized_search(param_dist, X=train_pool, cv=3, n_iter=20, shuffle=True, stratified=True, plot=True)\n",
    "\n",
    "# feature_importance = cbr.get_feature_importance(prettified=True)\n",
    "# print('Feature importance:', feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e2e03ec6fd42e2a8b58d6950a933a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.8443082\ttest: 1.8540434\tbest: 1.8540434 (0)\ttotal: 564ms\tremaining: 9m 23s\n",
      "50:\tlearn: 0.8976052\ttest: 0.9170469\tbest: 0.9170469 (50)\ttotal: 33.7s\tremaining: 10m 27s\n",
      "100:\tlearn: 0.7835852\ttest: 0.8095842\tbest: 0.8095842 (100)\ttotal: 1m 7s\tremaining: 10m 1s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.03,\n",
    "    # 'objective': RmsleObjective(),\n",
    "    # 'eval_metric': RmsleMetric()\n",
    "    'objective': RmseObjective(),\n",
    "    'eval_metric': LogTargetsRmsleMetric()\n",
    "}\n",
    "\n",
    "params = {'iterations': 1000,\n",
    " 'loss_function': 'RMSE',\n",
    " 'eval_metric': LogTargetsRmsleMetric(),\n",
    " 'objective': RmseObjective(),\n",
    " 'depth': 7.0,\n",
    " 'learning_rate': 0.0494195212108839}\n",
    "\n",
    "\n",
    "params = {'colsample_bylevel': 0.07329097359385545, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.1734504015536018}\n",
    "params = {'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.635180352520854}\n",
    "params = {'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}\n",
    "\n",
    "model = cb.CatBoostRegressor(**params, objective=RmseObjective(), eval_metric=LogTargetsRmsleMetric())\n",
    "model.fit(train_pool, eval_set=valid_pool, verbose=50, plot=True)\n",
    "\n",
    "y_pred = np.expm1(model.predict(X_test))\n",
    "submission['predicted'] = y_pred\n",
    "submission.to_csv('submissions/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.expm1(model.predict(X_test))\n",
    "submission['predicted'] = y_pred\n",
    "submission.to_csv('submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10.000000000000002\n"
     ]
    }
   ],
   "source": [
    "# y_pred = model.predict(test)\n",
    "# y_pred\n",
    "\n",
    "a = 10\n",
    "log_a = np.log1p(a)\n",
    "exp_log_a = np.expm1(log_a)\n",
    "\n",
    "print(a, exp_log_a)\n",
    "\n",
    "model.best_score_\n",
    "\n",
    "y_pred = np.expm1()\n",
    "submission['predicted'] = np.array(y_pred)\n",
    "submission.to_csv('submissions/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "There is no trained model to use predict(). Use fit() to train model. Then use this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [228], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[39m=\u001b[39m cb\u001b[39m.\u001b[39mCatBoostRegressor(loss_function\u001b[39m=\u001b[39mRmsleObjective, eval_metric\u001b[39m=\u001b[39mRmsleMetric)\n\u001b[1;32m     10\u001b[0m \u001b[39m# model.randomized_search(train_pool, param_distributions=params, cv=5)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_val)\n\u001b[1;32m     13\u001b[0m rmsle \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39msqrt(mean_squared_log_error(y_val, pred)))\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTesting performance\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:5775\u001b[0m, in \u001b[0;36mCatBoostRegressor.predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5773\u001b[0m \u001b[39mif\u001b[39;00m prediction_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5774\u001b[0m     prediction_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_default_prediction_type()\n\u001b[0;32m-> 5775\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, \u001b[39m'\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m'\u001b[39;49m, task_type)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:2541\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2540\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 2541\u001b[0m data, data_is_single_object \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[1;32m   2542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[1;32m   2544\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "File \u001b[0;32m~/Desktop/maskinprosjekt/venv/lib/python3.8/site-packages/catboost/core.py:2517\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_process_predict_input_data\u001b[39m(\u001b[39mself\u001b[39m, data, parent_method_name, thread_count, label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2516\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_fitted() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_count_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2517\u001b[0m         \u001b[39mraise\u001b[39;00m CatBoostError((\u001b[39m\"\u001b[39m\u001b[39mThere is no trained model to use \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m(). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2518\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39mUse fit() to train model. Then use this method.\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mformat(parent_method_name))\n\u001b[1;32m   2519\u001b[0m     is_single_object \u001b[39m=\u001b[39m _is_data_single_object(data)\n\u001b[1;32m   2520\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Pool):\n",
      "\u001b[0;31mCatBoostError\u001b[0m: There is no trained model to use predict(). Use fit() to train model. Then use this method."
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'depth': randint(2, 20),\n",
    "    'learning_rate': uniform(0.01, 0.4),\n",
    "    'iterations': randint(10, 1000)\n",
    "}\n",
    "\n",
    "model = cb.CatBoostRegressor(loss_function=RmsleObjective, eval_metric=RmsleMetric)\n",
    "\n",
    "\n",
    "# model.randomized_search(train_pool, param_distributions=params, cv=5)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "rmsle = (np.sqrt(mean_squared_log_error(y_val, pred)))\n",
    "print('Testing performance')\n",
    "print('RMSLE: {:.2f}'.format(rmsle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
